#!/usr/bin/env python3
"""
n8nãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç¾åœ¨ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹æˆã‚’è©³ç´°ã«åˆ†æ
"""

import os

import requests
from dotenv import load_dotenv

load_dotenv()


class N8nWorkflowAnalyzer:
    def __init__(self):
        self.base_url = "https://dd1107.app.n8n.cloud"
        self.api_key = os.getenv("N8N_API_KEY")
        self.headers = {
            "X-N8N-API-KEY": self.api_key,
            "Content-Type": "application/json",
            "Accept": "application/json",
        }

    def get_workflows(self):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ä¸€è¦§å–å¾—"""
        response = requests.get(
            f"{self.base_url}/api/v1/workflows?limit=250", headers=self.headers
        )
        return response.json().get("data", [])

    def find_claude_workflow(self, workflows):
        """claude-performanceãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ¤œç´¢"""
        print("ğŸ” Claudeé–¢é€£ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¤œç´¢:")

        found_workflows = []
        for wf in workflows:
            nodes = wf.get("nodes", [])
            for node in nodes:
                if node.get("type") == "n8n-nodes-base.webhook":
                    path = node.get("parameters", {}).get("path", "")
                    if "claude-performance" in path.lower():
                        print(
                            f"  âœ… ç™ºè¦‹: {wf['name']} (path: {path}, active: {wf.get('active')})"
                        )
                        found_workflows.append(wf)
                        break

        if not found_workflows:
            print("  âŒ Claudeé–¢é€£ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None

        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚‚ã®ã‚’å„ªå…ˆ
        for wf in found_workflows:
            if wf.get("active", False):
                print(f"  ğŸ¯ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é¸æŠ: {wf['name']}")
                return wf

        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚‚ã®ãŒãªã‘ã‚Œã°æœ€åˆã®ã‚‚ã®ã‚’è¿”ã™
        print(f"  âš ï¸ éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é¸æŠ: {found_workflows[0]['name']}")
        return found_workflows[0]

    def analyze_workflow_structure(self, workflow):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ§‹é€ åˆ†æ"""

        print(f"ğŸ“‹ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼åˆ†æ: {workflow['name']}")
        print(f"ID: {workflow['id']}")
        print(f"Active: {workflow.get('active', False)}")
        print(f"ãƒãƒ¼ãƒ‰æ•°: {len(workflow.get('nodes', []))}")
        print()

        nodes = workflow.get("nodes", [])
        connections = workflow.get("connections", {})

        print("ğŸ”— ãƒãƒ¼ãƒ‰ä¸€è¦§:")
        for i, node in enumerate(nodes):
            node_type = node.get("type", "unknown")
            node_name = node.get("name", "unnamed")
            print(f"  {i + 1}. {node_name} ({node_type})")

            # Webhookè©³ç´°
            if node_type == "n8n-nodes-base.webhook":
                params = node.get("parameters", {})
                print(f"     Path: {params.get('path', 'N/A')}")
                print(f"     Method: {params.get('httpMethod', 'GET')}")

            # HTTP Requestè©³ç´°
            elif node_type == "n8n-nodes-base.httpRequest":
                params = node.get("parameters", {})
                print(f"     URL: {params.get('url', 'N/A')}")
                print(f"     Method: {params.get('method', 'GET')}")

            # PostgreSQLè©³ç´°
            elif node_type == "n8n-nodes-base.postgres":
                params = node.get("parameters", {})
                print(f"     Table: {params.get('table', 'N/A')}")
                print(f"     Operation: {params.get('operation', 'N/A')}")

        print("\nğŸ”— æ¥ç¶šæƒ…å ±:")
        for source_node, targets in connections.items():
            main_targets = targets.get("main", [[]])
            if main_targets and main_targets[0]:
                target_names = [t["node"] for t in main_targets[0]]
                print(f"  {source_node} â†’ {', '.join(target_names)}")

        return nodes, connections

    def check_supabase_integration(self, nodes):
        """Supabaseçµ±åˆç¢ºèª"""

        print("\nğŸ” Supabaseçµ±åˆãƒã‚§ãƒƒã‚¯:")

        supabase_nodes = []
        postgres_nodes = []
        http_nodes = []

        for node in nodes:
            node_type = node.get("type", "")
            node_name = node.get("name", "")

            if "supabase" in node_name.lower():
                supabase_nodes.append(node)
            elif node_type == "n8n-nodes-base.postgres":
                postgres_nodes.append(node)
            elif node_type == "n8n-nodes-base.httpRequest":
                http_nodes.append(node)

        if supabase_nodes:
            print(f"  âœ… Supabaseãƒãƒ¼ãƒ‰ç™ºè¦‹: {len(supabase_nodes)}å€‹")
            for node in supabase_nodes:
                print(f"    - {node['name']}")
        else:
            print("  âŒ Supabaseãƒãƒ¼ãƒ‰ãªã—")

        if postgres_nodes:
            print(f"  ğŸ“Š PostgreSQLãƒãƒ¼ãƒ‰: {len(postgres_nodes)}å€‹")
            for node in postgres_nodes:
                params = node.get("parameters", {})
                print(f"    - {node['name']} (Table: {params.get('table', 'N/A')})")

        if http_nodes:
            print(f"  ğŸŒ HTTPãƒãƒ¼ãƒ‰: {len(http_nodes)}å€‹")
            for node in http_nodes:
                params = node.get("parameters", {})
                url = params.get("url", "N/A")
                if "supabase" in url:
                    print(f"    - {node['name']} â†’ {url}")
                else:
                    print(f"    - {node['name']} â†’ {url[:50]}...")

        return len(supabase_nodes) > 0 or any(
            "supabase" in node.get("parameters", {}).get("url", "")
            for node in http_nodes
        )

    def generate_fix_recommendation(self, workflow, has_supabase_integration):
        """ä¿®æ­£æ¨å¥¨ã‚’ç”Ÿæˆ"""

        print("\nğŸ’¡ ä¿®æ­£æ¨å¥¨:")

        if not has_supabase_integration:
            print("  ğŸ”§ å•é¡Œ: Supabaseçµ±åˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("  ğŸ“‹ è§£æ±ºç­–:")
            print("    1. æ—¢å­˜ã®PostgreSQLãƒãƒ¼ãƒ‰ã‚’å‰Šé™¤ã¾ãŸã¯ç„¡åŠ¹åŒ–")
            print("    2. Supabase REST APIç”¨ã®HTTP Requestãƒãƒ¼ãƒ‰ã‚’è¿½åŠ ")
            print("    3. ç’°å¢ƒå¤‰æ•°SUPABASE_ANON_KEYã‚’è¨­å®š")

        if not workflow.get("active", False):
            print("  âš ï¸ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒéã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã§ã™")
            print("  ğŸ“‹ è§£æ±ºç­–: n8nãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–")

        # PostgreSQLãƒãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã®è­¦å‘Š
        nodes = workflow.get("nodes", [])
        postgres_nodes = [
            n for n in nodes if n.get("type") == "n8n-nodes-base.postgres"
        ]
        if postgres_nodes:
            print("  âš ï¸ PostgreSQLãƒãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            print(
                "  ğŸ“‹ å•é¡Œ: Supabase REST APIã¨PostgreSQLãƒãƒ¼ãƒ‰ã¯ç«¶åˆã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
            )


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""

    print("ğŸ” n8nãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è©³ç´°åˆ†æé–‹å§‹")
    print("=" * 60)

    analyzer = N8nWorkflowAnalyzer()

    # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å–å¾—
    workflows = analyzer.get_workflows()
    print(f"ğŸ“Š åˆè¨ˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ•°: {len(workflows)}")

    # claude-performanceãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ¤œç´¢
    claude_workflow = analyzer.find_claude_workflow(workflows)

    if not claude_workflow:
        print("âŒ claude-performanceãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ğŸ’¡ åˆ©ç”¨å¯èƒ½ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼:")
        for wf in workflows:
            print(f"  - {wf['name']} (ID: {wf['id'][:8]}...)")
        return False

    # è©³ç´°åˆ†æ
    nodes, connections = analyzer.analyze_workflow_structure(claude_workflow)

    # Supabaseçµ±åˆç¢ºèª
    has_supabase = analyzer.check_supabase_integration(nodes)

    # ä¿®æ­£æ¨å¥¨
    analyzer.generate_fix_recommendation(claude_workflow, has_supabase)

    print("\nğŸ¯ åˆ†æçµæœ:")
    print(f"  - ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: {claude_workflow['name']}")
    print(f"  - ã‚¢ã‚¯ãƒ†ã‚£ãƒ–: {'âœ…' if claude_workflow.get('active') else 'âŒ'}")
    print(f"  - Supabaseçµ±åˆ: {'âœ…' if has_supabase else 'âŒ'}")
    print(f"  - ãƒãƒ¼ãƒ‰æ•°: {len(nodes)}")

    return has_supabase


if __name__ == "__main__":
    main()
