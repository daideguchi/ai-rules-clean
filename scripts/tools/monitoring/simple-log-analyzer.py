#!/usr/bin/env python3
"""
[LEGACY WRAPPER] Simple Log Analyzer

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ unified-monitoring-tool.py ã«çµ±åˆã•ã‚Œã¾ã—ãŸã€‚
Phase 4 çµ±åˆå®Œäº† - ãƒ¬ã‚¬ã‚·ãƒ¼äº’æ›æ€§ã®ãŸã‚ã®wrapperã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ–°ã—ã„ä½¿ç”¨æ–¹æ³•:
  scripts/tools/unified-monitoring-tool.py analyze
"""

import gzip
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Tuple

print("âš ï¸  [LEGACY] simple-log-analyzer.py ã¯çµ±åˆã•ã‚Œã¾ã—ãŸ")
print("ğŸ“¦ unified-monitoring-tool.py analyze ã«ç§»è¡Œã—ã¦ãã ã•ã„")
print("")
print("ğŸ”„ è‡ªå‹•è»¢é€ä¸­...")

# çµ±åˆãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œ
script_dir = Path(__file__).parent
unified_tool = script_dir.parent / "unified-monitoring-tool.py"

# å¼•æ•°å¤‰æ›
args = sys.argv[1:] if len(sys.argv) > 1 else ["analyze"]
if args[0] in ["analyze", "cleanup", "rotate", "all"]:
    new_args = ["analyze"] + args[1:]
else:
    new_args = ["analyze"] + args

os.execv(sys.executable, [sys.executable, str(unified_tool)] + new_args)


class SimpleLogAnalyzer:
    """ã‚·ãƒ³ãƒ—ãƒ«ãƒ­ã‚°åˆ†æã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, log_root: str = "runtime/logs"):
        self.log_root = Path(log_root)
        if not self.log_root.exists():
            self.log_root.mkdir(parents=True, exist_ok=True)

        print(f"ğŸ” SimpleLogAnalyzeråˆæœŸåŒ–å®Œäº† - ãƒ­ã‚°ãƒ«ãƒ¼ãƒˆ: {self.log_root}")

    def analyze_logs(self) -> Dict[str, Any]:
        """ãƒ­ã‚°åˆ†æå®Ÿè¡Œ"""
        print("ğŸ“Š ãƒ­ã‚°åˆ†æé–‹å§‹...")

        stats = {
            "total_files": 0,
            "total_size_mb": 0,
            "file_types": {},
            "large_files": [],
            "old_files": [],
            "errors_found": 0,
            "warnings_found": 0,
        }

        for log_file in self.log_root.rglob("*"):
            if not log_file.is_file():
                continue

            stats["total_files"] += 1
            file_size = log_file.stat().st_size
            stats["total_size_mb"] += file_size / (1024 * 1024)

            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—çµ±è¨ˆ
            suffix = log_file.suffix.lower()
            stats["file_types"][suffix] = stats["file_types"].get(suffix, 0) + 1

            # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º
            if file_size > 10 * 1024 * 1024:  # 10MBä»¥ä¸Š
                stats["large_files"].append(
                    {
                        "file": str(log_file.relative_to(self.log_root)),
                        "size_mb": round(file_size / (1024 * 1024), 2),
                    }
                )

            # å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º
            mtime = datetime.fromtimestamp(log_file.stat().st_mtime)
            if datetime.now() - mtime > timedelta(days=30):
                stats["old_files"].append(
                    {
                        "file": str(log_file.relative_to(self.log_root)),
                        "age_days": (datetime.now() - mtime).days,
                    }
                )

            # ãƒ­ã‚°å†…å®¹åˆ†æï¼ˆãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ï¼‰
            if suffix in [".log", ".txt"]:
                error_count, warning_count = self._analyze_log_content(log_file)
                stats["errors_found"] += error_count
                stats["warnings_found"] += warning_count

        # åˆ†æçµæœ
        result = {
            "analysis_time": datetime.now().isoformat(),
            "statistics": stats,
            "recommendations": self._generate_recommendations(stats),
        }

        print(
            f"âœ… ãƒ­ã‚°åˆ†æå®Œäº† - {stats['total_files']}ãƒ•ã‚¡ã‚¤ãƒ«, {stats['total_size_mb']:.1f}MB"
        )
        return result

    def _analyze_log_content(self, log_file: Path) -> Tuple[int, int]:
        """ãƒ­ã‚°å†…å®¹ã®åˆ†æ"""
        error_count = 0
        warning_count = 0

        try:
            with open(log_file, encoding="utf-8", errors="ignore") as f:
                for line in f:
                    line_lower = line.lower()
                    if "error" in line_lower or "fatal" in line_lower:
                        error_count += 1
                    elif "warning" in line_lower or "warn" in line_lower:
                        warning_count += 1
        except Exception:
            pass  # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–

        return error_count, warning_count

    def _generate_recommendations(self, stats: Dict[str, Any]) -> List[str]:
        """æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []

        # å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«
        if len(stats["large_files"]) > 0:
            recommendations.append(
                f"ğŸ—‚ï¸ å¤§å®¹é‡ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« {len(stats['large_files'])}å€‹ - ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ¨å¥¨"
            )

        # å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«
        if len(stats["old_files"]) > 5:
            recommendations.append(
                f"ğŸ—‘ï¸ å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« {len(stats['old_files'])}å€‹ - ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ¨å¥¨"
            )

        # ã‚¨ãƒ©ãƒ¼æ•°
        if stats["errors_found"] > 100:
            recommendations.append(
                f"ğŸš¨ å¤šæ•°ã®ã‚¨ãƒ©ãƒ¼æ¤œå‡º ({stats['errors_found']}ä»¶) - èª¿æŸ»ãŒå¿…è¦"
            )

        # è­¦å‘Šæ•°
        if stats["warnings_found"] > 500:
            recommendations.append(
                f"âš ï¸ å¤šæ•°ã®è­¦å‘Šæ¤œå‡º ({stats['warnings_found']}ä»¶) - ç¢ºèªæ¨å¥¨"
            )

        # ç·ã‚µã‚¤ã‚º
        if stats["total_size_mb"] > 100:
            recommendations.append(
                f"ğŸ’¾ ãƒ­ã‚°ã‚µã‚¤ã‚ºå¤§ ({stats['total_size_mb']:.1f}MB) - ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¨å¥¨"
            )

        if not recommendations:
            recommendations.append("âœ… ãƒ­ã‚°çŠ¶æ…‹ã¯è‰¯å¥½ã§ã™")

        return recommendations

    def cleanup_old_logs(self, days: int = 30) -> Dict[str, Any]:
        """å¤ã„ãƒ­ã‚°ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print(f"ğŸ§¹ {days}æ—¥ä»¥ä¸ŠçµŒéã—ãŸãƒ­ã‚°ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")

        cutoff_date = datetime.now() - timedelta(days=days)
        deleted_files = []
        freed_space_mb = 0

        for log_file in self.log_root.rglob("*.log"):
            if not log_file.is_file():
                continue

            mtime = datetime.fromtimestamp(log_file.stat().st_mtime)
            if mtime < cutoff_date:
                file_size = log_file.stat().st_size
                freed_space_mb += file_size / (1024 * 1024)
                deleted_files.append(str(log_file.relative_to(self.log_root)))

                try:
                    log_file.unlink()
                except Exception as e:
                    print(f"âŒ å‰Šé™¤å¤±æ•—: {log_file} - {e}")

        result = {
            "cleaned_files": len(deleted_files),
            "files": deleted_files,
            "freed_space_mb": round(freed_space_mb, 2),
            "cutoff_days": days,
        }

        print(
            f"âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº† - {len(deleted_files)}ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤, {freed_space_mb:.1f}MBè§£æ”¾"
        )
        return result

    def rotate_large_logs(self, max_size_mb: int = 10) -> Dict[str, Any]:
        """å¤§å®¹é‡ãƒ­ã‚°ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"""
        print(f"ğŸ”„ {max_size_mb}MBä»¥ä¸Šã®ãƒ­ã‚°ã‚’ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä¸­...")

        rotated_files = []
        max_size_bytes = max_size_mb * 1024 * 1024

        for log_file in self.log_root.rglob("*.log"):
            if not log_file.is_file():
                continue

            if log_file.stat().st_size > max_size_bytes:
                rotated_path = self._rotate_file(log_file)
                if rotated_path:
                    rotated_files.append(
                        {
                            "original": str(log_file.relative_to(self.log_root)),
                            "rotated": str(rotated_path.relative_to(self.log_root)),
                        }
                    )

        result = {
            "rotated_files": len(rotated_files),
            "files": rotated_files,
            "max_size_mb": max_size_mb,
        }

        print(f"âœ… ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº† - {len(rotated_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
        return result

    def _rotate_file(self, log_file: Path) -> Path:
        """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³"""
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        rotated_name = f"{log_file.stem}-{timestamp}.log.gz"
        rotated_path = log_file.parent / rotated_name

        try:
            # gzipåœ§ç¸®
            with open(log_file, "rb") as f_in:
                with gzip.open(rotated_path, "wb") as f_out:
                    f_out.writelines(f_in)

            # å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªã‚¢
            log_file.write_text("")
            return rotated_path

        except Exception as e:
            print(f"âŒ ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å¤±æ•—: {log_file} - {e}")
            return None


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse

    parser = argparse.ArgumentParser(description="Simple Log Analyzer")
    parser.add_argument(
        "action",
        choices=["analyze", "cleanup", "rotate", "all"],
        help="å®Ÿè¡Œã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³",
    )
    parser.add_argument(
        "--log-root", default="runtime/logs", help="ãƒ­ã‚°ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
    )
    parser.add_argument("--days", type=int, default=30, help="ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ—¥æ•°")
    parser.add_argument(
        "--max-size", type=int, default=10, help="ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚º(MB)"
    )

    args = parser.parse_args()

    analyzer = SimpleLogAnalyzer(args.log_root)

    if args.action == "analyze" or args.action == "all":
        result = analyzer.analyze_logs()
        print("\n" + "=" * 60)
        print("ğŸ“Š ãƒ­ã‚°åˆ†æçµæœ")
        print("=" * 60)
        print(f"ğŸ“ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {result['statistics']['total_files']}")
        print(f"ğŸ’¾ ç·ã‚µã‚¤ã‚º: {result['statistics']['total_size_mb']:.1f} MB")
        print(f"ğŸš¨ ã‚¨ãƒ©ãƒ¼æ•°: {result['statistics']['errors_found']}")
        print(f"âš ï¸ è­¦å‘Šæ•°: {result['statistics']['warnings_found']}")
        print(f"ğŸ“ˆ å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«: {len(result['statistics']['large_files'])}")
        print(f"ğŸ—“ï¸ å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«: {len(result['statistics']['old_files'])}")
        print("\nğŸ¯ æ¨å¥¨äº‹é …:")
        for rec in result["recommendations"]:
            print(f"  {rec}")
        print("=" * 60)

    if args.action == "cleanup" or args.action == "all":
        cleanup_result = analyzer.cleanup_old_logs(args.days)
        print(f"\nğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {cleanup_result['cleaned_files']}ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤")

    if args.action == "rotate" or args.action == "all":
        rotate_result = analyzer.rotate_large_logs(args.max_size)
        print(f"\nğŸ”„ ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {rotate_result['rotated_files']}ãƒ•ã‚¡ã‚¤ãƒ«")


if __name__ == "__main__":
    main()
