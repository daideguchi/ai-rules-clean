#!/usr/bin/env python3
"""
ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®Supabaseç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
=====================================

ãƒ­ãƒ¼ã‚«ãƒ«ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Supabaseã®ai_performance_logãƒ†ãƒ¼ãƒ–ãƒ«ã«ç§»è¡Œã—ã€
ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¦ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ç¯€ç´„ã™ã‚‹
"""

import json
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from supabase import Client, create_client
except ImportError as e:
    print(f"âŒ Required packages not installed: {e}")
    print("Run: pip install supabase")
    sys.exit(1)


class LogMigration:
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®Supabaseç§»è¡Œ"""

    def __init__(self):
        self.project_root = project_root
        self.supabase_url = "http://127.0.0.1:54321"
        self.supabase_key = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZS1kZW1vIiwicm9sZSI6ImFub24iLCJleHAiOjE5ODM4MTI5OTZ9.CRXP1A7WOeoJeXxjNni43kdQwgnWNReilDMblYTn_I0"
        self.supabase: Optional[Client] = None
        self.migrated_logs = []

    def connect_supabase(self) -> bool:
        """Supabaseã«æ¥ç¶š"""
        try:
            self.supabase = create_client(self.supabase_url, self.supabase_key)
            print("âœ… Supabaseæ¥ç¶šæˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ Supabaseæ¥ç¶šå¤±æ•—: {e}")
            return False

    def find_log_files(self) -> List[Path]:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        log_files = []

        # runtime/logs/
        runtime_logs = self.project_root / "runtime" / "logs"
        if runtime_logs.exists():
            log_files.extend(runtime_logs.glob("*.log"))

        # runtime/ç›´ä¸‹
        runtime_dir = self.project_root / "runtime"
        if runtime_dir.exists():
            log_files.extend(runtime_dir.glob("*.log"))

        # logs/
        logs_dir = self.project_root / "logs"
        if logs_dir.exists():
            log_files.extend(logs_dir.glob("*.log"))

        # åœ§ç¸®ãƒ­ã‚°
        if runtime_logs.exists():
            log_files.extend(runtime_logs.glob("*.log.gz"))

        return sorted(log_files)

    def parse_log_entry(self, log_path: Path, line: str) -> Optional[Dict]:
        """ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’è§£æ"""
        try:
            # JSONå½¢å¼ã®ãƒ­ã‚°ã‚’è©¦ã™
            if line.strip().startswith("{"):
                data = json.loads(line.strip())
                return {
                    "session_id": data.get("session_id", "unknown"),
                    "timestamp": data.get("timestamp", datetime.now().isoformat()),
                    "task_success": data.get("success", False),
                    "execution_time": data.get("execution_time", 0),
                    "tool_calls_count": data.get("tool_calls_count", 0),
                    "tool_calls": data.get("tool_calls", []),
                    "error_count": data.get("error_count", 0),
                    "thinking_tag_used": data.get("thinking_tag_used", False),
                    "todo_tracking": data.get("todo_tracking", False),
                    "task_complexity": data.get("task_complexity", "simple"),
                    "learning_score": data.get("learning_score", 0),
                    "success_patterns": data.get("success_patterns", []),
                    "failure_patterns": data.get("failure_patterns", []),
                    "user_feedback": data.get("user_feedback", ""),
                    "log_source": str(log_path.name),
                }

            # ä¸€èˆ¬çš„ãªãƒ­ã‚°å½¢å¼ã‚’è§£æ
            timestamp_match = re.search(
                r"(\d{4}-\d{2}-\d{2}[T\s]\d{2}:\d{2}:\d{2})", line
            )
            timestamp = (
                timestamp_match.group(1)
                if timestamp_match
                else datetime.now().isoformat()
            )

            # ã‚¨ãƒ©ãƒ¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š
            is_error = any(
                keyword in line.lower()
                for keyword in ["error", "failed", "exception", "traceback"]
            )

            # æˆåŠŸã‹ã©ã†ã‹ã‚’åˆ¤å®š
            is_success = any(
                keyword in line.lower()
                for keyword in ["success", "completed", "done", "âœ…"]
            )

            return {
                "session_id": f"log_migration_{log_path.stem}",
                "timestamp": timestamp,
                "task_success": is_success and not is_error,
                "execution_time": 0,
                "tool_calls_count": 0,
                "tool_calls": [],
                "error_count": 1 if is_error else 0,
                "thinking_tag_used": "<thinking>" in line,
                "todo_tracking": "todo" in line.lower(),
                "task_complexity": "simple",
                "learning_score": 0,
                "success_patterns": [],
                "failure_patterns": [],
                "user_feedback": line.strip()[:500],  # æœ€åˆã®500æ–‡å­—
                "log_source": str(log_path.name),
            }

        except Exception as e:
            print(f"âš ï¸ ãƒ­ã‚°è§£æã‚¨ãƒ©ãƒ¼ {log_path}: {e}")
            return None

    def migrate_log_file(self, log_path: Path) -> int:
        """å€‹åˆ¥ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç§»è¡Œ"""
        migrated_count = 0

        try:
            # åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
            if log_path.suffix == ".gz":
                import gzip

                with gzip.open(log_path, "rt", encoding="utf-8", errors="ignore") as f:
                    lines = f.readlines()
            else:
                with open(log_path, encoding="utf-8", errors="ignore") as f:
                    lines = f.readlines()

            batch_data = []
            for line in lines:
                if line.strip():
                    entry = self.parse_log_entry(log_path, line)
                    if entry:
                        batch_data.append(entry)

                        # ãƒãƒƒãƒå‡¦ç†ï¼ˆ100ä»¶ãšã¤ï¼‰
                        if len(batch_data) >= 100:
                            if self.insert_batch(batch_data):
                                migrated_count += len(batch_data)
                            batch_data = []

            # æ®‹ã‚Šã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
            if batch_data:
                if self.insert_batch(batch_data):
                    migrated_count += len(batch_data)

            print(f"âœ… {log_path.name}: {migrated_count}ä»¶ç§»è¡Œå®Œäº†")
            return migrated_count

        except Exception as e:
            print(f"âŒ {log_path.name}: ç§»è¡Œå¤±æ•— - {e}")
            return 0

    def insert_batch(self, batch_data: List[Dict]) -> bool:
        """ãƒãƒƒãƒãƒ‡ãƒ¼ã‚¿ã‚’Supabaseã«æŒ¿å…¥"""
        try:
            self.supabase.table("ai_performance_log").insert(batch_data).execute()
            return True
        except Exception as e:
            print(f"âŒ ãƒãƒƒãƒæŒ¿å…¥å¤±æ•—: {e}")
            return False

    def cleanup_log_files(self, log_files: List[Path]) -> int:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤"""
        cleaned_count = 0

        for log_path in log_files:
            try:
                log_path.unlink()
                print(f"ğŸ—‘ï¸ å‰Šé™¤: {log_path.name}")
                cleaned_count += 1
            except Exception as e:
                print(f"âŒ å‰Šé™¤å¤±æ•— {log_path.name}: {e}")

        return cleaned_count

    def run_migration(self) -> Dict[str, int]:
        """ç§»è¡Œå®Ÿè¡Œ"""
        print("ğŸš€ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«Supabaseç§»è¡Œé–‹å§‹")
        print("=" * 50)

        # Supabaseæ¥ç¶š
        if not self.connect_supabase():
            return {"error": 1}

        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        log_files = self.find_log_files()
        print(f"ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º: {len(log_files)}ä»¶")

        if not log_files:
            print("â„¹ï¸ ç§»è¡Œå¯¾è±¡ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {"files": 0, "entries": 0}

        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆè¡¨ç¤º
        for log_file in log_files:
            size = log_file.stat().st_size
            print(f"  ğŸ“„ {log_file.name} ({size:,} bytes)")

        # ç§»è¡Œå®Ÿè¡Œ
        total_migrated = 0
        for log_file in log_files:
            migrated = self.migrate_log_file(log_file)
            total_migrated += migrated
            self.migrated_logs.append(
                {
                    "file": str(log_file.name),
                    "entries": migrated,
                    "size": log_file.stat().st_size,
                }
            )

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        cleaned_files = self.cleanup_log_files(log_files)

        # çµæœãƒ¬ãƒãƒ¼ãƒˆ
        print("\n" + "=" * 50)
        print("ğŸ“Š ç§»è¡Œçµæœãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 50)
        print(f"âœ… ç§»è¡Œãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(log_files)}")
        print(f"âœ… ç§»è¡Œã‚¨ãƒ³ãƒˆãƒªæ•°: {total_migrated:,}")
        print(f"âœ… å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {cleaned_files}")

        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
        total_size = sum(log["size"] for log in self.migrated_logs)
        print(f"ğŸ’¾ è§£æ”¾å®¹é‡: {total_size:,} bytes ({total_size / 1024 / 1024:.2f} MB)")

        return {
            "files": len(log_files),
            "entries": total_migrated,
            "cleaned": cleaned_files,
            "size_freed": total_size,
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    migrator = LogMigration()

    try:
        result = migrator.run_migration()

        # çµæœä¿å­˜
        result_file = project_root / "runtime" / "log_migration_report.json"
        result_file.parent.mkdir(parents=True, exist_ok=True)

        with open(result_file, "w") as f:
            json.dump(
                {
                    "migration_timestamp": datetime.now().isoformat(),
                    "results": result,
                    "migrated_logs": migrator.migrated_logs,
                },
                f,
                indent=2,
            )

        print(f"\nğŸ“ çµæœãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {result_file}")

        if result.get("entries", 0) > 0:
            print("\nğŸ‰ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«Supabaseç§»è¡Œå®Œäº†ï¼")
            print("ğŸ’¡ æ¬¡å›ã‹ã‚‰æ–°ã—ã„ãƒ­ã‚°ã¯ç›´æ¥Supabaseã«è¨˜éŒ²ã•ã‚Œã¾ã™")
        else:
            print("\nâš ï¸ ç§»è¡Œå¯¾è±¡ã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    except KeyboardInterrupt:
        print("\nâš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ç§»è¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
