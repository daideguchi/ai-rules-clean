#!/bin/bash
# ğŸ—„ï¸ Database Unified Maintenance System - DBçµ±åˆãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ 
# ================================================================
# db-maintenance-scheduler.sh + archive-wal.sh + setup-backup-cron.shçµ±åˆ
# o3æ¨å¥¨ã®flockåˆ¶å¾¡ãƒ»æ’ä»–å®Ÿè¡Œãƒ»æ§‹é€ åŒ–ãƒ­ã‚°ãƒ»æ®µéšçš„å®Ÿè¡Œå¯¾å¿œ

set -o pipefail  # o3æ¨å¥¨: set -eå›é¿ã§Cronåœæ­¢é˜²æ­¢

PROJECT_ROOT="/Users/dd/Desktop/1_dev/coding-rule2"
DB_NAME="coding_rule2_ai"
DB_USER="dd"
LOG_DIR="$PROJECT_ROOT/runtime/ai_api_logs"
BACKUP_DIR="$PROJECT_ROOT/runtime/backups"
WAL_ARCHIVE_DIR="$PROJECT_ROOT/runtime/wal_archives"
UNIFIED_LOG="$LOG_DIR/db_unified_maintenance_$(date +%Y%m%d).log"

# o3æ¨å¥¨: ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p "$LOG_DIR" "$BACKUP_DIR" "$WAL_ARCHIVE_DIR"

# o3æ¨å¥¨: æ§‹é€ åŒ–ãƒ­ã‚° + syslogçµ±åˆ
log_structured() {
    local level=$1
    local operation=$2
    local message=$3
    local timestamp=$(date -Iseconds)
    local details="${4:-{}}"
    
    # æ§‹é€ åŒ–JSONå‡ºåŠ›
    echo "{\"timestamp\":\"$timestamp\",\"level\":\"$level\",\"operation\":\"$operation\",\"message\":\"$message\",\"details\":$details}" | tee -a "$UNIFIED_LOG"
    
    # syslogé€ä¿¡ï¼ˆç›£è¦–ç³»é€£æºï¼‰
    logger -t db-unified-maintenance -p local3.$level "[$operation] $message"
    
    # å¾“æ¥ãƒ­ã‚°äº’æ›æ€§
    echo "[$timestamp] [$level] [$operation] $message" | tee -a "$LOG_DIR/maintenance_$(date +%Y%m%d).log"
}

show_usage() {
    cat << EOF
Database Unified Maintenance System - DBçµ±åˆãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã‚·ã‚¹ãƒ†ãƒ 

ä½¿ç”¨æ–¹æ³•:
  $0 [OPTIONS] <operation>

æ“ä½œ:
  vacuum          ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹VACUUMãƒ»ANALYZEå®Ÿè¡Œ
  backup          ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆï¼ˆpg_dumpï¼‰  
  archive         WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè¡Œï¼ˆPITRç”¨ï¼‰
  monitor         ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
  vector          ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–
  inheritance     ãƒ¡ãƒ¢ãƒªç¶™æ‰¿ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–
  embeddings      ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ›´æ–°
  setup-cron      cronã‚¸ãƒ§ãƒ–è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
  all             å…¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Ÿè¡Œï¼ˆæ’ä»–åˆ¶å¾¡ä»˜ãï¼‰

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
  --dry-run       å®Ÿè¡Œå†…å®¹ã‚’ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿ï¼ˆå®Ÿéš›ã®å¤‰æ›´ãªã—ï¼‰
  --scope <name>  ç‰¹å®šã‚¹ã‚³ãƒ¼ãƒ—ã®ã¿å®Ÿè¡Œï¼ˆtables/indexes/logsï¼‰
  --throttle <n>  æ“ä½œé–“ã®å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 5ï¼‰
  --no-lock       ãƒ­ãƒƒã‚¯åˆ¶å¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆç·Šæ€¥æ™‚ã®ã¿ï¼‰
  --output <fmt>  å‡ºåŠ›å½¢å¼ï¼ˆjson|textã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: textï¼‰
  -v, --verbose   è©³ç´°ãƒ­ã‚°å‡ºåŠ›
  -h, --help      ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤º

ä¾‹:
  $0 --dry-run all                    # å…¨æ“ä½œã®ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³
  $0 --throttle 10 vacuum backup      # VACUUMâ†’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆ10ç§’é–“éš”ï¼‰
  $0 --scope tables vacuum            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿VACUUM
  $0 --output json monitor            # ç›£è¦–çµæœã‚’JSONå‡ºåŠ›

çµ±åˆå…ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ:
  - db-maintenance-scheduler.sh (PostgreSQLä¿å®ˆ)
  - archive-wal.sh (WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–)
  - setup-backup-cron.sh (ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š)

o3æ¨å¥¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½:
  - flock(1)ã«ã‚ˆã‚‹å˜ä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å®Ÿè¡Œåˆ¶å¾¡
  - æ®µéšçš„å®Ÿè¡Œï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã®ç‹¬ç«‹ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼‰
  - PostgreSQLæ¥ç¶šãƒ—ãƒ¼ãƒ«åˆ¶å¾¡
  - æ§‹é€ åŒ–ãƒ­ã‚° + syslogç›£è¦–é€£æº
EOF
}

# o3æ¨å¥¨: PIDãƒ™ãƒ¼ã‚¹å˜ä¸€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å®Ÿè¡Œåˆ¶å¾¡ï¼ˆflockã®ä»£æ›¿ï¼‰
acquire_lock() {
    local lock_file="/tmp/db_unified_maintenance.lock"
    local operation=${1:-"maintenance"}
    local timeout=300  # 5åˆ†
    
    # æ—¢å­˜ãƒ­ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    if [ -f "$lock_file" ]; then
        local lock_pid=$(cat "$lock_file" 2>/dev/null || echo "")
        if [ -n "$lock_pid" ] && kill -0 "$lock_pid" 2>/dev/null; then
            log_structured "ERROR" "$operation" "Another maintenance instance is running" "{\"lock_pid\":\"$lock_pid\"}"
            exit 1
        else
            log_structured "WARN" "$operation" "Stale lock file removed" "{\"old_pid\":\"$lock_pid\"}"
            rm -f "$lock_file"
        fi
    fi
    
    # æ–°ã—ã„ãƒ­ãƒƒã‚¯ä½œæˆ
    echo $$ > "$lock_file"
    log_structured "INFO" "$operation" "Lock acquired successfully" "{\"pid\":$$}"
}

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç¢ºèª
verify_db_connection() {
    local operation=${1:-"connection"}
    
    if ! psql -d "$DB_NAME" -c "SELECT 1;" >/dev/null 2>&1; then
        log_structured "ERROR" "$operation" "Database connection failed" "{\"database\":\"$DB_NAME\"}"
        return 1
    fi
    
    log_structured "INFO" "$operation" "Database connection verified" "{\"database\":\"$DB_NAME\"}"
    return 0
}

# o3æ¨å¥¨: æ®µéšçš„VACUUMå®Ÿè¡Œï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«æ¯ã«åˆ†å‰²ï¼‰
execute_vacuum_analyze() {
    local dry_run=${1:-false}
    local scope=${2:-all}
    local throttle=${3:-5}
    
    log_structured "INFO" "vacuum" "Starting vacuum and analyze operations" "{\"scope\":\"$scope\",\"throttle\":$throttle}"
    
    if [ "$dry_run" = "true" ]; then
        log_structured "INFO" "vacuum" "[DRY-RUN] Would execute VACUUM ANALYZE on all tables"
        return 0
    fi
    
    if ! verify_db_connection "vacuum"; then
        return 1
    fi
    
    local tables=()
    case $scope in
        "all"|"tables")
            tables=("context_stream" "mistakes_database" "document_intelligence" "session_memory" "learning_signals")
            ;;
        "context")
            tables=("context_stream")
            ;;
        "logs")
            tables=("mistakes_database" "learning_signals")
            ;;
        *)
            log_structured "ERROR" "vacuum" "Invalid scope specified" "{\"scope\":\"$scope\"}"
            return 1
            ;;
    esac
    
    local vacuum_success=0
    local vacuum_total=${#tables[@]}
    
    for table in "${tables[@]}"; do
        log_structured "INFO" "vacuum" "Processing table: $table"
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«æ¯ã«å€‹åˆ¥å®Ÿè¡Œï¼ˆã‚¨ãƒ©ãƒ¼ç¶™ç¶šï¼‰
        if psql -d "$DB_NAME" -c "VACUUM (ANALYZE, VERBOSE) $table;" 2>/dev/null; then
            ((vacuum_success++))
            log_structured "INFO" "vacuum" "Table vacuum completed" "{\"table\":\"$table\",\"status\":\"success\"}"
        else
            log_structured "WARN" "vacuum" "Table vacuum failed" "{\"table\":\"$table\",\"status\":\"failed\"}"
        fi
        
        sleep "$throttle"
    done
    
    # çµæœãƒ­ã‚°è¨˜éŒ²
    psql -d "$DB_NAME" -c "
        INSERT INTO maintenance_log 
        (operation_type, table_name, status, details, completed_at) 
        VALUES ('vacuum', 'multiple', 'completed', '{\"success\":$vacuum_success,\"total\":$vacuum_total}'::jsonb, NOW())
    " 2>/dev/null || true
    
    log_structured "INFO" "vacuum" "Vacuum operations completed" "{\"success\":$vacuum_success,\"total\":$vacuum_total}"
    
    return 0
}

# o3æ¨å¥¨: ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œï¼ˆä¸–ä»£ç®¡ç†ä»˜ãï¼‰
execute_full_backup() {
    local dry_run=${1:-false}
    local retention_days=${2:-7}
    
    log_structured "INFO" "backup" "Starting full database backup" "{\"retention_days\":$retention_days}"
    
    if [ "$dry_run" = "true" ]; then
        log_structured "INFO" "backup" "[DRY-RUN] Would create compressed backup with pg_dump"
        log_structured "INFO" "backup" "[DRY-RUN] Would clean backups older than $retention_days days"
        return 0
    fi
    
    if ! verify_db_connection "backup"; then
        return 1
    fi
    
    local backup_file="$BACKUP_DIR/coding_rule2_ai_$(date +%Y%m%d_%H%M%S).sql"
    local start_time=$(date +%s)
    
    # pg_dumpå®Ÿè¡Œï¼ˆåœ§ç¸®ä»˜ãï¼‰
    log_structured "INFO" "backup" "Creating database backup" "{\"file\":\"$backup_file\"}"
    
    if pg_dump "$DB_NAME" | gzip > "${backup_file}.gz" 2>/dev/null; then
        local end_time=$(date +%s)
        local duration=$((end_time - start_time))
        local backup_size=$(du -h "${backup_file}.gz" 2>/dev/null | cut -f1 || echo "unknown")
        
        log_structured "INFO" "backup" "Backup completed successfully" "{\"file\":\"${backup_file}.gz\",\"size\":\"$backup_size\",\"duration\":$duration}"
        
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ¤œè¨¼
        if gzip -t "${backup_file}.gz" 2>/dev/null; then
            log_structured "INFO" "backup" "Backup integrity verified"
        else
            log_structured "WARN" "backup" "Backup integrity check failed"
        fi
        
        # ä¸–ä»£ç®¡ç†ï¼ˆå¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤ï¼‰
        local deleted_count=$(find "$BACKUP_DIR" -name "coding_rule2_ai_*.sql.gz" -mtime +$retention_days -delete -print | wc -l)
        if [ "$deleted_count" -gt 0 ]; then
            log_structured "INFO" "backup" "Old backups cleaned up" "{\"deleted_count\":$deleted_count}"
        fi
        
        # ãƒ­ã‚°è¨˜éŒ²
        psql -d "$DB_NAME" -c "
            INSERT INTO maintenance_log 
            (operation_type, table_name, status, details, completed_at) 
            VALUES ('backup', 'database', 'completed', '{\"file\":\"${backup_file}.gz\",\"size\":\"$backup_size\",\"duration\":$duration}'::jsonb, NOW())
        " 2>/dev/null || true
        
        return 0
    else
        log_structured "ERROR" "backup" "Backup creation failed" "{\"file\":\"$backup_file\"}"
        
        # å¤±æ•—ãƒ­ã‚°è¨˜éŒ²
        psql -d "$DB_NAME" -c "
            INSERT INTO maintenance_log 
            (operation_type, table_name, status, details, completed_at) 
            VALUES ('backup', 'database', 'failed', '{\"error\":\"pg_dump_failed\"}'::jsonb, NOW())
        " 2>/dev/null || true
        
        return 1
    fi
}

# o3æ¨å¥¨: WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè¡Œï¼ˆPITRå¯¾å¿œï¼‰
execute_wal_archive() {
    local dry_run=${1:-false}
    local wal_path=${2:-}
    local wal_file=${3:-}
    
    # PostgreSQLã®archive_commandã‹ã‚‰å‘¼ã°ã‚Œã‚‹å ´åˆã®å¼•æ•°å‡¦ç†
    if [ -n "$wal_path" ] && [ -n "$wal_file" ]; then
        log_structured "INFO" "archive" "WAL archive request" "{\"wal_path\":\"$wal_path\",\"wal_file\":\"$wal_file\"}"
        
        if [ "$dry_run" = "true" ]; then
            log_structured "INFO" "archive" "[DRY-RUN] Would archive WAL file"
            return 0
        fi
        
        # WALãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å®Ÿè¡Œ
        if cp "$wal_path" "$WAL_ARCHIVE_DIR/$wal_file" 2>/dev/null; then
            # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¤œè¨¼
            if [ -f "$WAL_ARCHIVE_DIR/$wal_file" ]; then
                echo "$(date -Iseconds): Archived $wal_file" >> "$WAL_ARCHIVE_DIR/archive.log"
                log_structured "INFO" "archive" "WAL file archived successfully" "{\"wal_file\":\"$wal_file\"}"
                return 0
            fi
        fi
        
        echo "$(date -Iseconds): Failed to archive $wal_file" >> "$WAL_ARCHIVE_DIR/archive.log"
        log_structured "ERROR" "archive" "WAL archive failed" "{\"wal_file\":\"$wal_file\"}"
        return 1
    else
        # æ‰‹å‹•å®Ÿè¡Œã®å ´åˆï¼ˆã‚¢ãƒ¼ã‚«ã‚¤ãƒ–çŠ¶æ³ç¢ºèªï¼‰
        log_structured "INFO" "archive" "Checking WAL archive status"
        
        if [ "$dry_run" = "true" ]; then
            log_structured "INFO" "archive" "[DRY-RUN] Would check archive status and cleanup old WAL files"
            return 0
        fi
        
        # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèª
        local archived_count=$(find "$WAL_ARCHIVE_DIR" -name "*.wal" -o -name "*[0-9A-F][0-9A-F][0-9A-F][0-9A-F][0-9A-F][0-9A-F][0-9A-F][0-9A-F]" | wc -l)
        local archive_size=$(du -sh "$WAL_ARCHIVE_DIR" 2>/dev/null | cut -f1 || echo "unknown")
        
        log_structured "INFO" "archive" "WAL archive status" "{\"archived_files\":$archived_count,\"total_size\":\"$archive_size\"}"
        
        # å¤ã„WALãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆ7æ—¥ä»¥ä¸Šå‰ï¼‰
        local deleted_wal=$(find "$WAL_ARCHIVE_DIR" -type f -mtime +7 -delete -print | wc -l)
        if [ "$deleted_wal" -gt 0 ]; then
            log_structured "INFO" "archive" "Old WAL files cleaned up" "{\"deleted_count\":$deleted_wal}"
        fi
        
        return 0
    fi
}

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
execute_performance_monitor() {
    local dry_run=${1:-false}
    local output_format=${2:-text}
    
    log_structured "INFO" "monitor" "Starting performance monitoring"
    
    if [ "$dry_run" = "true" ]; then
        log_structured "INFO" "monitor" "[DRY-RUN] Would collect database performance metrics"
        return 0
    fi
    
    if ! verify_db_connection "monitor"; then
        return 1
    fi
    
    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
    local db_size=$(psql -d "$DB_NAME" -t -c "SELECT pg_size_pretty(pg_database_size('$DB_NAME'));" 2>/dev/null | xargs || echo "unknown")
    local context_records=$(psql -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM context_stream;" 2>/dev/null | xargs || echo "0")
    local mistake_records=$(psql -d "$DB_NAME" -t -c "SELECT COUNT(*) FROM mistakes_database;" 2>/dev/null | xargs || echo "0")
    local avg_learning_weight=$(psql -d "$DB_NAME" -t -c "SELECT ROUND(AVG(learning_weight)::numeric, 3) FROM context_stream WHERE created_at > NOW() - INTERVAL '24 hours';" 2>/dev/null | xargs || echo "0")
    
    # ä½é€Ÿã‚¯ã‚¨ãƒªæ¤œå‡º
    local slow_queries=$(psql -d "$DB_NAME" -t -c "
        SELECT COUNT(*) FROM pg_stat_statements 
        WHERE mean_exec_time > 1000;" 2>/dev/null | xargs || echo "0")
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹JSONç”Ÿæˆ
    local metrics_json="{\"database_size\":\"$db_size\",\"context_records\":$context_records,\"mistake_records\":$mistake_records,\"avg_learning_weight\":$avg_learning_weight,\"slow_queries\":$slow_queries}"
    
    log_structured "INFO" "monitor" "Performance metrics collected" "$metrics_json"
    
    # ç›£è¦–ãƒ­ã‚°è¨˜éŒ²
    psql -d "$DB_NAME" -c "
        INSERT INTO maintenance_log 
        (operation_type, table_name, status, details, completed_at) 
        VALUES ('monitor', 'database', 'completed', '$metrics_json'::jsonb, NOW())
    " 2>/dev/null || true
    
    if [ "$output_format" = "json" ]; then
        echo "$metrics_json"
    else
        echo "ğŸ“Š DBç›£è¦–å®Œäº†: ã‚µã‚¤ã‚º $db_size, ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ $context_records, ãƒŸã‚¹ $mistake_records"
    fi
    
    return 0
}

# ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–ï¼ˆå…ƒdb-maintenance-scheduler.shæ©Ÿèƒ½ï¼‰
execute_vector_optimization() {
    local dry_run=${1:-false}
    local throttle=${2:-5}
    
    log_structured "INFO" "vector" "Starting vector index optimization"
    
    if [ "$dry_run" = "true" ]; then
        log_structured "INFO" "vector" "[DRY-RUN] Would reindex vector indexes concurrently"
        return 0
    fi
    
    if ! verify_db_connection "vector"; then
        return 1
    fi
    
    # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹çµ±è¨ˆå–å¾—
    local vector_stats=$(psql -d "$DB_NAME" -t -c "
        SELECT COUNT(*) FROM pg_stat_user_indexes 
        WHERE indexname LIKE '%vector%';" 2>/dev/null | xargs || echo "0")
    
    if [ "$vector_stats" -eq 0 ]; then
        log_structured "WARN" "vector" "No vector indexes found"
        return 0
    fi
    
    # REINDEXã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œï¼ˆCONCURRENTLYã§éãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
    local reindex_commands=(
        "REINDEX INDEX CONCURRENTLY IF EXISTS idx_context_stream_vector_cosine"
        "REINDEX INDEX CONCURRENTLY IF EXISTS idx_context_stream_vector_l2"
        "REINDEX INDEX CONCURRENTLY IF EXISTS idx_context_stream_vector_recall"
    )
    
    local reindex_success=0
    for cmd in "${reindex_commands[@]}"; do
        if psql -d "$DB_NAME" -c "$cmd;" 2>/dev/null; then
            ((reindex_success++))
            log_structured "INFO" "vector" "Vector index reindexed" "{\"command\":\"$cmd\"}"
        else
            log_structured "WARN" "vector" "Vector index reindex failed" "{\"command\":\"$cmd\"}"
        fi
        sleep "$throttle"
    done
    
    # çµæœãƒ­ã‚°è¨˜éŒ²
    psql -d "$DB_NAME" -c "
        INSERT INTO maintenance_log 
        (operation_type, table_name, status, details, completed_at) 
        VALUES ('reindex', 'context_stream', 'completed', '{\"indexes\":[\"vector_cosine\",\"vector_l2\",\"vector_recall\"],\"success\":$reindex_success}'::jsonb, NOW())
    " 2>/dev/null || true
    
    log_structured "INFO" "vector" "Vector optimization completed" "{\"reindexed\":$reindex_success,\"total\":${#reindex_commands[@]}}"
    
    return 0
}

# ãƒ¡ãƒ¢ãƒªç¶™æ‰¿ã‚·ã‚¹ãƒ†ãƒ å¼·åŒ–ï¼ˆå…ƒdb-maintenance-scheduler.shæ©Ÿèƒ½ï¼‰
execute_inheritance_enhancement() {
    local dry_run=${1:-false}
    
    log_structured "INFO" "inheritance" "Starting memory inheritance enhancement"
    
    if [ "$dry_run" = "true" ]; then
        log_structured "INFO" "inheritance" "[DRY-RUN] Would enhance memory inheritance cross-references"
        return 0
    fi
    
    if ! verify_db_connection "inheritance"; then
        return 1
    fi
    
    # é«˜ä¾¡å€¤ãƒ¡ãƒ¢ãƒªã®å¼·åŒ–
    local enhanced_count=$(psql -d "$DB_NAME" -t -c "
        UPDATE context_stream 
        SET metadata = jsonb_set(
            COALESCE(metadata, '{}'), 
            '{inheritance_enhanced}', 
            'true'
        )
        WHERE 
            salience_score > 0.7
            AND metadata->>'inheritance_enhanced' IS NULL;
        SELECT ROW_COUNT();
    " 2>/dev/null | xargs || echo "0")
    
    log_structured "INFO" "inheritance" "High-value memories enhanced" "{\"enhanced_count\":$enhanced_count}"
    
    # ã‚¯ãƒ­ã‚¹ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹æ§‹ç¯‰
    local cross_ref_count=$(psql -d "$DB_NAME" -t -c "
        WITH updates AS (
            UPDATE context_stream cs1
            SET cross_references = array_append(
                COALESCE(cs1.cross_references, '{}'), 
                cs2.id
            )
            FROM context_stream cs2
            WHERE 
                cs1.id != cs2.id
                AND cs1.salience_score > 0.6
                AND cs2.salience_score > 0.6
                AND array_length(cs1.cross_references, 1) < 5
                AND NOT (cs2.id = ANY(COALESCE(cs1.cross_references, '{}')))
            RETURNING cs1.id
        )
        SELECT COUNT(*) FROM updates;
    " 2>/dev/null | xargs || echo "0")
    
    log_structured "INFO" "inheritance" "Cross-references built" "{\"cross_ref_count\":$cross_ref_count}"
    
    # çµæœãƒ­ã‚°è¨˜éŒ²
    psql -d "$DB_NAME" -c "
        INSERT INTO maintenance_log 
        (operation_type, table_name, status, details, completed_at) 
        VALUES ('inheritance', 'context_stream', 'completed', '{\"enhanced\":$enhanced_count,\"cross_references\":$cross_ref_count}'::jsonb, NOW())
    " 2>/dev/null || true
    
    return 0
}

# ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ›´æ–°ï¼ˆå…ƒdb-maintenance-scheduler.shæ©Ÿèƒ½ï¼‰
execute_embeddings_update() {
    local dry_run=${1:-false}
    
    log_structured "INFO" "embeddings" "Starting embedding version update"
    
    if [ "$dry_run" = "true" ]; then
        log_structured "INFO" "embeddings" "[DRY-RUN] Would update embedding model versions"
        return 0
    fi
    
    if ! verify_db_connection "embeddings"; then
        return 1
    fi
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ãªã—ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ç¢ºèª
    local unversioned_count=$(psql -d "$DB_NAME" -t -c "
        SELECT COUNT(*) FROM context_stream 
        WHERE embedding_model IS NULL OR embedding_version IS NULL;" 2>/dev/null | xargs || echo "0")
    
    if [ "$unversioned_count" -eq 0 ]; then
        log_structured "INFO" "embeddings" "All embeddings have version info"
        return 0
    fi
    
    # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ›´æ–°
    local updated_count=$(psql -d "$DB_NAME" -t -c "
        UPDATE context_stream 
        SET 
            embedding_model = 'text-embedding-ada-002',
            embedding_version = 'v1',
            embedding_hash = md5(vector_embedding::text)
        WHERE embedding_model IS NULL OR embedding_version IS NULL;
        SELECT ROW_COUNT();
    " 2>/dev/null | xargs || echo "0")
    
    log_structured "INFO" "embeddings" "Embedding versions updated" "{\"updated_count\":$updated_count}"
    
    # çµæœãƒ­ã‚°è¨˜éŒ²
    psql -d "$DB_NAME" -c "
        INSERT INTO maintenance_log 
        (operation_type, table_name, status, details, completed_at) 
        VALUES ('update', 'context_stream', 'completed', '{\"updated_records\":$updated_count}'::jsonb, NOW())
    " 2>/dev/null || true
    
    return 0
}

# cronã‚¸ãƒ§ãƒ–ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ï¼ˆå…ƒsetup-backup-cron.shæ©Ÿèƒ½ï¼‰
execute_cron_setup() {
    local dry_run=${1:-false}
    
    log_structured "INFO" "setup" "Setting up automated maintenance cron jobs"
    
    if [ "$dry_run" = "true" ]; then
        log_structured "INFO" "setup" "[DRY-RUN] Would install cron jobs for automated maintenance"
        return 0
    fi
    
    local temp_cron=$(mktemp)
    local this_script="$PROJECT_ROOT/scripts/maintenance/db-unified-maintenance.sh"
    
    # æ—¢å­˜cronä¿æŒ
    crontab -l 2>/dev/null > "$temp_cron" || true
    
    # æ—¢å­˜ã®DBä¿å®ˆã‚¸ãƒ§ãƒ–å‰Šé™¤ï¼ˆé‡è¤‡å›é¿ï¼‰
    grep -v "db-maintenance-scheduler.sh\|db-unified-maintenance.sh" "$temp_cron" > "${temp_cron}.tmp" || true
    mv "${temp_cron}.tmp" "$temp_cron"
    
    # çµ±åˆä¿å®ˆã‚¸ãƒ§ãƒ–è¿½åŠ 
    cat >> "$temp_cron" << EOF
# AI Database Unified Maintenance Jobs (Generated by db-unified-maintenance.sh)
0 2 * * * $this_script backup >/dev/null 2>&1
0 3 * * 0 $this_script vector >/dev/null 2>&1
0 4 * * * $this_script vacuum >/dev/null 2>&1
0 * * * * $this_script monitor >/dev/null 2>&1
0 1 * * * $this_script embeddings >/dev/null 2>&1
0 5 * * * $this_script inheritance >/dev/null 2>&1
0 6 * * * $this_script archive >/dev/null 2>&1
EOF
    
    # cronã‚¸ãƒ§ãƒ– ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    if crontab "$temp_cron" 2>/dev/null; then
        rm "$temp_cron"
        log_structured "INFO" "setup" "Cron jobs installed successfully" "{\"script\":\"$this_script\"}"
        
        echo "âœ… è‡ªå‹•ä¿å®ˆcronã‚¸ãƒ§ãƒ–ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ãŸ:"
        echo "  â€¢ 02:00 daily - ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"
        echo "  â€¢ 03:00 weekly(æ—¥æ›œ) - ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–"
        echo "  â€¢ 04:00 daily - VACUUMãƒ»ANALYZE"
        echo "  â€¢ æ¯æ™‚00åˆ† - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–"
        echo "  â€¢ 01:00 daily - ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ›´æ–°"
        echo "  â€¢ 05:00 daily - ãƒ¡ãƒ¢ãƒªç¶™æ‰¿å¼·åŒ–"
        echo "  â€¢ 06:00 daily - WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ç¢ºèª"
        
        return 0
    else
        rm "$temp_cron"
        log_structured "ERROR" "setup" "Failed to install cron jobs"
        return 1
    fi
}

# o3æ¨å¥¨: å…¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å®Ÿè¡Œï¼ˆæ’ä»–åˆ¶å¾¡ä»˜ãï¼‰
execute_all_maintenance() {
    local dry_run=${1:-false}
    local throttle=${2:-10}
    local scope=${3:-all}
    
    log_structured "INFO" "all" "Starting comprehensive database maintenance" "{\"throttle\":$throttle,\"scope\":\"$scope\"}"
    
    # å®Ÿè¡Œé †åºï¼ˆo3æ¨å¥¨ï¼šãƒ‡ãƒ¼ã‚¿å½±éŸ¿ã®å°‘ãªã„é †ï¼‰
    local operations=(
        "monitor"
        "embeddings"
        "inheritance"
        "vector"
        "vacuum"
        "backup"
        "archive"
    )
    
    local success_count=0
    local total_count=${#operations[@]}
    
    for operation in "${operations[@]}"; do
        log_structured "INFO" "all" "Executing operation: $operation"
        
        case $operation in
            "monitor")
                execute_performance_monitor "$dry_run" "text"
                ;;
            "embeddings")
                execute_embeddings_update "$dry_run"
                ;;
            "inheritance")
                execute_inheritance_enhancement "$dry_run"
                ;;
            "vector")
                execute_vector_optimization "$dry_run" "$throttle"
                ;;
            "vacuum")
                execute_vacuum_analyze "$dry_run" "$scope" "$throttle"
                ;;
            "backup")
                execute_full_backup "$dry_run" 7
                ;;
            "archive")
                execute_wal_archive "$dry_run"
                ;;
        esac
        
        local exit_code=$?
        if [ $exit_code -eq 0 ]; then
            ((success_count++))
            log_structured "INFO" "all" "Operation completed successfully" "{\"operation\":\"$operation\"}"
        else
            log_structured "WARN" "all" "Operation failed" "{\"operation\":\"$operation\",\"exit_code\":$exit_code}"
        fi
        
        # o3æ¨å¥¨ï¼šæ“ä½œé–“ã®é–“éš”èª¿æ•´
        sleep "$throttle"
    done
    
    log_structured "INFO" "all" "Comprehensive maintenance completed" "{\"success\":$success_count,\"total\":$total_count}"
    
    echo "ğŸ¯ å…¨DBä¿å®ˆå®Œäº†: $success_count/$total_count æˆåŠŸ"
    
    return 0
}

# o3æ¨å¥¨: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©
cleanup() {
    local exit_code=$?
    if [ $exit_code -ne 0 ]; then
        log_structured "ERROR" "main" "Script failed with exit code $exit_code"
    fi
    
    # ãƒ­ãƒƒã‚¯è§£æ”¾
    rm -f /tmp/db_unified_maintenance.lock 2>/dev/null || true
}

trap cleanup EXIT ERR INT TERM

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
main() {
    local operations=()
    local dry_run=false
    local scope="all"
    local throttle=5
    local no_lock=false
    local output_format="text"
    local verbose=false
    
    # å¼•æ•°è§£æ
    while [[ $# -gt 0 ]]; do
        case $1 in
            --dry-run)
                dry_run=true
                shift
                ;;
            --scope)
                scope="$2"
                shift 2
                ;;
            --throttle)
                throttle="$2"
                shift 2
                ;;
            --no-lock)
                no_lock=true
                shift
                ;;
            --output)
                output_format="$2"
                shift 2
                ;;
            -v|--verbose)
                verbose=true
                shift
                ;;
            -h|--help)
                show_usage
                exit 0
                ;;
            vacuum|backup|archive|monitor|vector|inheritance|embeddings|setup-cron|all)
                operations+=("$1")
                shift
                ;;
            *)
                echo "ã‚¨ãƒ©ãƒ¼: ä¸æ˜ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³ $1" >&2
                show_usage
                exit 1
                ;;
        esac
    done
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ“ä½œ
    if [ ${#operations[@]} -eq 0 ]; then
        operations=("all")
    fi
    
    # o3æ¨å¥¨: ãƒ­ãƒƒã‚¯å–å¾—ï¼ˆ--no-lockã§ã‚¹ã‚­ãƒƒãƒ—å¯èƒ½ï¼‰
    if [ "$no_lock" = "false" ]; then
        acquire_lock "${operations[0]}"
    fi
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
    if [ "$verbose" = "true" ]; then
        log_structured "INFO" "main" "Database Unified Maintenance System v1.0" "{\"operations\":[\"$(IFS=,; echo "${operations[*]}")\"],\"dry_run\":$dry_run}"
    fi
    
    # æ“ä½œå®Ÿè¡Œ
    for operation in "${operations[@]}"; do
        case $operation in
            vacuum)
                execute_vacuum_analyze "$dry_run" "$scope" "$throttle"
                ;;
            backup)
                execute_full_backup "$dry_run" 7
                ;;
            archive)
                execute_wal_archive "$dry_run"
                ;;
            monitor)
                execute_performance_monitor "$dry_run" "$output_format"
                ;;
            vector)
                execute_vector_optimization "$dry_run" "$throttle"
                ;;
            inheritance)
                execute_inheritance_enhancement "$dry_run"
                ;;
            embeddings)
                execute_embeddings_update "$dry_run"
                ;;
            setup-cron)
                execute_cron_setup "$dry_run"
                ;;
            all)
                execute_all_maintenance "$dry_run" "$throttle" "$scope"
                ;;
        esac
        
        # è¤‡æ•°æ“ä½œã®å ´åˆã¯é–“éš”èª¿æ•´
        if [ ${#operations[@]} -gt 1 ]; then
            sleep "$throttle"
        fi
    done
}

# archive_commandã‹ã‚‰ç›´æ¥å‘¼ã°ã‚Œã‚‹å ´åˆã®ç‰¹åˆ¥å‡¦ç†
if [ "$1" = "--archive-command" ] && [ $# -eq 3 ]; then
    shift  # --archive-commandã‚’é™¤å»
    execute_wal_archive false "$1" "$2"
    exit $?
fi

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒç›´æ¥å®Ÿè¡Œã•ã‚ŒãŸå ´åˆ
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi