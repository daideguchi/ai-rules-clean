#!/usr/bin/env python3
"""
å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ 
======================

å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã¨å¾©æ—§å¿…è¦åˆ†ã®ç‰¹å®š
"""

import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


class DeletionVerification:
    """å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.project_root = project_root
        self.backup_dir = self.project_root / "runtime" / "config_backups"
        self.verification_report = (
            self.project_root / "runtime" / "deletion_verification_report.json"
        )

        # å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®è¨˜éŒ²
        self.deleted_files = {
            "cleaned_files": [
                "test/ai_learning_test.py",
                "runtime/dynamic_mode_test.py",
                "tests/integration_test.py",
                "src/ai/apply_autonomous_fix.py",
                "scripts/setup/quick_api_setup.py",
                "scripts/setup/cloudflare_zero_trust_setup.py",
                "scripts/setup/complete_setup.py",
                "scripts/setup/n8n_auto_setup.py",
                "scripts/setup/supabase_rls_auto_setup.py",
                "scripts/setup/n8n_supabase_debug.py",
                "scripts/setup/simple_n8n_setup.py",
                "scripts/autonomous/supabase_setup.py",
                "tests/integration/test_supabase_final.py",
            ],
            "virtual_env_files": [".venv/", "venv/"],
            "log_files": [
                "runtime/logs/",
                "logs/",
                "runtime/session_violations.log",
                "runtime/president_declaration.log",
                "runtime/template_integrity/",
                "runtime/instruction_logs/",
                "runtime/compression_events.log",
            ],
            "config_files": [
                "config/.mcp.json",
                "config/security/api_keys.json",
                "config/security/rbac_config.json",
                "config/integrations/integration_config.json",
                "config/claude-settings-envvar.json",
                "runtime/log_management_config.json",
                "runtime/mistakes/mistake_config.json",
                "runtime/unified_interceptor_config.json",
            ],
            "duplicate_files": [
                "scripts/setup/n8n_debug_execution.py",
                "scripts/setup/n8n_detailed_error_analysis.py",
                "scripts/setup/n8n_fix_http_node.py",
                "scripts/setup/n8n_debug_webhook.py",
                "scripts/setup/n8n_detailed_error.py",
                "scripts/setup/n8n_full_debug.py",
                "scripts/setup/n8n_create_simple_workflow.py",
                "scripts/setup/n8n_recreate_simple_workflow.py",
                "scripts/setup/ultimate_n8n_solution.py",
                "scripts/setup/hybrid_ultimate_solution.py",
                "scripts/setup/ultimate_solution.py",
                "scripts/setup/hybrid-final.py",
                "scripts/setup/create_working_final_workflow.py",
                "scripts/setup/n8n_complete_rebuild.py",
                "scripts/setup/final_production_test.sh",
                "scripts/setup/final_zero_trust_setup.sh",
            ],
        }

        # é‡è¦åº¦åˆ†é¡
        self.importance_levels = {
            "critical": [
                "src/conductor/core.py",
                "src/enforcement/reference_monitor.py",
                "src/memory/user_prompt_recorder.py",
                "scripts/tools/unified-president-tool.py",
                "CLAUDE.md",
                "Makefile",
            ],
            "high": [
                "src/ai/constitutional_ai.py",
                "src/enforcement/lightweight_president.py",
                "src/enforcement/escalation_system.py",
                "src/enforcement/hook_integration.py",
                "scripts/hooks/critical_failure_prevention.py",
            ],
            "medium": [
                "src/orchestrator/intelligent_project_analyzer.py",
                "scripts/automation/smart_ai_org_launcher.py",
                "config/unified_config.json",
                "src/config/config_loader.py",
            ],
            "low": ["tests/", "docs/", "scripts/setup/"],
        }

    def verify_critical_files(self) -> Dict[str, bool]:
        """é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª"""
        results = {}

        for importance, files in self.importance_levels.items():
            for file_path in files:
                full_path = self.project_root / file_path
                if full_path.is_file() or full_path.is_dir():
                    results[file_path] = True
                else:
                    results[file_path] = False
                    print(f"âŒ {importance.upper()} ãƒ•ã‚¡ã‚¤ãƒ«æ¬ æ: {file_path}")

        return results

    def analyze_deleted_files(self) -> Dict[str, any]:
        """å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ"""
        analysis = {
            "total_deleted": 0,
            "categories": {},
            "recovery_needed": [],
            "safe_deletions": [],
        }

        for category, files in self.deleted_files.items():
            analysis["categories"][category] = {"count": len(files), "files": files}
            analysis["total_deleted"] += len(files)

            # å¾©æ—§å¿…è¦æ€§ã®åˆ¤å®š
            if category == "cleaned_files":
                for file_path in files:
                    if self._is_recovery_needed(file_path):
                        analysis["recovery_needed"].append(file_path)
                    else:
                        analysis["safe_deletions"].append(file_path)
            else:
                analysis["safe_deletions"].extend(files)

        return analysis

    def _is_recovery_needed(self, file_path: str) -> bool:
        """å¾©æ—§å¿…è¦æ€§ã®åˆ¤å®š"""
        # é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã¨ã®ç…§åˆ
        for _importance, files in self.importance_levels.items():
            if file_path in files or any(file_path.startswith(f) for f in files):
                return True

        # ç‰¹å®šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¢ºèª
        recovery_patterns = [
            "src/ai/constitutional_ai.py",
            "src/memory/",
            "src/enforcement/",
            "scripts/tools/",
            "config/",
        ]

        for pattern in recovery_patterns:
            if file_path.startswith(pattern):
                return True

        return False

    def check_backup_availability(self) -> Dict[str, bool]:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å¯ç”¨æ€§ç¢ºèª"""
        backup_status = {}

        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç¢ºèª
        for backup_file in self.backup_dir.glob("*.json"):
            backup_status[backup_file.name] = backup_file.exists()

        # Gitãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ç¢ºèª
        try:
            import subprocess

            result = subprocess.run(
                ["git", "log", "--oneline", "-n", "10"],
                capture_output=True,
                text=True,
                cwd=self.project_root,
            )
            backup_status["git_history"] = result.returncode == 0
        except Exception:
            backup_status["git_history"] = False

        return backup_status

    def generate_recovery_plan(self) -> Dict[str, any]:
        """å¾©æ—§è¨ˆç”»ã®ç”Ÿæˆ"""
        analysis = self.analyze_deleted_files()
        self.check_backup_availability()

        recovery_plan = {
            "immediate_actions": [],
            "medium_priority": [],
            "low_priority": [],
            "no_action_needed": [],
        }

        # å¾©æ—§å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†é¡
        for file_path in analysis["recovery_needed"]:
            if any(
                file_path.startswith(pattern)
                for pattern in ["src/ai/", "src/memory/", "src/enforcement/"]
            ):
                recovery_plan["immediate_actions"].append(
                    {
                        "file": file_path,
                        "reason": "Core system component",
                        "action": "Recreate from backup or git history",
                    }
                )
            elif file_path.startswith("scripts/tools/"):
                recovery_plan["medium_priority"].append(
                    {
                        "file": file_path,
                        "reason": "Important tooling",
                        "action": "Recreate if needed",
                    }
                )
            else:
                recovery_plan["low_priority"].append(
                    {
                        "file": file_path,
                        "reason": "Optional component",
                        "action": "Recreate only if required",
                    }
                )

        # å®‰å…¨ãªå‰Šé™¤ã®ç¢ºèª
        recovery_plan["no_action_needed"] = analysis["safe_deletions"]

        return recovery_plan

    def restore_from_backup(self, file_path: str) -> bool:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©æ—§"""
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å¾©æ—§
        for backup_file in self.backup_dir.glob("*.json"):
            if file_path in backup_file.name:
                try:
                    target_path = self.project_root / file_path
                    target_path.parent.mkdir(parents=True, exist_ok=True)

                    with open(backup_file) as src:
                        with open(target_path, "w") as dst:
                            dst.write(src.read())

                    print(f"âœ… å¾©æ—§å®Œäº†: {file_path}")
                    return True
                except Exception as e:
                    print(f"âŒ å¾©æ—§å¤±æ•—: {file_path} - {e}")
                    return False

        return False

    def run_verification(self) -> Dict[str, any]:
        """æ¤œè¨¼ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
        print("ğŸ” å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼é–‹å§‹")
        print("=" * 50)

        # 1. é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        print("\n1. é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª")
        critical_files = self.verify_critical_files()
        missing_critical = [f for f, exists in critical_files.items() if not exists]

        if missing_critical:
            print(f"âŒ é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«æ¬ æ: {len(missing_critical)}ä»¶")
            for file_path in missing_critical:
                print(f"  - {file_path}")
        else:
            print("âœ… é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã™ã¹ã¦å­˜åœ¨ã—ã¾ã™")

        # 2. å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ
        print("\n2. å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ")
        analysis = self.analyze_deleted_files()
        print(f"ğŸ“Š å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«ç·æ•°: {analysis['total_deleted']}")
        print(f"ğŸ”„ å¾©æ—§å¿…è¦: {len(analysis['recovery_needed'])}ä»¶")
        print(f"âœ… å®‰å…¨ãªå‰Šé™¤: {len(analysis['safe_deletions'])}ä»¶")

        # 3. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯ç”¨æ€§ç¢ºèª
        print("\n3. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯ç”¨æ€§ç¢ºèª")
        backup_status = self.check_backup_availability()
        available_backups = sum(backup_status.values())
        print(f"ğŸ’¾ åˆ©ç”¨å¯èƒ½ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {available_backups}ä»¶")

        # 4. å¾©æ—§è¨ˆç”»ç”Ÿæˆ
        print("\n4. å¾©æ—§è¨ˆç”»ç”Ÿæˆ")
        recovery_plan = self.generate_recovery_plan()
        print(f"ğŸš¨ å³åº§å¯¾å¿œ: {len(recovery_plan['immediate_actions'])}ä»¶")
        print(f"âš ï¸ ä¸­å„ªå…ˆ: {len(recovery_plan['medium_priority'])}ä»¶")
        print(f"â„¹ï¸ ä½å„ªå…ˆ: {len(recovery_plan['low_priority'])}ä»¶")
        print(f"âœ… å¯¾å¿œä¸è¦: {len(recovery_plan['no_action_needed'])}ä»¶")

        # 5. å³åº§å¯¾å¿œãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å¾©æ—§
        print("\n5. å³åº§å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«ã®å¾©æ—§")
        restored_count = 0
        for action in recovery_plan["immediate_actions"]:
            if self.restore_from_backup(action["file"]):
                restored_count += 1

        print(f"âœ… å¾©æ—§å®Œäº†: {restored_count}ä»¶")

        # çµæœãƒ¬ãƒãƒ¼ãƒˆ
        verification_result = {
            "verification_completed": True,
            "timestamp": datetime.now().isoformat(),
            "critical_files_status": critical_files,
            "missing_critical_files": missing_critical,
            "deletion_analysis": analysis,
            "backup_status": backup_status,
            "recovery_plan": recovery_plan,
            "restored_files": restored_count,
        }

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        with open(self.verification_report, "w") as f:
            json.dump(verification_result, f, indent=2)

        print(f"\nğŸ“ æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {self.verification_report}")

        return verification_result


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    verifier = DeletionVerification()

    try:
        result = verifier.run_verification()

        if result["missing_critical_files"]:
            print("\nâš ï¸ é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            print("ğŸ’¡ å¿…è¦ã«å¿œã˜ã¦å¾©æ—§ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        else:
            print("\nâœ… å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼å®Œäº†")
            print("ğŸ’¡ é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ã®æå¤±ã¯ã‚ã‚Šã¾ã›ã‚“")

    except Exception as e:
        print(f"\nâŒ æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())
