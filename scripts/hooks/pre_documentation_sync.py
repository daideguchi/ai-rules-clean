#!/usr/bin/env python3
"""
ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªå‹•åŒæœŸã‚·ã‚¹ãƒ†ãƒ 
ã‚³ãƒ¼ãƒ‰å¤‰æ›´æ™‚ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åŒæœŸçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ãƒ»è‡ªå‹•æ›´æ–°
"""

import hashlib
import json
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple

PROJECT_ROOT = Path(__file__).parent.parent.parent
SYNC_STATE_FILE = PROJECT_ROOT / "runtime" / "doc_sync_state.json"
DOCS_ROOT = PROJECT_ROOT / "docs"


class DocumentationSyncer:
    def __init__(self):
        self.project_root = PROJECT_ROOT
        self.sync_state = self._load_sync_state()

    def _load_sync_state(self) -> Dict:
        """åŒæœŸçŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        if SYNC_STATE_FILE.exists():
            with open(SYNC_STATE_FILE, encoding="utf-8") as f:
                return json.load(f)
        return {
            "version": "1.0",
            "last_sync": None,
            "file_hashes": {},
            "doc_mappings": {},
            "auto_sync_enabled": True,
        }

    def _save_sync_state(self):
        """åŒæœŸçŠ¶æ…‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜"""
        SYNC_STATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(SYNC_STATE_FILE, "w", encoding="utf-8") as f:
            json.dump(self.sync_state, f, indent=2, ensure_ascii=False)

    def _get_file_hash(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤è¨ˆç®—"""
        try:
            with open(file_path, "rb") as f:
                return hashlib.md5(f.read()).hexdigest()
        except Exception:
            return ""

    def _get_git_changed_files(self) -> List[str]:
        """Gitå¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—"""
        try:
            result = subprocess.run(
                ["git", "diff", "--cached", "--name-only"],
                cwd=self.project_root,
                capture_output=True,
                text=True,
            )
            return result.stdout.strip().split("\n") if result.stdout.strip() else []
        except Exception:
            return []

    def _find_related_docs(self, source_file: str) -> List[Path]:
        """ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã«é–¢é€£ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç™ºè¦‹"""
        related_docs = []
        file_stem = Path(source_file).stem

        # 1. ç›´æ¥å‘½åé–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
        for doc_file in DOCS_ROOT.rglob("*.md"):
            if file_stem.lower() in doc_file.stem.lower():
                related_docs.append(doc_file)

        # 2. å†…å®¹å‚ç…§é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
        try:
            result = subprocess.run(
                ["grep", "-r", "-l", file_stem, str(DOCS_ROOT)],
                capture_output=True,
                text=True,
            )
            for line in result.stdout.strip().split("\n"):
                if line and line.endswith(".md"):
                    related_docs.append(Path(line))
        except Exception:
            pass

        return list(set(related_docs))

    def _check_doc_staleness(self, doc_path: Path) -> Tuple[bool, str]:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®é™³è…åŒ–ãƒã‚§ãƒƒã‚¯"""
        if not doc_path.exists():
            return True, "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå­˜åœ¨ã—ã¾ã›ã‚“"

        # æœ€çµ‚æ›´æ–°æ—¥ãƒã‚§ãƒƒã‚¯
        doc_mtime = doc_path.stat().st_mtime
        week_ago = datetime.now().timestamp() - (7 * 24 * 3600)

        if doc_mtime < week_ago:
            return (
                True,
                f"7æ—¥ä»¥ä¸Šæ›´æ–°ã•ã‚Œã¦ã„ã¾ã›ã‚“ ({datetime.fromtimestamp(doc_mtime).strftime('%Y-%m-%d')})",
            )

        # ãƒãƒƒã‚·ãƒ¥å¤‰æ›´ãƒã‚§ãƒƒã‚¯
        current_hash = self._get_file_hash(doc_path)
        stored_hash = self.sync_state["file_hashes"].get(str(doc_path), "")

        if current_hash != stored_hash:
            return False, "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯æœ€æ–°ã§ã™"

        return True, "é–¢é€£ã‚³ãƒ¼ãƒ‰ãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸãŒã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯æœªæ›´æ–°ã§ã™"

    def _auto_update_doc_header(self, doc_path: Path):
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã®è‡ªå‹•æ›´æ–°"""
        try:
            with open(doc_path, encoding="utf-8") as f:
                content = f.read()

            # æ›´æ–°æ—¥æ™‚ãƒ˜ãƒƒãƒ€ãƒ¼ã®è¿½åŠ ãƒ»æ›´æ–°
            current_date = datetime.now().strftime("%Y-%m-%d")

            if "**æœ€çµ‚æ›´æ–°**:" in content:
                # æ—¢å­˜ã®æ›´æ–°æ—¥ã‚’ç½®æ›
                import re

                content = re.sub(
                    r"\*\*æœ€çµ‚æ›´æ–°\*\*: \d{4}-\d{2}-\d{2}",
                    f"**æœ€çµ‚æ›´æ–°**: {current_date}",
                    content,
                )
            else:
                # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
                lines = content.split("\n")
                if lines and lines[0].startswith("#"):
                    lines.insert(1, f"\n**æœ€çµ‚æ›´æ–°**: {current_date}")
                    content = "\n".join(lines)

            with open(doc_path, "w", encoding="utf-8") as f:
                f.write(content)

            print(
                f"âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°: {doc_path.relative_to(self.project_root)}"
            )

        except Exception as e:
            print(
                f"âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°å¤±æ•—: {doc_path.relative_to(self.project_root)} - {e}"
            )

    def check_and_sync(self) -> bool:
        """å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒæœŸãƒã‚§ãƒƒã‚¯"""
        if not self.sync_state["auto_sync_enabled"]:
            return True

        changed_files = self._get_git_changed_files()
        if not changed_files:
            return True

        issues_found = False
        sync_needed = []

        for file_path in changed_files:
            if not file_path.endswith((".py", ".sh", ".js", ".ts")):
                continue

            # é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆç™ºè¦‹
            related_docs = self._find_related_docs(file_path)

            for doc_path in related_docs:
                is_stale, reason = self._check_doc_staleness(doc_path)

                if is_stale:
                    issues_found = True
                    sync_needed.append((file_path, doc_path, reason))
                    print(
                        f"âš ï¸  åŒæœŸå¿…è¦: {file_path} â†’ {doc_path.relative_to(self.project_root)}"
                    )
                    print(f"   ç†ç”±: {reason}")

        # è‡ªå‹•åŒæœŸå®Ÿè¡Œ
        if sync_needed:
            print(f"\nğŸ”„ {len(sync_needed)}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªå‹•åŒæœŸä¸­...")

            for _source_file, doc_path, _reason in sync_needed:
                self._auto_update_doc_header(doc_path)

                # ãƒãƒƒã‚·ãƒ¥çŠ¶æ…‹æ›´æ–°
                self.sync_state["file_hashes"][str(doc_path)] = self._get_file_hash(
                    doc_path
                )

        # åŒæœŸçŠ¶æ…‹ä¿å­˜
        self.sync_state["last_sync"] = datetime.now().isoformat()
        self._save_sync_state()

        if issues_found:
            print("\nğŸ“ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒæœŸã‚’å®Ÿè¡Œã—ã¾ã—ãŸ")
            print(f"   å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«: {len(changed_files)}ä»¶")
            print(f"   åŒæœŸã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: {len(sync_needed)}ä»¶")

        return True


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    try:
        syncer = DocumentationSyncer()
        success = syncer.check_and_sync()

        if not success:
            print("âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒæœŸãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)

        print("âœ… ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒæœŸãƒã‚§ãƒƒã‚¯å®Œäº†")

    except Exception as e:
        print(f"âŒ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒæœŸã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
