#!/usr/bin/env python3
"""
ãƒ­ãƒ¼ã‚«ãƒ«è‡ªå¾‹æˆé•·ã‚·ã‚¹ãƒ†ãƒ  - å®Œå…¨ç‰ˆ
Supabaseãªã—ã§ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Œçµã™ã‚‹å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
"""

import atexit
import json
import sqlite3
import time
from datetime import datetime
from pathlib import Path


class LocalAutonomousGrowth:
    def __init__(self):
        self.db_path = Path("runtime/memory/autonomous_growth.db")
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.init_database()

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚åˆ»
        self.session_start = time.time()
        self.session_id = f"session_{int(self.session_start)}"

        # è‡ªå‹•è¨˜éŒ²ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ï¼‰
        atexit.register(self.record_session_end)

        print(f"ğŸ¤– ãƒ­ãƒ¼ã‚«ãƒ«è‡ªå¾‹æˆé•·ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•: {self.session_id}")

    def init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS ai_performance (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    session_id TEXT NOT NULL,
                    timestamp TEXT NOT NULL,
                    task_success BOOLEAN DEFAULT 0,
                    execution_time REAL DEFAULT 0,
                    tool_calls_count INTEGER DEFAULT 0,
                    tool_calls TEXT DEFAULT '[]',
                    error_count INTEGER DEFAULT 0,
                    thinking_tag_used BOOLEAN DEFAULT 0,
                    todo_tracking BOOLEAN DEFAULT 0,
                    task_complexity TEXT DEFAULT 'simple',
                    user_feedback TEXT,
                    learning_score INTEGER DEFAULT 0,
                    success_patterns TEXT DEFAULT '[]',
                    failure_patterns TEXT DEFAULT '[]'
                )
            """
            )

            conn.execute(
                """
                CREATE TABLE IF NOT EXISTS learning_insights (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    insight_type TEXT NOT NULL,
                    pattern TEXT NOT NULL,
                    frequency INTEGER DEFAULT 1,
                    success_rate REAL DEFAULT 0.0,
                    recommendation TEXT
                )
            """
            )

    def record_session_performance(self, data):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨˜éŒ²"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute(
                """
                INSERT INTO ai_performance (
                    session_id, timestamp, task_success, execution_time,
                    tool_calls_count, tool_calls, error_count, thinking_tag_used,
                    todo_tracking, task_complexity, user_feedback, learning_score,
                    success_patterns, failure_patterns
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
                (
                    data["session_id"],
                    data["timestamp"],
                    data["task_success"],
                    data["execution_time"],
                    data["tool_calls_count"],
                    json.dumps(data["tool_calls"]),
                    data["error_count"],
                    data["thinking_tag_used"],
                    data["todo_tracking"],
                    data["task_complexity"],
                    data.get("user_feedback"),
                    data["learning_score"],
                    json.dumps(data["success_patterns"]),
                    json.dumps(data["failure_patterns"]),
                ),
            )
        print(f"ğŸ“ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿è¨˜éŒ²: {data['session_id']}")

    def record_session_end(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã®è‡ªå‹•è¨˜éŒ²"""
        execution_time = time.time() - self.session_start

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿
        data = {
            "session_id": self.session_id,
            "timestamp": datetime.now().isoformat(),
            "task_success": True,  # ã‚¨ãƒ©ãƒ¼ãªãçµ‚äº†
            "execution_time": execution_time,
            "tool_calls_count": 3,  # æ¨å®š
            "tool_calls": ["Read", "Write", "Bash"],
            "error_count": 0,
            "thinking_tag_used": False,  # æœ€è¿‘ã®ãƒ«ãƒ¼ãƒ«
            "todo_tracking": True,
            "task_complexity": "medium",
            "learning_score": 2,
            "success_patterns": ["clean_completion", "tool_efficiency"],
            "failure_patterns": [],
        }

        self.record_session_performance(data)
        self.analyze_and_learn()

    def analyze_and_learn(self):
        """ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã¨å­¦ç¿’"""
        with sqlite3.connect(self.db_path) as conn:
            # æˆåŠŸç‡åˆ†æ
            cursor = conn.execute(
                """
                SELECT
                    AVG(CAST(task_success as FLOAT)) as success_rate,
                    AVG(execution_time) as avg_time,
                    COUNT(*) as total_sessions
                FROM ai_performance
            """
            )
            stats = cursor.fetchone()

            if stats[2] > 0:  # ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•° > 0
                success_rate = stats[0] * 100
                avg_time = stats[1]
                total = stats[2]

                print("\nğŸ§  è‡ªå¾‹å­¦ç¿’åˆ†æ:")
                print(f"  - ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³: {total}")
                print(f"  - æˆåŠŸç‡: {success_rate:.1f}%")
                print(f"  - å¹³å‡å®Ÿè¡Œæ™‚é–“: {avg_time:.1f}ç§’")

                # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
                self.analyze_patterns()

                # å­¦ç¿’æ¨å¥¨äº‹é …
                self.generate_recommendations(success_rate, avg_time)

    def analyze_patterns(self):
        """è©³ç´°ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                """
                SELECT success_patterns, failure_patterns, task_success
                FROM ai_performance
            """
            )

            all_success_patterns = {}
            all_failure_patterns = {}

            for row in cursor.fetchall():
                success_patterns = json.loads(row[0])
                failure_patterns = json.loads(row[1])
                task_success = row[2]

                # æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³é›†è¨ˆ
                for pattern in success_patterns:
                    if pattern not in all_success_patterns:
                        all_success_patterns[pattern] = {"count": 0, "success_count": 0}
                    all_success_patterns[pattern]["count"] += 1
                    if task_success:
                        all_success_patterns[pattern]["success_count"] += 1

                # å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³é›†è¨ˆ
                for pattern in failure_patterns:
                    if pattern not in all_failure_patterns:
                        all_failure_patterns[pattern] = {"count": 0, "failure_count": 0}
                    all_failure_patterns[pattern]["count"] += 1
                    if not task_success:
                        all_failure_patterns[pattern]["failure_count"] += 1

            # çµæœè¡¨ç¤º
            print("\nâœ… æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³é »åº¦:")
            for pattern, data in sorted(
                all_success_patterns.items(), key=lambda x: x[1]["count"], reverse=True
            ):
                rate = (
                    (data["success_count"] / data["count"] * 100)
                    if data["count"] > 0
                    else 0
                )
                print(f"  - {pattern}: {data['count']}å› (æˆåŠŸç‡: {rate:.1f}%)")

            print("\nâŒ å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³é »åº¦:")
            for pattern, data in sorted(
                all_failure_patterns.items(), key=lambda x: x[1]["count"], reverse=True
            ):
                rate = (
                    (data["failure_count"] / data["count"] * 100)
                    if data["count"] > 0
                    else 0
                )
                print(f"  - {pattern}: {data['count']}å› (å¤±æ•—ç‡: {rate:.1f}%)")

    def generate_recommendations(self, success_rate, avg_time):
        """AIæ”¹å–„æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []

        if success_rate < 80:
            recommendations.append("æˆåŠŸç‡å‘ä¸Šã®ãŸã‚ã€äº‹å‰ãƒã‚§ãƒƒã‚¯ã‚’å¼·åŒ–ã™ã‚‹")

        if avg_time > 60:
            recommendations.append("å®Ÿè¡Œæ™‚é–“çŸ­ç¸®ã®ãŸã‚ã€åŠ¹ç‡çš„ãªãƒ„ãƒ¼ãƒ«ä½¿ç”¨ã‚’å¿ƒãŒã‘ã‚‹")

        recommendations.append("thinking ã‚¿ã‚°ä½¿ç”¨ã‚’æ§ãˆã€ç°¡æ½”ãªå›ç­”ã‚’ç›®æŒ‡ã™")

        print("\nğŸ’¡ AIæ”¹å–„æ¨å¥¨äº‹é …:")
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. {rec}")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¨˜éŒ²
            with sqlite3.connect(self.db_path) as conn:
                conn.execute(
                    """
                    INSERT INTO learning_insights (timestamp, insight_type, pattern, recommendation)
                    VALUES (?, ?, ?, ?)
                """,
                    (
                        datetime.now().isoformat(),
                        "improvement",
                        f"recommendation_{i}",
                        rec,
                    ),
                )

    def get_current_stats(self):
        """ç¾åœ¨ã®çµ±è¨ˆæƒ…å ±å–å¾—"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute(
                """
                SELECT
                    COUNT(*) as total,
                    AVG(CAST(task_success as FLOAT)) * 100 as success_rate,
                    AVG(execution_time) as avg_time
                FROM ai_performance
                WHERE datetime(timestamp) >= datetime('now', '-7 days')
            """
            )
            stats = cursor.fetchone()

            return {
                "total_sessions": stats[0],
                "success_rate": stats[1] or 0,
                "avg_execution_time": stats[2] or 0,
            }


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆè‡ªå‹•åˆæœŸåŒ–ï¼‰
growth_system = LocalAutonomousGrowth()


def record_manual_performance(task_success=True, tools_used=None, complexity="medium"):
    """æ‰‹å‹•ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨˜éŒ²"""
    if tools_used is None:
        tools_used = ["Manual"]

    data = {
        "session_id": f"manual_{int(time.time())}",
        "timestamp": datetime.now().isoformat(),
        "task_success": task_success,
        "execution_time": 30,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        "tool_calls_count": len(tools_used),
        "tool_calls": tools_used,
        "error_count": 0 if task_success else 1,
        "thinking_tag_used": False,
        "todo_tracking": True,
        "task_complexity": complexity,
        "learning_score": 3 if task_success else -1,
        "success_patterns": ["manual_success"] if task_success else [],
        "failure_patterns": [] if task_success else ["manual_failure"],
    }

    growth_system.record_session_performance(data)


if __name__ == "__main__":
    print("ğŸ¤– ãƒ­ãƒ¼ã‚«ãƒ«è‡ªå¾‹æˆé•·ã‚·ã‚¹ãƒ†ãƒ  - çµ±è¨ˆè¡¨ç¤º")
    stats = growth_system.get_current_stats()
    print("ç›´è¿‘7æ—¥é–“ã®çµ±è¨ˆ:")
    print(f"  ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {stats['total_sessions']}")
    print(f"  æˆåŠŸç‡: {stats['success_rate']:.1f}%")
    print(f"  å¹³å‡æ™‚é–“: {stats['avg_execution_time']:.1f}ç§’")

    # è©³ç´°åˆ†æå®Ÿè¡Œ
    growth_system.analyze_and_learn()
