#!/usr/bin/env python3
"""
ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ«ãƒ¼ãƒ«å¼·åˆ¶ã‚·ã‚¹ãƒ†ãƒ 
============================

Pythonãƒ•ã‚¡ã‚¤ãƒ«é‡ç”£é˜²æ­¢ã®ãŸã‚ã®å³æ ¼ãªä½œæˆãƒ«ãƒ¼ãƒ«ã¨å¼·åˆ¶ã‚·ã‚¹ãƒ†ãƒ 

ã€çµ¶å¯¾ç¦æ­¢äº‹é …ã€‘
1. é‡è¤‡æ©Ÿèƒ½ã®ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
2. ä¸€æ™‚çš„ãƒ»å®Ÿé¨“çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®æ®‹ç½®
3. æ©Ÿèƒ½åˆ†é›¢ã®éåº¦ãªç´°åˆ†åŒ–
4. ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®æœ¬ç•ªæ··åœ¨
5. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ•£

ã€å¼·åˆ¶ãƒ«ãƒ¼ãƒ«ã€‘
1. æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå‰ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯å¿…é ˆ
2. æ©Ÿèƒ½çµ±åˆå¯èƒ½æ€§ã®æ¤œè¨¼å¿…é ˆ
3. ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆç†ç”±ã®æ˜æ–‡åŒ–å¿…é ˆ
4. å®šæœŸçš„ãªä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¿…é ˆ
5. ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°ä¸Šé™ã®å³å®ˆå¿…é ˆ
"""

import hashlib
import json
import os
import re
import sys
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# PostgreSQL connection for logging
try:
    import psycopg2
    import psycopg2.extras

    POSTGRESQL_AVAILABLE = True
except ImportError:
    POSTGRESQL_AVAILABLE = False


class FileCreationRules:
    """ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ«ãƒ¼ãƒ«å¼·åˆ¶ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.project_root = project_root
        self.rules_file = self.project_root / "runtime" / "file_creation_rules.json"
        self.violation_log = (
            self.project_root / "runtime" / "file_creation_violations.json"
        )
        self.allowed_extensions = {
            ".py",
            ".md",
            ".json",
            ".yaml",
            ".yml",
            ".txt",
            ".sh",
            ".sql",
        }

        # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™
        self.max_files = {
            "python": 500,  # ç¾åœ¨346å€‹ â†’ 500å€‹ä¸Šé™
            "markdown": 350,  # ç¾åœ¨327å€‹ â†’ 350å€‹ä¸Šé™
            "total": 1000,  # å…¨ä½“1000å€‹ä¸Šé™
        }

        # å¿…é ˆæ§‹é€ 
        self.required_structure = {
            "scripts/": {
                "allowed_subdirs": [
                    "automation",
                    "enforcement",
                    "hooks",
                    "maintenance",
                    "setup",
                    "system",
                    "tools",
                ],
                "max_files_per_dir": 20,
                "description": "ã‚·ã‚¹ãƒ†ãƒ ã‚¹ã‚¯ãƒªãƒ—ãƒˆ",
            },
            "src/": {
                "allowed_subdirs": [
                    "ai",
                    "conductor",
                    "enforcement",
                    "memory",
                    "orchestrator",
                    "session_management",
                ],
                "max_files_per_dir": 30,
                "description": "ãƒ¡ã‚¤ãƒ³ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰",
            },
            "tests/": {
                "allowed_subdirs": ["integration", "unit"],
                "max_files_per_dir": 50,
                "description": "ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰",
            },
            "docs/": {
                "allowed_subdirs": ["api", "guides", "reference", "setup"],
                "max_files_per_dir": 100,
                "description": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
            },
            "config/": {
                "allowed_subdirs": ["n8n", "supabase"],
                "max_files_per_dir": 10,
                "description": "è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«",
            },
        }

        # ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³
        self.forbidden_patterns = [
            r".*_test\.py$",  # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆtestsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä»¥å¤–ï¼‰
            r".*_backup\.py$",  # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«
            r".*_old\.py$",  # å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«
            r".*_temp\.py$",  # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
            r".*_debug\.py$",  # ãƒ‡ãƒãƒƒã‚°ãƒ•ã‚¡ã‚¤ãƒ«
            r".*_experiment\.py$",  # å®Ÿé¨“ãƒ•ã‚¡ã‚¤ãƒ«
            r".*_draft\.py$",  # ä¸‹æ›¸ããƒ•ã‚¡ã‚¤ãƒ«
            r".*_copy\.py$",  # ã‚³ãƒ”ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«
            r".*_v\d+\.py$",  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç•ªå·ä»˜ããƒ•ã‚¡ã‚¤ãƒ«
            r".*_final\.py$",  # æœ€çµ‚ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«
            r".*_ultimate\.py$",  # ç©¶æ¥µç‰ˆãƒ•ã‚¡ã‚¤ãƒ«
            r".*_hybrid\.py$",  # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«
            r".*_complete\.py$",  # å®Œå…¨ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«
            r".*_simple\.py$",  # ã‚·ãƒ³ãƒ—ãƒ«ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«
            r".*_quick\.py$",  # ã‚¯ã‚¤ãƒƒã‚¯ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«
            r".*_auto\.py$",  # è‡ªå‹•ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«
            r".*_manual\.py$",  # æ‰‹å‹•ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«
            r".*_fix\.py$",  # ä¿®æ­£ç‰ˆãƒ•ã‚¡ã‚¤ãƒ«
            r".*_solution\.py$",  # ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«
            r".*_setup\.py$",  # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆsetup.pyã‚’é™¤ãï¼‰
        ]

        # DBæ¥ç¶šè¨­å®š
        self.db_config = {
            "host": "localhost",
            "port": 5432,
            "database": "coding_rule2_ai",
            "user": "dd",
            "password": "",
        }

        self.initialize_rules()

    def initialize_rules(self):
        """ãƒ«ãƒ¼ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«åˆæœŸåŒ–"""
        self.rules_file.parent.mkdir(parents=True, exist_ok=True)
        self.violation_log.parent.mkdir(parents=True, exist_ok=True)

        if not self.rules_file.exists():
            rules_data = {
                "version": "1.0",
                "created_at": datetime.now().isoformat(),
                "rules": {
                    "max_files": self.max_files,
                    "required_structure": self.required_structure,
                    "forbidden_patterns": self.forbidden_patterns,
                    "allowed_extensions": list(self.allowed_extensions),
                },
                "enforcement_level": "strict",
                "auto_delete": True,
            }

            with open(self.rules_file, "w") as f:
                json.dump(rules_data, f, indent=2)

    def check_file_creation(
        self, file_path: str, content: str = "", reason: str = ""
    ) -> Tuple[bool, List[str]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒã‚§ãƒƒã‚¯"""
        violations = []
        file_path = Path(file_path)

        # 1. æ‹¡å¼µå­ãƒã‚§ãƒƒã‚¯
        if file_path.suffix not in self.allowed_extensions:
            violations.append(f"ç¦æ­¢æ‹¡å¼µå­: {file_path.suffix}")

        # 2. ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        for pattern in self.forbidden_patterns:
            if re.match(pattern, file_path.name):
                violations.append(f"ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern}")

        # 3. æ§‹é€ ãƒã‚§ãƒƒã‚¯
        if not self._check_directory_structure(file_path):
            violations.append("ä¸æ­£ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ")

        # 4. é‡è¤‡ãƒã‚§ãƒƒã‚¯
        duplicates = self._check_duplicates(file_path, content)
        if duplicates:
            violations.append(f"é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(duplicates)}")

        # 5. ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯
        if not self._check_file_limits():
            violations.append("ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™è¶…é")

        # 6. å¿…è¦æ€§ãƒã‚§ãƒƒã‚¯
        if not reason:
            violations.append("ä½œæˆç†ç”±ãŒæœªè¨˜è¼‰")

        # é•åãƒ­ã‚°è¨˜éŒ²
        if violations:
            self._log_violation(file_path, violations, reason)

        return len(violations) == 0, violations

    def _check_directory_structure(self, file_path: Path) -> bool:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ãƒã‚§ãƒƒã‚¯"""
        str(file_path)

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹
        try:
            rel_path = file_path.relative_to(self.project_root)
        except ValueError:
            return False

        # ç¬¬1éšå±¤ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯
        parts = rel_path.parts
        if len(parts) == 0:
            return False

        first_dir = parts[0]

        # è¨±å¯ã•ã‚ŒãŸãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ãƒã‚§ãƒƒã‚¯
        if first_dir not in self.required_structure:
            return False

        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆ¶é™ãƒã‚§ãƒƒã‚¯
        if len(parts) > 1:
            sub_dir = parts[1]
            allowed_subdirs = self.required_structure[first_dir]["allowed_subdirs"]
            if sub_dir not in allowed_subdirs:
                return False

        return True

    def _check_duplicates(self, file_path: Path, content: str) -> List[str]:
        """é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯"""
        duplicates = []

        if not content:
            return duplicates

        # å†…å®¹ã®ãƒãƒƒã‚·ãƒ¥åŒ–
        content_hash = hashlib.md5(content.encode()).hexdigest()

        # åŒã˜æ‹¡å¼µå­ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
        for existing_file in self.project_root.rglob(f"*{file_path.suffix}"):
            if existing_file == file_path:
                continue

            try:
                with open(existing_file, encoding="utf-8") as f:
                    existing_content = f.read()

                existing_hash = hashlib.md5(existing_content.encode()).hexdigest()

                # å®Œå…¨ä¸€è‡´ã¾ãŸã¯é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯
                if content_hash == existing_hash:
                    duplicates.append(str(existing_file))
                elif self._calculate_similarity(content, existing_content) > 0.8:
                    duplicates.append(str(existing_file))

            except Exception:
                continue

        return duplicates

    def _calculate_similarity(self, content1: str, content2: str) -> float:
        """å†…å®¹ã®é¡ä¼¼åº¦è¨ˆç®—"""
        # ç°¡æ˜“çš„ãªé¡ä¼¼åº¦è¨ˆç®—ï¼ˆå®Ÿéš›ã«ã¯ã‚ˆã‚Šç²¾å¯†ãªè¨ˆç®—ãŒå¿…è¦ï¼‰
        lines1 = set(content1.split("\n"))
        lines2 = set(content2.split("\n"))

        if not lines1 or not lines2:
            return 0.0

        intersection = len(lines1.intersection(lines2))
        union = len(lines1.union(lines2))

        return intersection / union if union > 0 else 0.0

    def _check_file_limits(self) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯"""
        current_counts = self.get_current_file_counts()

        # Python ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
        if current_counts["python"] >= self.max_files["python"]:
            return False

        # Markdown ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
        if current_counts["markdown"] >= self.max_files["markdown"]:
            return False

        # ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
        if current_counts["total"] >= self.max_files["total"]:
            return False

        return True

    def get_current_file_counts(self) -> Dict[str, int]:
        """ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°å–å¾—"""
        python_count = len(list(self.project_root.rglob("*.py")))
        markdown_count = len(list(self.project_root.rglob("*.md")))
        total_count = python_count + markdown_count

        return {
            "python": python_count,
            "markdown": markdown_count,
            "total": total_count,
        }

    def _log_violation(self, file_path: Path, violations: List[str], reason: str):
        """é•åãƒ­ã‚°è¨˜éŒ²"""
        violation_entry = {
            "timestamp": datetime.now().isoformat(),
            "file_path": str(file_path),
            "violations": violations,
            "reason": reason,
            "session_id": os.environ.get("CLAUDE_SESSION_ID", "unknown"),
        }

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²
        if self.violation_log.exists():
            with open(self.violation_log) as f:
                log_data = json.load(f)
        else:
            log_data = {"violations": []}

        log_data["violations"].append(violation_entry)

        with open(self.violation_log, "w") as f:
            json.dump(log_data, f, indent=2)

        # PostgreSQL ã«ã‚‚è¨˜éŒ²
        if POSTGRESQL_AVAILABLE:
            self._log_to_postgresql(violation_entry)

    def _log_to_postgresql(self, violation_entry: Dict):
        """PostgreSQL ã«é•åãƒ­ã‚°è¨˜éŒ²"""
        try:
            with psycopg2.connect(**self.db_config) as conn:
                with conn.cursor() as cursor:
                    cursor.execute(
                        """
                        SELECT log_system_event(
                            'file_creation_violation',
                            %s::jsonb,
                            'warning',
                            %s,
                            'file_creation_rules.py'
                        )
                    """,
                        (json.dumps(violation_entry), violation_entry["session_id"]),
                    )

                    conn.commit()
        except Exception:
            pass  # ãƒ­ã‚°è¨˜éŒ²å¤±æ•—ã¯éè‡´å‘½çš„

    def cleanup_violations(self) -> Dict[str, int]:
        """é•åãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        cleaned_count = 0

        for file_path in self.project_root.rglob("*.py"):
            file_name = file_path.name

            # ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
            for pattern in self.forbidden_patterns:
                if re.match(pattern, file_name):
                    try:
                        file_path.unlink()
                        cleaned_count += 1
                        print(f"ğŸ—‘ï¸ å‰Šé™¤: {file_path}")
                    except Exception as e:
                        print(f"âŒ å‰Šé™¤å¤±æ•— {file_path}: {e}")
                    break

        return {"cleaned_files": cleaned_count}

    def generate_report(self) -> Dict:
        """ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ«ãƒ¼ãƒ«å ±å‘Šæ›¸ç”Ÿæˆ"""
        current_counts = self.get_current_file_counts()

        report = {
            "timestamp": datetime.now().isoformat(),
            "file_counts": current_counts,
            "limits": self.max_files,
            "compliance": {
                "python": current_counts["python"] < self.max_files["python"],
                "markdown": current_counts["markdown"] < self.max_files["markdown"],
                "total": current_counts["total"] < self.max_files["total"],
            },
            "violations": [],
        }

        # é•åãƒ­ã‚°èª­ã¿è¾¼ã¿
        if self.violation_log.exists():
            with open(self.violation_log) as f:
                log_data = json.load(f)
                report["violations"] = log_data.get("violations", [])

        return report

    def enforce_rules(self) -> Dict:
        """ãƒ«ãƒ¼ãƒ«å¼·åˆ¶å®Ÿè¡Œ"""
        print("ğŸš¨ ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ«ãƒ¼ãƒ«å¼·åˆ¶å®Ÿè¡Œé–‹å§‹")
        print("=" * 50)

        # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèª
        current_counts = self.get_current_file_counts()
        print("ğŸ“Š ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°:")
        print(f"  Python: {current_counts['python']}/{self.max_files['python']}")
        print(f"  Markdown: {current_counts['markdown']}/{self.max_files['markdown']}")
        print(f"  Total: {current_counts['total']}/{self.max_files['total']}")

        # é•åãƒ•ã‚¡ã‚¤ãƒ«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        cleanup_result = self.cleanup_violations()
        print(f"ğŸ—‘ï¸ é•åãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {cleanup_result['cleaned_files']}ä»¶")

        # æ›´æ–°å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèª
        updated_counts = self.get_current_file_counts()
        print("ğŸ“Š æ›´æ–°å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°:")
        print(f"  Python: {updated_counts['python']}/{self.max_files['python']}")
        print(f"  Markdown: {updated_counts['markdown']}/{self.max_files['markdown']}")
        print(f"  Total: {updated_counts['total']}/{self.max_files['total']}")

        # å ±å‘Šæ›¸ç”Ÿæˆ
        report = self.generate_report()
        report_file = self.project_root / "runtime" / "file_creation_rules_report.json"
        with open(report_file, "w") as f:
            json.dump(report, f, indent=2)

        print(f"ğŸ“ å ±å‘Šæ›¸ç”Ÿæˆ: {report_file}")

        return {
            "enforcement_completed": True,
            "files_cleaned": cleanup_result["cleaned_files"],
            "current_counts": updated_counts,
            "compliance_status": all(report["compliance"].values()),
            "report_file": str(report_file),
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    rules = FileCreationRules()

    try:
        result = rules.enforce_rules()

        if result["compliance_status"]:
            print("\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ«ãƒ¼ãƒ«é©åˆ")
            print("ğŸ’¡ ä»Šå¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã¯å³æ ¼ã«ãƒã‚§ãƒƒã‚¯ã•ã‚Œã¾ã™")
        else:
            print("\nâš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«æ•°åˆ¶é™ã«è¿‘ã¥ã„ã¦ã„ã¾ã™")
            print("ğŸš¨ æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆã‚’æ§ãˆã¦ãã ã•ã„")

        print("\nğŸ‰ ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆãƒ«ãƒ¼ãƒ«å¼·åˆ¶ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒé–‹å§‹ï¼")

    except Exception as e:
        print(f"\nâŒ ãƒ«ãƒ¼ãƒ«å¼·åˆ¶ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return 1

    return 0


if __name__ == "__main__":
    sys.exit(main())
