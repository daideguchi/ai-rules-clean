# ğŸ“Š Performance Monitoring (perf) - å®Œå…¨è§£èª¬

## "perf" ã¨ã¯ä½•ã‹

**Performance Monitoring** = ç¶™ç¶šçš„ãªã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½ç›£è¦–

### 3å±¤ç›£è¦–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

#### 1. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤
```
ğŸ“Š Application Metrics
â”œâ”€â”€ å¿œç­”æ™‚é–“ (Latency)
â”‚   â”œâ”€â”€ p50: 50%ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å¿œç­”æ™‚é–“
â”‚   â”œâ”€â”€ p95: 95%ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å¿œç­”æ™‚é–“
â”‚   â””â”€â”€ p99: 99%ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å¿œç­”æ™‚é–“
â”œâ”€â”€ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ (Throughput)
â”‚   â”œâ”€â”€ ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ç§’ (RPS)
â”‚   â”œâ”€â”€ ã‚¿ã‚¹ã‚¯å®Œäº†ç‡
â”‚   â””â”€â”€ ä¸¦è¡Œå‡¦ç†æ•°
â””â”€â”€ ã‚¨ãƒ©ãƒ¼ç‡ (Error Rate)
    â”œâ”€â”€ 4xx ã‚¨ãƒ©ãƒ¼ç‡
    â”œâ”€â”€ 5xx ã‚¨ãƒ©ãƒ¼ç‡
    â””â”€â”€ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç‡
```

#### 2. ã‚·ã‚¹ãƒ†ãƒ å±¤
```
ğŸ–¥ï¸ System Metrics
â”œâ”€â”€ CPUä½¿ç”¨ç‡
â”‚   â”œâ”€â”€ å…¨ä½“ä½¿ç”¨ç‡
â”‚   â”œâ”€â”€ ã‚³ã‚¢åˆ¥ä½¿ç”¨ç‡
â”‚   â””â”€â”€ ã‚¢ã‚¤ãƒ‰ãƒ«æ™‚é–“
â”œâ”€â”€ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
â”‚   â”œâ”€â”€ ç‰©ç†ãƒ¡ãƒ¢ãƒª
â”‚   â”œâ”€â”€ ã‚¹ãƒ¯ãƒƒãƒ—ä½¿ç”¨é‡
â”‚   â””â”€â”€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨é‡
â”œâ”€â”€ ãƒ‡ã‚£ã‚¹ã‚¯I/O
â”‚   â”œâ”€â”€ èª­ã¿å–ã‚Šé€Ÿåº¦
â”‚   â”œâ”€â”€ æ›¸ãè¾¼ã¿é€Ÿåº¦
â”‚   â””â”€â”€ IOPS
â””â”€â”€ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    â”œâ”€â”€ å¸¯åŸŸå¹…ä½¿ç”¨ç‡
    â”œâ”€â”€ æ¥ç¶šæ•°
    â””â”€â”€ ãƒ‘ã‚±ãƒƒãƒˆæå¤±ç‡
```

#### 3. AIç‰¹åŒ–å±¤
```
ğŸ¤– AI-Specific Metrics
â”œâ”€â”€ GPUä½¿ç”¨ç‡
â”‚   â”œâ”€â”€ GPUä½¿ç”¨ç‡ (%)
â”‚   â”œâ”€â”€ VRAMãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
â”‚   â””â”€â”€ GPUæ¸©åº¦
â”œâ”€â”€ æ¨è«–æ€§èƒ½
â”‚   â”œâ”€â”€ Token/ç§’
â”‚   â”œâ”€â”€ æ¨è«–ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
â”‚   â””â”€â”€ ãƒãƒƒãƒå‡¦ç†åŠ¹ç‡
â”œâ”€â”€ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½
â”‚   â”œâ”€â”€ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½¿ç”¨ç‡
â”‚   â”œâ”€â”€ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡
â”‚   â””â”€â”€ ç²¾åº¦ãƒ‰ãƒªãƒ•ãƒˆ
â””â”€â”€ AI WorkerçŠ¶æ…‹
    â”œâ”€â”€ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–Workeræ•°
    â”œâ”€â”€ å¾…æ©Ÿä¸­Workeræ•°
    â””â”€â”€ ã‚¨ãƒ©ãƒ¼çŠ¶æ…‹Workeræ•°
```

## å®Ÿè£…è©³ç´°

### 1. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
```python
# monitoring/metrics_collector.py
import time
import psutil
import GPUtil
from dataclasses import dataclass
from typing import Dict, List

@dataclass
class PerformanceMetrics:
    timestamp: float
    cpu_percent: float
    memory_percent: float
    disk_usage: float
    gpu_usage: float
    gpu_memory: float
    active_workers: int
    completed_tasks: int
    error_rate: float

class MetricsCollector:
    def __init__(self):
        self.start_time = time.time()
        self.task_count = 0
        self.error_count = 0
    
    def collect_system_metrics(self) -> PerformanceMetrics:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’åé›†"""
        
        # CPUãƒ»ãƒ¡ãƒ¢ãƒª
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        # GPU (åˆ©ç”¨å¯èƒ½ãªå ´åˆ)
        gpu_usage = 0
        gpu_memory = 0
        try:
            gpus = GPUtil.getGPUs()
            if gpus:
                gpu_usage = gpus[0].load * 100
                gpu_memory = gpus[0].memoryUtil * 100
        except:
            pass
        
        # AI WorkerçŠ¶æ…‹
        active_workers = self.count_active_workers()
        
        # ã‚¨ãƒ©ãƒ¼ç‡è¨ˆç®—
        error_rate = (self.error_count / max(self.task_count, 1)) * 100
        
        return PerformanceMetrics(
            timestamp=time.time(),
            cpu_percent=cpu_percent,
            memory_percent=memory.percent,
            disk_usage=disk.percent,
            gpu_usage=gpu_usage,
            gpu_memory=gpu_memory,
            active_workers=active_workers,
            completed_tasks=self.task_count,
            error_rate=error_rate
        )
    
    def count_active_workers(self) -> int:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªAI Workeræ•°ã‚’å–å¾—"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€AI Organization Systemã¨é€£æº
        return 8  # 8 AI workers
```

### 2. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
```python
# monitoring/live_dashboard.py
from rich.console import Console
from rich.live import Live
from rich.table import Table
from rich.panel import Panel
from rich.layout import Layout
import time

class LivePerformanceDashboard:
    def __init__(self):
        self.console = Console()
        self.collector = MetricsCollector()
    
    def create_metrics_table(self, metrics: PerformanceMetrics) -> Table:
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        table = Table(title="ğŸ“Š Performance Metrics")
        table.add_column("Metric", style="cyan")
        table.add_column("Value", style="green")
        table.add_column("Status", style="yellow")
        
        # CPU
        cpu_status = "ğŸŸ¢ Normal" if metrics.cpu_percent < 70 else "ğŸŸ¡ Warning" if metrics.cpu_percent < 90 else "ğŸ”´ Critical"
        table.add_row("CPU Usage", f"{metrics.cpu_percent:.1f}%", cpu_status)
        
        # Memory
        mem_status = "ğŸŸ¢ Normal" if metrics.memory_percent < 70 else "ğŸŸ¡ Warning" if metrics.memory_percent < 90 else "ğŸ”´ Critical"
        table.add_row("Memory Usage", f"{metrics.memory_percent:.1f}%", mem_status)
        
        # GPU
        if metrics.gpu_usage > 0:
            gpu_status = "ğŸŸ¢ Normal" if metrics.gpu_usage < 80 else "ğŸŸ¡ Warning" if metrics.gpu_usage < 95 else "ğŸ”´ Critical"
            table.add_row("GPU Usage", f"{metrics.gpu_usage:.1f}%", gpu_status)
            table.add_row("GPU Memory", f"{metrics.gpu_memory:.1f}%", gpu_status)
        
        # AI Workers
        worker_status = "ğŸŸ¢ Active" if metrics.active_workers >= 6 else "ğŸŸ¡ Degraded" if metrics.active_workers >= 4 else "ğŸ”´ Critical"
        table.add_row("Active Workers", f"{metrics.active_workers}/8", worker_status)
        
        # Error Rate
        error_status = "ğŸŸ¢ Normal" if metrics.error_rate < 5 else "ğŸŸ¡ Warning" if metrics.error_rate < 15 else "ğŸ”´ Critical"
        table.add_row("Error Rate", f"{metrics.error_rate:.1f}%", error_status)
        
        return table
    
    def create_worker_status_panel(self) -> Panel:
        """WorkerçŠ¶æ…‹ãƒ‘ãƒãƒ«"""
        worker_info = """
ğŸ¤– AI Workers Status:
â”œâ”€â”€ ğŸ‘‘ PRESIDENT: ACTIVE (CPU: 45%, Tasks: 12)
â”œâ”€â”€ ğŸ”„ COORDINATOR: PROCESSING (CPU: 38%, Tasks: 8)
â”œâ”€â”€ ğŸ“‹ ANALYST: ACTIVE (CPU: 52%, Tasks: 15)
â”œâ”€â”€ ğŸ—ï¸ ARCHITECT: IDLE (CPU: 12%, Tasks: 3)
â”œâ”€â”€ ğŸ“Š DATA_ENG: PROCESSING (CPU: 78%, Tasks: 20)
â”œâ”€â”€ ğŸ”’ SECURITY: ACTIVE (CPU: 34%, Tasks: 6)
â”œâ”€â”€ ğŸ“ˆ PM: IDLE (CPU: 8%, Tasks: 2)
â””â”€â”€ âš™ï¸ DEVOPS: ACTIVE (CPU: 41%, Tasks: 10)
        """
        return Panel(worker_info, title="AI Organization Status")
    
    def run_live_dashboard(self):
        """ãƒ©ã‚¤ãƒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰å®Ÿè¡Œ"""
        def generate_display():
            while True:
                metrics = self.collector.collect_system_metrics()
                
                # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆä½œæˆ
                layout = Layout()
                layout.split_column(
                    Layout(name="metrics", size=12),
                    Layout(name="workers")
                )
                
                layout["metrics"].update(self.create_metrics_table(metrics))
                layout["workers"].update(self.create_worker_status_panel())
                
                yield layout
                time.sleep(2)  # 2ç§’æ›´æ–°
        
        with Live(generate_display(), console=self.console, refresh_per_second=0.5):
            try:
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                pass
```

### 3. ã‚¢ãƒ©ãƒ¼ãƒˆãƒ»é€šçŸ¥
```python
# monitoring/alerting.py
from dataclasses import dataclass
from enum import Enum
from typing import List, Callable

class AlertLevel(Enum):
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"

@dataclass
class Alert:
    level: AlertLevel
    message: str
    metric_name: str
    current_value: float
    threshold: float
    timestamp: float

class AlertManager:
    def __init__(self):
        self.alert_rules = []
        self.alert_handlers = []
    
    def add_rule(self, metric_name: str, threshold: float, level: AlertLevel, message: str):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ«è¿½åŠ """
        self.alert_rules.append({
            'metric_name': metric_name,
            'threshold': threshold,
            'level': level,
            'message': message
        })
    
    def add_handler(self, handler: Callable[[Alert], None]):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¿½åŠ """
        self.alert_handlers.append(handler)
    
    def check_alerts(self, metrics: PerformanceMetrics):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯"""
        metric_values = {
            'cpu_percent': metrics.cpu_percent,
            'memory_percent': metrics.memory_percent,
            'gpu_usage': metrics.gpu_usage,
            'error_rate': metrics.error_rate
        }
        
        for rule in self.alert_rules:
            current_value = metric_values.get(rule['metric_name'])
            if current_value and current_value > rule['threshold']:
                alert = Alert(
                    level=rule['level'],
                    message=rule['message'],
                    metric_name=rule['metric_name'],
                    current_value=current_value,
                    threshold=rule['threshold'],
                    timestamp=time.time()
                )
                
                # ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡
                for handler in self.alert_handlers:
                    handler(alert)

# ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šä¾‹
alert_manager = AlertManager()
alert_manager.add_rule('cpu_percent', 80.0, AlertLevel.WARNING, "CPUä½¿ç”¨ç‡ãŒé«˜ããªã£ã¦ã„ã¾ã™")
alert_manager.add_rule('cpu_percent', 95.0, AlertLevel.CRITICAL, "CPUä½¿ç”¨ç‡ãŒå±é™ºãƒ¬ãƒ™ãƒ«ã§ã™")
alert_manager.add_rule('memory_percent', 85.0, AlertLevel.WARNING, "ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ããªã£ã¦ã„ã¾ã™")
alert_manager.add_rule('error_rate', 10.0, AlertLevel.CRITICAL, "ã‚¨ãƒ©ãƒ¼ç‡ãŒè¨±å®¹ç¯„å›²ã‚’è¶…ãˆã¦ã„ã¾ã™")
```

## ä½¿ç”¨æ–¹æ³•

### 1. åŸºæœ¬çš„ãªç›£è¦–
```bash
# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–é–‹å§‹
python3 monitoring/live_dashboard.py

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã®ã¿
python3 monitoring/metrics_collector.py --collect-only

# ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
python3 monitoring/alerting.py --config alerts.json
```

### 2. çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
```bash
# AI Organization + Performance çµ±åˆè¡¨ç¤º
python3 src/ui/ai_org_ui.py --mode dashboard --with-perf

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å°‚ç”¨
python3 src/ui/ai_org_ui.py --mode perf
```

## çµè«–

**"perf" = ç¶™ç¶šçš„ãªã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½ç›£è¦–**

1. **3å±¤ç›£è¦–**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ã‚·ã‚¹ãƒ†ãƒ ãƒ»AIç‰¹åŒ–
2. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º**: 2ç§’é–“éš”æ›´æ–°
3. **ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½**: é–¾å€¤ãƒ™ãƒ¼ã‚¹ã®è‡ªå‹•é€šçŸ¥
4. **çµ±åˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**: AI Organization + Performance
5. **24/7é‹ç”¨**: ç¶™ç¶šçš„ãªç›£è¦–ãƒ»æ”¹å–„

**å¸¸ã«å‹•ã„ã¦ã„ã‚‹ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã§ã™ã€‚**