#!/usr/bin/env python3
"""
Task Complexity Classification System
ã‚¿ã‚¹ã‚¯è¤‡é›‘åº¦åˆ¤å®šãƒ»é©åˆ‡æ‰‹æ³•é¸æŠã‚·ã‚¹ãƒ†ãƒ 
PRESIDENT/æŒ‡æ®è€…ã«ã‚ˆã‚‹åŠ¹ç‡çš„ã‚¿ã‚¹ã‚¯åˆ†é¡
"""

import re
from dataclasses import dataclass
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional


class TaskComplexity(Enum):
    """ã‚¿ã‚¹ã‚¯è¤‡é›‘åº¦ãƒ¬ãƒ™ãƒ«"""

    SIMPLE = "simple"  # LEVEL 1: ç›´æ¥å®Ÿè¡Œï¼ˆno thinkingï¼‰
    STANDARD = "standard"  # LEVEL 2: è¨ˆç”»å®Ÿè¡Œï¼ˆ<thinking>ï¼‰
    COMPLEX = "complex"  # LEVEL 3: AIå”æ¥­+ultrathinkï¼ˆ<thinking>ï¼‰
    CRITICAL = "critical"  # LEVEL 4: å®Œå…¨å”æ¥­+max ultrathinkï¼ˆ<thinking>ï¼‰


class ExecutionMethod(Enum):
    """å®Ÿè¡Œæ‰‹æ³•"""

    DIRECT = "direct"  # LEVEL 1: ç›´æ¥å®Ÿè¡Œï¼ˆno thinkingï¼‰
    PLANNED = "planned"  # LEVEL 2: è¨ˆç”»å®Ÿè¡Œï¼ˆ<thinking>ï¼‰
    AI_COLLABORATION = "ai_collaboration"  # LEVEL 3: AIå”æ¥­ï¼ˆultrathinkï¼‰
    FULL_COLLABORATION = "full_collaboration"  # LEVEL 4: å®Œå…¨å”æ¥­ï¼ˆmax ultrathinkï¼‰


class ThinkingLevel(Enum):
    """æ€è€ƒãƒ¬ãƒ™ãƒ«"""

    NONE = "none"  # thinkingä¸è¦
    STANDARD = "standard"  # <thinking>å¿…é ˆ
    ULTRATHINK = "ultrathink"  # ultrathinkæ·±æ€è€ƒ
    MAX_ULTRATHINK = "max_ultrathink"  # ultrathinkæœ€å¤§æ·±åº¦


@dataclass
class TaskClassification:
    """ã‚¿ã‚¹ã‚¯åˆ†é¡çµæœ"""

    complexity: TaskComplexity
    execution_method: ExecutionMethod
    thinking_level: ThinkingLevel
    confidence: float
    reasoning: str
    estimated_time: int  # åˆ†
    required_tools: List[str]
    required_files: List[str]
    ai_collaboration_needed: bool
    risk_level: str


class TaskComplexityClassifier:
    """ã‚¿ã‚¹ã‚¯è¤‡é›‘åº¦åˆ†é¡å™¨"""

    def __init__(self):
        self.base_path = Path("/Users/dd/Desktop/1_dev/coding-rule2")
        self.patterns = self._load_classification_patterns()

    def _load_classification_patterns(self) -> Dict[str, Any]:
        """åˆ†é¡ãƒ‘ã‚¿ãƒ¼ãƒ³èª­ã¿è¾¼ã¿"""
        return {
            "simple_patterns": [
                # LEVEL 1: ç›´æ¥å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³
                r"(?i)(show|display|list|view|read|check|status|info|get)",
                r"(?i)(what|where|which|how many|count)",
                r"(?i)(ls|pwd|whoami|date|echo)",
                r"(?i)(å˜ç´”ãª|ç°¡å˜ãª|ç¢ºèª|è¡¨ç¤º|ãƒªã‚¹ãƒˆ)",
            ],
            "standard_patterns": [
                # LEVEL 2: è¨ˆç”»å®Ÿè¡Œãƒ‘ã‚¿ãƒ¼ãƒ³
                r"(?i)(edit|modify|update|change|replace|fix)",
                r"(?i)(add|remove|delete|create|write)",
                r"(?i)(copy|move|rename|chmod)",
                r"(?i)(run|execute|start|stop)",
                r"(?i)(ç·¨é›†|ä¿®æ­£|æ›´æ–°|å¤‰æ›´|è¿½åŠ |å‰Šé™¤|ä½œæˆ)",
            ],
            "complex_patterns": [
                # LEVEL 3: AIå”æ¥­+ultrathinkãƒ‘ã‚¿ãƒ¼ãƒ³
                r"(?i)(implement|develop|build|design|architect)",
                r"(?i)(refactor|restructure|optimize|migrate)",
                r"(?i)(integrate|configure|setup|install)",
                r"(?i)(test|debug|troubleshoot|analyze)",
                r"(?i)(å®Ÿè£…|é–‹ç™º|æ§‹ç¯‰|è¨­è¨ˆ|çµ±åˆ|è¨­å®š|ãƒ†ã‚¹ãƒˆ)",
            ],
            "critical_patterns": [
                # LEVEL 4: å®Œå…¨å”æ¥­+max ultrathinkãƒ‘ã‚¿ãƒ¼ãƒ³
                r"(?i)(strategy|architecture|framework|system)",
                r"(?i)(evaluate|assess|recommend|decide)",
                r"(?i)(research|investigate|explore|discover)",
                r"(?i)(coordinate|manage|orchestrate|govern)",
                r"(?i)(critical|system-wide|infrastructure|migration)",
                r"(?i)(æˆ¦ç•¥|ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£|ã‚·ã‚¹ãƒ†ãƒ |è©•ä¾¡|ç ”ç©¶|èª¿æŸ»|ç®¡ç†|é‡è¦|åŸºç›¤)",
            ],
            "scale_indicators": {
                "file_count": {
                    "single": 1,  # TRIVIAL/SIMPLE
                    "few": 5,  # SIMPLE/COMPLEX
                    "many": 20,  # COMPLEX/AI_CONSULTATION
                },
                "time_indicators": {
                    "minutes": ["minute", "min", "quick", "fast", "åˆ†"],
                    "hours": ["hour", "æ™‚é–“", "long", "detailed"],
                    "days": ["day", "days", "æ—¥", "extensive", "comprehensive"],
                },
            },
        }

    def classify_task(
        self, task_description: str, context: Optional[Dict[str, Any]] = None
    ) -> TaskClassification:
        """ã‚¿ã‚¹ã‚¯åˆ†é¡"""
        context = context or {}

        # è¤‡æ•°æŒ‡æ¨™ã«ã‚ˆã‚‹åˆ†é¡
        complexity_scores = {
            TaskComplexity.SIMPLE: 0,
            TaskComplexity.STANDARD: 0,
            TaskComplexity.COMPLEX: 0,
            TaskComplexity.CRITICAL: 0,
        }

        # 1. ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°åˆ†æ
        pattern_scores = self._analyze_patterns(task_description)
        for complexity, score in pattern_scores.items():
            complexity_scores[complexity] += score * 0.4

        # 2. è¦æ¨¡æŒ‡æ¨™åˆ†æ
        scale_scores = self._analyze_scale_indicators(task_description, context)
        for complexity, score in scale_scores.items():
            complexity_scores[complexity] += score * 0.3

        # 3. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
        context_scores = self._analyze_context(task_description, context)
        for complexity, score in context_scores.items():
            complexity_scores[complexity] += score * 0.2

        # 4. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯†åº¦åˆ†æ
        keyword_scores = self._analyze_keyword_density(task_description)
        for complexity, score in keyword_scores.items():
            complexity_scores[complexity] += score * 0.1

        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®è¤‡é›‘åº¦ã‚’é¸æŠ
        max_complexity = max(complexity_scores.items(), key=lambda x: x[1])
        complexity = max_complexity[0]
        confidence = min(1.0, max_complexity[1])

        # å®Ÿè¡Œæ‰‹æ³•æ±ºå®š
        execution_method = self._determine_execution_method(
            complexity, task_description, context
        )

        # æ€è€ƒãƒ¬ãƒ™ãƒ«æ±ºå®š
        thinking_level = self._determine_thinking_level(complexity)

        # è©³ç´°æƒ…å ±ç”Ÿæˆ
        reasoning = self._generate_reasoning(
            complexity, complexity_scores, task_description
        )
        estimated_time = self._estimate_time(complexity, task_description)
        required_tools = self._identify_required_tools(task_description)
        required_files = self._get_required_files(complexity)
        ai_collaboration_needed = complexity in [
            TaskComplexity.COMPLEX,
            TaskComplexity.CRITICAL,
        ]
        risk_level = self._assess_risk_level(complexity, task_description)

        return TaskClassification(
            complexity=complexity,
            execution_method=execution_method,
            thinking_level=thinking_level,
            confidence=confidence,
            reasoning=reasoning,
            estimated_time=estimated_time,
            required_tools=required_tools,
            required_files=required_files,
            ai_collaboration_needed=ai_collaboration_needed,
            risk_level=risk_level,
        )

    def _analyze_patterns(self, task_description: str) -> Dict[TaskComplexity, float]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        scores = dict.fromkeys(TaskComplexity, 0)

        # å„è¤‡é›‘åº¦ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
        patterns_map = {
            TaskComplexity.SIMPLE: self.patterns["simple_patterns"],
            TaskComplexity.STANDARD: self.patterns["standard_patterns"],
            TaskComplexity.COMPLEX: self.patterns["complex_patterns"],
            TaskComplexity.CRITICAL: self.patterns["critical_patterns"],
        }

        for complexity, patterns in patterns_map.items():
            for pattern in patterns:
                matches = len(re.findall(pattern, task_description))
                scores[complexity] += matches * 0.25

        return scores

    def _analyze_scale_indicators(
        self, task_description: str, context: Dict[str, Any]
    ) -> Dict[TaskComplexity, float]:
        """è¦æ¨¡æŒ‡æ¨™åˆ†æ"""
        scores = dict.fromkeys(TaskComplexity, 0)

        # ãƒ•ã‚¡ã‚¤ãƒ«æ•°æ¨å®š
        file_indicators = [
            "file",
            "files",
            "ãƒ•ã‚¡ã‚¤ãƒ«",
            "directory",
            "directories",
            "ãƒ•ã‚©ãƒ«ãƒ€",
        ]
        file_mentions = sum(
            task_description.lower().count(indicator) for indicator in file_indicators
        )

        if file_mentions == 0 or file_mentions == 1:
            scores[TaskComplexity.SIMPLE] += 0.3
            scores[TaskComplexity.STANDARD] += 0.2
        elif file_mentions <= 3:
            scores[TaskComplexity.STANDARD] += 0.4
            scores[TaskComplexity.COMPLEX] += 0.2
        else:
            scores[TaskComplexity.COMPLEX] += 0.3
            scores[TaskComplexity.CRITICAL] += 0.2

        # æ™‚é–“æŒ‡æ¨™
        time_indicators = self.patterns["scale_indicators"]["time_indicators"]
        for time_category, keywords in time_indicators.items():
            for keyword in keywords:
                if keyword in task_description.lower():
                    if time_category == "minutes":
                        scores[TaskComplexity.SIMPLE] += 0.2
                        scores[TaskComplexity.STANDARD] += 0.1
                    elif time_category == "hours":
                        scores[TaskComplexity.COMPLEX] += 0.3
                    elif time_category == "days":
                        scores[TaskComplexity.CRITICAL] += 0.4

        return scores

    def _analyze_context(
        self, task_description: str, context: Dict[str, Any]
    ) -> Dict[TaskComplexity, float]:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ"""
        scores = dict.fromkeys(TaskComplexity, 0)

        # æ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ è¤‡é›‘åº¦
        if context.get("existing_system_complexity", "low") == "high":
            scores[TaskComplexity.COMPLEX] += 0.2
            scores[TaskComplexity.AI_CONSULTATION] += 0.3

        # ã‚¨ãƒ©ãƒ¼å¯¾å¿œã‚¿ã‚¹ã‚¯
        if context.get("is_error_response", False):
            scores[TaskComplexity.SIMPLE] += 0.2
            scores[TaskComplexity.COMPLEX] += 0.1

        # å‰å›ã®ãƒŸã‚¹å±¥æ­´
        if context.get("previous_mistakes_count", 0) > 0:
            scores[TaskComplexity.COMPLEX] += 0.2
            scores[TaskComplexity.AI_CONSULTATION] += 0.3

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç·Šæ€¥åº¦
        urgency = context.get("urgency", "normal")
        if urgency == "high":
            scores[TaskComplexity.SIMPLE] += 0.2
        elif urgency == "low":
            scores[TaskComplexity.AI_CONSULTATION] += 0.1

        return scores

    def _analyze_keyword_density(
        self, task_description: str
    ) -> Dict[TaskComplexity, float]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯†åº¦åˆ†æ"""
        scores = dict.fromkeys(TaskComplexity, 0)

        words = task_description.lower().split()
        word_count = len(words)

        if word_count == 0:
            return scores

        # è¤‡é›‘åº¦åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        keywords = {
            TaskComplexity.SIMPLE: [
                "show",
                "list",
                "check",
                "get",
                "view",
                "see",
                "ç¢ºèª",
                "è¡¨ç¤º",
            ],
            TaskComplexity.STANDARD: [
                "edit",
                "fix",
                "change",
                "update",
                "add",
                "ç·¨é›†",
                "ä¿®æ­£",
                "å¤‰æ›´",
            ],
            TaskComplexity.COMPLEX: [
                "implement",
                "build",
                "create",
                "design",
                "setup",
                "å®Ÿè£…",
                "æ§‹ç¯‰",
                "è¨­è¨ˆ",
            ],
            TaskComplexity.CRITICAL: [
                "analyze",
                "evaluate",
                "strategy",
                "research",
                "åˆ†æ",
                "æˆ¦ç•¥",
                "ç ”ç©¶",
            ],
        }

        for complexity, keyword_list in keywords.items():
            keyword_count = sum(words.count(keyword) for keyword in keyword_list)
            density = keyword_count / word_count
            scores[complexity] += density * 0.5

        return scores

    def _determine_execution_method(
        self, complexity: TaskComplexity, task_description: str, context: Dict[str, Any]
    ) -> ExecutionMethod:
        """å®Ÿè¡Œæ‰‹æ³•æ±ºå®š"""
        # è¤‡é›‘åº¦ãƒ™ãƒ¼ã‚¹ã®åŸºæœ¬ãƒãƒƒãƒ”ãƒ³ã‚°
        method_map = {
            TaskComplexity.SIMPLE: ExecutionMethod.DIRECT,
            TaskComplexity.STANDARD: ExecutionMethod.PLANNED,
            TaskComplexity.COMPLEX: ExecutionMethod.AI_COLLABORATION,
            TaskComplexity.CRITICAL: ExecutionMethod.FULL_COLLABORATION,
        }

        return method_map[complexity]

    def _determine_thinking_level(self, complexity: TaskComplexity) -> ThinkingLevel:
        """æ€è€ƒãƒ¬ãƒ™ãƒ«æ±ºå®š"""
        thinking_map = {
            TaskComplexity.SIMPLE: ThinkingLevel.NONE,  # LEVEL 1: thinkingä¸è¦
            TaskComplexity.STANDARD: ThinkingLevel.STANDARD,  # LEVEL 2: <thinking>
            TaskComplexity.COMPLEX: ThinkingLevel.ULTRATHINK,  # LEVEL 3: ultrathink
            TaskComplexity.CRITICAL: ThinkingLevel.MAX_ULTRATHINK,  # LEVEL 4: max ultrathink
        }

        return thinking_map[complexity]

    def _get_required_files(self, complexity: TaskComplexity) -> List[str]:
        """è¤‡é›‘åº¦ãƒ™ãƒ¼ã‚¹ã®å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§"""
        base_files = ["./CLAUDE.md", "./.claude/claude.md", ".cursor/rules/globals.mdc"]

        if complexity == TaskComplexity.SIMPLE:
            return base_files
        elif complexity == TaskComplexity.STANDARD:
            return base_files + ["docs/", "runtime/logs/"]
        elif complexity == TaskComplexity.COMPLEX:
            return base_files + ["docs/", "runtime/", "src/", "scripts/"]
        else:  # CRITICAL
            return base_files + [
                "docs/",
                "runtime/",
                "src/",
                "scripts/",
                "tests/",
                "config/",
            ]

    def _generate_reasoning(
        self,
        complexity: TaskComplexity,
        scores: Dict[TaskComplexity, float],
        task_description: str,
    ) -> str:
        """æ¨è«–ç†ç”±ç”Ÿæˆ"""
        top_scores = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:2]

        reasoning_parts = [
            f"Primary classification: {complexity.value} (score: {scores[complexity]:.2f})"
        ]

        if top_scores[1][1] > 0.1:
            reasoning_parts.append(
                f"Secondary consideration: {top_scores[1][0].value} (score: {top_scores[1][1]:.2f})"
            )

        # ç‰¹å¾´çš„è¦ç´ ã®èª¬æ˜
        if "read" in task_description.lower() or "show" in task_description.lower():
            reasoning_parts.append("Reason: Information retrieval task")
        elif (
            "implement" in task_description.lower()
            or "build" in task_description.lower()
        ):
            reasoning_parts.append("Reason: Implementation task requiring planning")
        elif (
            "analyze" in task_description.lower()
            or "evaluate" in task_description.lower()
        ):
            reasoning_parts.append("Reason: Analysis task requiring expertise")

        return " | ".join(reasoning_parts)

    def _estimate_time(self, complexity: TaskComplexity, task_description: str) -> int:
        """æ™‚é–“è¦‹ç©ã‚‚ã‚Šï¼ˆåˆ†ï¼‰"""
        base_times = {
            TaskComplexity.SIMPLE: 5,
            TaskComplexity.STANDARD: 15,
            TaskComplexity.COMPLEX: 60,
            TaskComplexity.CRITICAL: 180,
        }

        base_time = base_times[complexity]

        # ä¿®æ­£è¦å› 
        if "quick" in task_description.lower() or "simple" in task_description.lower():
            base_time = int(base_time * 0.7)
        elif (
            "detailed" in task_description.lower()
            or "comprehensive" in task_description.lower()
        ):
            base_time = int(base_time * 1.5)

        return base_time

    def _identify_required_tools(self, task_description: str) -> List[str]:
        """å¿…è¦ãƒ„ãƒ¼ãƒ«ç‰¹å®š"""
        tools = []

        tool_patterns = {
            "git": ["git", "repository", "commit", "push", "ãƒªãƒã‚¸ãƒˆãƒª"],
            "npm": ["npm", "node", "package", "install"],
            "python": ["python", "pip", "py", "script"],
            "make": ["make", "makefile", "build"],
            "docker": ["docker", "container", "image"],
            "editor": ["edit", "modify", "change", "ç·¨é›†", "ä¿®æ­£"],
            "search": ["search", "find", "grep", "æ¤œç´¢"],
            "ai_org": ["analyze", "evaluate", "strategy", "åˆ†æ", "æˆ¦ç•¥"],
        }

        for tool, patterns in tool_patterns.items():
            if any(pattern in task_description.lower() for pattern in patterns):
                tools.append(tool)

        return tools

    def _assess_risk_level(
        self, complexity: TaskComplexity, task_description: str
    ) -> str:
        """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«è©•ä¾¡"""
        risk_keywords = {
            "high": ["delete", "remove", "destroy", "force", "reset", "å‰Šé™¤", "å¼·åˆ¶"],
            "medium": ["modify", "change", "update", "merge", "ä¿®æ­£", "å¤‰æ›´"],
            "low": ["read", "show", "list", "check", "è¡¨ç¤º", "ç¢ºèª"],
        }

        for risk_level, keywords in risk_keywords.items():
            if any(keyword in task_description.lower() for keyword in keywords):
                return risk_level

        # è¤‡é›‘åº¦ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        complexity_risk = {
            TaskComplexity.SIMPLE: "low",
            TaskComplexity.STANDARD: "low",
            TaskComplexity.COMPLEX: "medium",
            TaskComplexity.CRITICAL: "high",
        }

        return complexity_risk[complexity]

    def get_execution_recommendation(
        self, task_description: str, context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """å®Ÿè¡Œæ¨å¥¨äº‹é …å–å¾—"""
        classification = self.classify_task(task_description, context)

        recommendations = {
            ExecutionMethod.DIRECT: [
                "Proceed with direct execution (no thinking required)",
                "Use standard tools and commands",
                "Complete task immediately",
            ],
            ExecutionMethod.PLANNED: [
                "Use <thinking> tag for planning",
                "Break down into manageable steps",
                "Use TodoWrite tool for tracking",
            ],
            ExecutionMethod.AI_COLLABORATION: [
                "Use <thinking> tag with ultrathink approach",
                "Engage AI organization for consultation",
                "Use collaborative decision making",
                "Consider multiple perspectives",
            ],
            ExecutionMethod.FULL_COLLABORATION: [
                "Use <thinking> tag with maximum ultrathink depth",
                "Full AI organization collaboration required",
                "User confirmation before major changes",
                "Comprehensive risk assessment",
            ],
        }

        return {
            "classification": {
                "complexity": classification.complexity.value,
                "execution_method": classification.execution_method.value,
                "confidence": classification.confidence,
                "reasoning": classification.reasoning,
            },
            "execution_plan": {
                "estimated_time_minutes": classification.estimated_time,
                "required_tools": classification.required_tools,
                "risk_level": classification.risk_level,
                "recommendations": recommendations[classification.execution_method],
            },
            "efficiency_notes": [
                f"Task complexity: {classification.complexity.value}",
                f"Thinking level: {classification.thinking_level.value}",
                f"Recommended method: {classification.execution_method.value}",
                f"AI collaboration: {'Yes' if classification.ai_collaboration_needed else 'No'}",
                f"Estimated time: {classification.estimated_time} minutes",
                f"Risk level: {classification.risk_level}",
            ],
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
    classifier = TaskComplexityClassifier()

    test_tasks = [
        "Show me the current git status",
        "Edit the README file to add installation instructions",
        "Implement a new authentication system with JWT tokens",
        "Analyze our system architecture and recommend critical improvements",
        "List all Python files in the project",
        "Debug the failing integration tests and fix issues",
        "Research and evaluate different database solutions for scalability",
    ]

    print("ğŸ§  Task Complexity Classification Test")
    print("=" * 60)

    for i, task in enumerate(test_tasks, 1):
        print(f"\nğŸ“ Test {i}: {task}")
        print("-" * 50)

        recommendation = classifier.get_execution_recommendation(task)
        classification = recommendation["classification"]
        execution_plan = recommendation["execution_plan"]

        print(f"ğŸ·ï¸  Complexity: {classification['complexity']}")
        print(f"ğŸ§   Thinking: {recommendation['efficiency_notes'][1].split(': ')[1]}")
        print(f"âš™ï¸  Method: {classification['execution_method']}")
        print(f"ğŸ¤ AI Collab: {recommendation['efficiency_notes'][3].split(': ')[1]}")
        print(f"ğŸ¯ Confidence: {classification['confidence']:.2f}")
        print(f"â±ï¸  Time: {execution_plan['estimated_time_minutes']} minutes")
        print(
            f"ğŸ› ï¸  Tools: {', '.join(execution_plan['required_tools']) if execution_plan['required_tools'] else 'None'}"
        )
        print(f"âš ï¸  Risk: {execution_plan['risk_level']}")
        print(f"ğŸ’­ Reasoning: {classification['reasoning']}")


if __name__ == "__main__":
    main()
