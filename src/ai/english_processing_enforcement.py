#!/usr/bin/env python3
"""
ğŸ”¤ English Processing Enforcement System - æŠ€è¡“å‡¦ç†è‹±èªå¼·åˆ¶ã‚·ã‚¹ãƒ†ãƒ 
==================================================================
æŠ€è¡“çš„å‡¦ç†ã‚’è‹±èªã§å¼·åˆ¶å®Ÿè¡Œã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 
{{mistake_count}}å›ãƒŸã‚¹é˜²æ­¢ãƒ»CLAUDE.mdãƒ«ãƒ¼ãƒ«éµå®ˆã®ä¸€ç’°ã¨ã—ã¦å®Ÿè£…
"""

import json
import re
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Tuple


class ProcessingLanguage(Enum):
    JAPANESE = "japanese"
    ENGLISH = "english"
    MIXED = "mixed"


class ProcessingType(Enum):
    DECLARATION = "declaration"  # å®£è¨€ï¼ˆæ—¥æœ¬èªï¼‰
    TECHNICAL = "technical"  # æŠ€è¡“å‡¦ç†ï¼ˆè‹±èªï¼‰
    REPORTING = "reporting"  # å ±å‘Šï¼ˆæ—¥æœ¬èªï¼‰
    MIXED_CONTEXT = "mixed_context"


@dataclass
class LanguageRule:
    """è¨€èªä½¿ç”¨ãƒ«ãƒ¼ãƒ«"""

    processing_type: ProcessingType
    required_language: ProcessingLanguage
    description: str
    patterns: List[str] = field(default_factory=list)
    enforcement_level: str = "mandatory"  # mandatory, recommended, optional
    violation_penalty: float = 1.0


@dataclass
class ProcessingContext:
    """å‡¦ç†ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""

    content: str
    detected_language: ProcessingLanguage
    expected_language: ProcessingLanguage
    processing_type: ProcessingType
    confidence_score: float
    violations: List[str] = field(default_factory=list)
    corrections: List[str] = field(default_factory=list)


class EnglishProcessingEnforcement:
    """è‹±èªå‡¦ç†å¼·åˆ¶ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, project_root: str = "/Users/dd/Desktop/1_dev/coding-rule2"):
        self.project_root = Path(project_root)
        self.enforcement_log = (
            self.project_root / "runtime" / "logs" / "english_enforcement.log"
        )
        self.violation_archive = (
            self.project_root / "runtime" / "violations" / "language_violations.json"
        )

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.enforcement_log.parent.mkdir(parents=True, exist_ok=True)
        self.violation_archive.parent.mkdir(parents=True, exist_ok=True)

        # è¨€èªä½¿ç”¨ãƒ«ãƒ¼ãƒ«ã®å®šç¾©
        self.language_rules = self._define_language_rules()

        # æŠ€è¡“ç”¨èªè¾æ›¸ï¼ˆæ—¥æœ¬èªâ†’è‹±èªï¼‰
        self.technical_dictionary = self._load_technical_dictionary()

        # è¨€èªæ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³
        self.language_patterns = self._define_language_patterns()

        # é•åè¨˜éŒ²
        self.violation_history = self._load_violation_history()

    def _define_language_rules(self) -> List[LanguageRule]:
        """è¨€èªä½¿ç”¨ãƒ«ãƒ¼ãƒ«ã®å®šç¾©"""
        return [
            LanguageRule(
                processing_type=ProcessingType.DECLARATION,
                required_language=ProcessingLanguage.JAPANESE,
                description="å®£è¨€éƒ¨åˆ†ã¯æ—¥æœ¬èªã§è¨˜è¿°ï¼ˆ## ğŸ¯ ã“ã‚Œã‹ã‚‰è¡Œã†ã“ã¨ï¼‰",
                patterns=[r"##\s*ğŸ¯\s*ã“ã‚Œã‹ã‚‰è¡Œã†ã“ã¨", r"å®£è¨€", r"ç›®æ¨™"],
                enforcement_level="mandatory",
                violation_penalty=0.8,
            ),
            LanguageRule(
                processing_type=ProcessingType.TECHNICAL,
                required_language=ProcessingLanguage.ENGLISH,
                description="æŠ€è¡“çš„å‡¦ç†ã¯è‹±èªã§å®Ÿè¡Œï¼ˆTechnical implementationï¼‰",
                patterns=[
                    r"def\s+\w+",
                    r"class\s+\w+",
                    r"import\s+\w+",
                    r"from\s+\w+",
                    r"function\s+\w+",
                    r"var\s+\w+",
                    r"const\s+\w+",
                    r"let\s+\w+",
                    r"system\s+\w+",
                    r"process\s+\w+",
                    r"execute\s+\w+",
                    r"implement\s+\w+",
                    r"database",
                    r"api",
                    r"server",
                    r"client",
                    r"network",
                    r"security",
                    r"algorithm",
                    r"data\s+structure",
                    r"performance",
                    r"optimization",
                ],
                enforcement_level="mandatory",
                violation_penalty=1.0,
            ),
            LanguageRule(
                processing_type=ProcessingType.REPORTING,
                required_language=ProcessingLanguage.JAPANESE,
                description="å ±å‘Šéƒ¨åˆ†ã¯æ—¥æœ¬èªã§è¨˜è¿°ï¼ˆ## âœ… å®Œé‚å ±å‘Šï¼‰",
                patterns=[r"##\s*âœ…\s*å®Œé‚å ±å‘Š", r"å ±å‘Š", r"çµæœ", r"å®Œäº†"],
                enforcement_level="mandatory",
                violation_penalty=0.8,
            ),
        ]

    def _load_technical_dictionary(self) -> Dict[str, str]:
        """æŠ€è¡“ç”¨èªè¾æ›¸ã®èª­ã¿è¾¼ã¿"""
        return {
            # ã‚·ã‚¹ãƒ†ãƒ é–¢é€£
            "ã‚·ã‚¹ãƒ†ãƒ ": "system",
            "å‡¦ç†": "processing",
            "å®Ÿè£…": "implementation",
            "é–‹ç™º": "development",
            "è¨­è¨ˆ": "design",
            "æ§‹ç¯‰": "construction",
            "ä½œæˆ": "creation",
            "ç”Ÿæˆ": "generation",
            "å¤‰æ›": "conversion",
            "å¤‰æ›´": "modification",
            "ä¿®æ­£": "correction",
            "æ”¹å–„": "improvement",
            "æœ€é©åŒ–": "optimization",
            "çµ±åˆ": "integration",
            "é€£æº": "coordination",
            "ç®¡ç†": "management",
            "åˆ¶å¾¡": "control",
            "ç›£è¦–": "monitoring",
            "æ¤œè¨¼": "verification",
            "ãƒ†ã‚¹ãƒˆ": "testing",
            "è©•ä¾¡": "evaluation",
            "åˆ†æ": "analysis",
            "è§£æ": "parsing",
            "æ¤œç´¢": "search",
            "æŠ½å‡º": "extraction",
            "ãƒ•ã‚£ãƒ«ã‚¿": "filtering",
            "ã‚½ãƒ¼ãƒˆ": "sorting",
            "ä¸¦ã³æ›¿ãˆ": "sorting",
            # ãƒ‡ãƒ¼ã‚¿é–¢é€£
            "ãƒ‡ãƒ¼ã‚¿": "data",
            "æƒ…å ±": "information",
            "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹": "database",
            "ãƒ•ã‚¡ã‚¤ãƒ«": "file",
            "ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª": "directory",
            "ãƒ•ã‚©ãƒ«ãƒ€": "folder",
            "ãƒ‘ã‚¹": "path",
            "è¨­å®š": "configuration",
            "ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿": "parameter",
            "å¼•æ•°": "argument",
            "æˆ»ã‚Šå€¤": "return value",
            "çµæœ": "result",
            "å‡ºåŠ›": "output",
            "å…¥åŠ›": "input",
            # ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°é–¢é€£
            "é–¢æ•°": "function",
            "ãƒ¡ã‚½ãƒƒãƒ‰": "method",
            "ã‚¯ãƒ©ã‚¹": "class",
            "ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ": "object",
            "ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹": "instance",
            "å¤‰æ•°": "variable",
            "å®šæ•°": "constant",
            "é…åˆ—": "array",
            "ãƒªã‚¹ãƒˆ": "list",
            "è¾æ›¸": "dictionary",
            "ãƒãƒƒã‚·ãƒ¥ãƒãƒƒãƒ—": "hash map",
            "ãƒ«ãƒ¼ãƒ—": "loop",
            "æ¡ä»¶åˆ†å²": "conditional",
            "ä¾‹å¤–": "exception",
            "ã‚¨ãƒ©ãƒ¼": "error",
            "ãƒã‚°": "bug",
            "ãƒ‡ãƒãƒƒã‚°": "debug",
            "ã‚³ãƒ¼ãƒ‰": "code",
            "ãƒ—ãƒ­ã‚°ãƒ©ãƒ ": "program",
            "ã‚¹ã‚¯ãƒªãƒ—ãƒˆ": "script",
            "ãƒ©ã‚¤ãƒ–ãƒ©ãƒª": "library",
            "ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«": "module",
            "ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸": "package",
            "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯": "framework",
            "ãƒ„ãƒ¼ãƒ«": "tool",
            "ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£": "utility",
            # ã‚¤ãƒ³ãƒ•ãƒ©é–¢é€£
            "ã‚µãƒ¼ãƒãƒ¼": "server",
            "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ": "client",
            "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯": "network",
            "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£": "security",
            "èªè¨¼": "authentication",
            "èªå¯": "authorization",
            "æš—å·åŒ–": "encryption",
            "ãƒ—ãƒ­ãƒˆã‚³ãƒ«": "protocol",
            "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹": "interface",
            "API": "API",
            "ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ": "endpoint",
            "ãƒªã‚¯ã‚¨ã‚¹ãƒˆ": "request",
            "ãƒ¬ã‚¹ãƒãƒ³ã‚¹": "response",
            "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": "status",
            "ãƒ­ã‚°": "log",
            "ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«": "log file",
            "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—": "backup",
            "å¾©æ—§": "recovery",
            "ç½å®³å¾©æ—§": "disaster recovery",
        }

    def _define_language_patterns(self) -> Dict[str, List[str]]:
        """è¨€èªæ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã®å®šç¾©"""
        return {
            "japanese": [
                r"[\u3040-\u309F]",  # ã²ã‚‰ãŒãª
                r"[\u30A0-\u30FF]",  # ã‚«ã‚¿ã‚«ãƒŠ
                r"[\u4E00-\u9FAF]",  # æ¼¢å­—
                r"ã§ã™",
                r"ã§ã‚ã‚‹",
                r"ã—ã¾ã™",
                r"ã—ã¦ã„ã‚‹",
                r"ã—ãŸ",
                r"ã™ã‚‹",
                r"ã¾ã™",
                r"ã¾ã—ãŸ",
                r"ã¾ã›ã‚“",
                r"ã§ã—ãŸ",
                r"ã ã£ãŸ",
                r"ã ã‚ã†",
                r"ã¨ã—ã¦",
                r"ã«ã‚ˆã‚‹",
                r"ã«ã¤ã„ã¦",
                r"ã«ãŠã„ã¦",
                r"ã«ã‚ˆã‚Š",
                r"ã‚’",
                r"ãŒ",
                r"ã«",
                r"ã§",
                r"ã‹ã‚‰",
                r"ã¾ã§",
                r"ã®",
                r"ã¨",
                r"ã¯",
            ],
            "english": [
                r"\b(the|a|an|and|or|but|in|on|at|to|for|of|with|by)\b",
                r"\b(is|are|was|were|been|be|have|has|had|do|does|did)\b",
                r"\b(will|would|should|could|can|may|might|must|shall)\b",
                r"\b(this|that|these|those|here|there|where|when|how|why)\b",
                r"\b(function|class|method|variable|parameter|return|if|else|while|for)\b",
                r"\b(system|process|data|file|directory|configuration|implementation)\b",
            ],
        }

    def detect_language(self, content: str) -> Tuple[ProcessingLanguage, float]:
        """è¨€èªæ¤œå‡º"""
        japanese_matches = 0
        english_matches = 0

        # æ—¥æœ¬èªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for pattern in self.language_patterns["japanese"]:
            matches = re.findall(pattern, content, re.IGNORECASE)
            japanese_matches += len(matches)

        # è‹±èªãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
        for pattern in self.language_patterns["english"]:
            matches = re.findall(pattern, content, re.IGNORECASE)
            english_matches += len(matches)

        total_matches = japanese_matches + english_matches

        if total_matches == 0:
            return ProcessingLanguage.MIXED, 0.0

        japanese_ratio = japanese_matches / total_matches
        english_ratio = english_matches / total_matches

        if japanese_ratio > 0.7:
            return ProcessingLanguage.JAPANESE, japanese_ratio
        elif english_ratio > 0.7:
            return ProcessingLanguage.ENGLISH, english_ratio
        else:
            return ProcessingLanguage.MIXED, max(japanese_ratio, english_ratio)

    def detect_processing_type(self, content: str) -> ProcessingType:
        """å‡¦ç†ã‚¿ã‚¤ãƒ—ã®æ¤œå‡º"""
        content.lower()

        # å®£è¨€éƒ¨åˆ†ã®æ¤œå‡º
        if (
            re.search(r"##\s*ğŸ¯\s*ã“ã‚Œã‹ã‚‰è¡Œã†ã“ã¨", content)
            or "å®£è¨€" in content
            or "ç›®æ¨™" in content
        ):
            return ProcessingType.DECLARATION

        # å ±å‘Šéƒ¨åˆ†ã®æ¤œå‡º
        if (
            re.search(r"##\s*âœ…\s*å®Œé‚å ±å‘Š", content)
            or "å ±å‘Š" in content
            or "çµæœ" in content
        ):
            return ProcessingType.REPORTING

        # æŠ€è¡“å‡¦ç†ã®æ¤œå‡º
        technical_indicators = [
            r"def\s+\w+",
            r"class\s+\w+",
            r"import\s+\w+",
            r"from\s+\w+",
            r"function",
            r"method",
            r"implementation",
            r"system",
            r"process",
            r"database",
            r"api",
            r"server",
            r"algorithm",
            r"data structure",
        ]

        for pattern in technical_indicators:
            if re.search(pattern, content, re.IGNORECASE):
                return ProcessingType.TECHNICAL

        return ProcessingType.MIXED_CONTEXT

    def enforce_language_rules(self, content: str) -> ProcessingContext:
        """è¨€èªãƒ«ãƒ¼ãƒ«ã®å¼·åˆ¶é©ç”¨"""
        # è¨€èªã¨ã‚¿ã‚¤ãƒ—ã®æ¤œå‡º
        detected_language, confidence = self.detect_language(content)
        processing_type = self.detect_processing_type(content)

        # é©ç”¨ã™ã¹ããƒ«ãƒ¼ãƒ«ã®æ±ºå®š
        applicable_rule = None
        for rule in self.language_rules:
            if rule.processing_type == processing_type:
                applicable_rule = rule
                break

        if not applicable_rule:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ«ãƒ¼ãƒ«ï¼šæŠ€è¡“çš„å†…å®¹ã¯è‹±èª
            if self._is_technical_content(content):
                applicable_rule = LanguageRule(
                    processing_type=ProcessingType.TECHNICAL,
                    required_language=ProcessingLanguage.ENGLISH,
                    description="Technical content should be in English",
                    enforcement_level="recommended",
                    violation_penalty=0.5,
                )
            else:
                # ãƒ«ãƒ¼ãƒ«ãªã—ã€ç¾çŠ¶ç¶­æŒ
                return ProcessingContext(
                    content=content,
                    detected_language=detected_language,
                    expected_language=detected_language,
                    processing_type=processing_type,
                    confidence_score=confidence,
                )

        # é•åãƒã‚§ãƒƒã‚¯
        violations = []
        corrections = []

        if detected_language != applicable_rule.required_language:
            violations.append(
                f"Language mismatch: Expected {applicable_rule.required_language.value}, got {detected_language.value}"
            )

            # ä¿®æ­£ææ¡ˆç”Ÿæˆ
            if applicable_rule.required_language == ProcessingLanguage.ENGLISH:
                corrections.extend(self._generate_english_corrections(content))
            elif applicable_rule.required_language == ProcessingLanguage.JAPANESE:
                corrections.extend(self._generate_japanese_corrections(content))

        # é•åã‚’è¨˜éŒ²
        if violations:
            self._record_violation(content, violations, applicable_rule)

        return ProcessingContext(
            content=content,
            detected_language=detected_language,
            expected_language=applicable_rule.required_language,
            processing_type=processing_type,
            confidence_score=confidence,
            violations=violations,
            corrections=corrections,
        )

    def _is_technical_content(self, content: str) -> bool:
        """æŠ€è¡“çš„å†…å®¹ã®åˆ¤å®š"""
        technical_keywords = [
            "function",
            "class",
            "method",
            "variable",
            "parameter",
            "system",
            "process",
            "algorithm",
            "data",
            "database",
            "api",
            "server",
            "client",
            "network",
            "security",
            "implementation",
            "development",
            "programming",
            "code",
            "def ",
            "class ",
            "import ",
            "from ",
            "return ",
            "if ",
            "else ",
            "while ",
            "for ",
            "try ",
            "except ",
        ]

        content_lower = content.lower()
        return any(keyword in content_lower for keyword in technical_keywords)

    def _generate_english_corrections(self, content: str) -> List[str]:
        """è‹±èªä¿®æ­£ææ¡ˆã®ç”Ÿæˆ"""
        corrections = []

        # æŠ€è¡“ç”¨èªã®æ—¥æœ¬èªâ†’è‹±èªå¤‰æ›
        for japanese_term, english_term in self.technical_dictionary.items():
            if japanese_term in content:
                corrections.append(f"Replace '{japanese_term}' with '{english_term}'")

        # ä¸€èˆ¬çš„ãªä¿®æ­£ææ¡ˆ
        corrections.extend(
            [
                "Use English for technical descriptions",
                "Use English variable names and function names",
                "Use English comments in code",
                "Use English for system messages and log outputs",
            ]
        )

        return corrections

    def _generate_japanese_corrections(self, content: str) -> List[str]:
        """æ—¥æœ¬èªä¿®æ­£ææ¡ˆã®ç”Ÿæˆ"""
        corrections = []

        # è‹±èªâ†’æ—¥æœ¬èªå¤‰æ›ï¼ˆé€†å¼•ãï¼‰
        for japanese_term, english_term in self.technical_dictionary.items():
            if english_term in content.lower():
                corrections.append(f"Replace '{english_term}' with '{japanese_term}'")

        # ä¸€èˆ¬çš„ãªä¿®æ­£ææ¡ˆ
        corrections.extend(
            [
                "Use Japanese for declarations and explanations",
                "Use Japanese for user-facing messages",
                "Use Japanese for reports and summaries",
            ]
        )

        return corrections

    def _record_violation(
        self, content: str, violations: List[str], rule: LanguageRule
    ):
        """é•åè¨˜éŒ²"""
        violation_record = {
            "timestamp": datetime.now().isoformat(),
            "content": content[:200] + "..." if len(content) > 200 else content,
            "violations": violations,
            "rule": {
                "processing_type": rule.processing_type.value,
                "required_language": rule.required_language.value,
                "description": rule.description,
                "enforcement_level": rule.enforcement_level,
                "violation_penalty": rule.violation_penalty,
            },
        }

        self.violation_history.append(violation_record)
        self._save_violation_history()

        # ãƒ­ã‚°å‡ºåŠ›
        self._log(f"Language violation: {', '.join(violations)}")

    def _load_violation_history(self) -> List[Dict[str, Any]]:
        """é•åå±¥æ­´ã®èª­ã¿è¾¼ã¿"""
        try:
            if self.violation_archive.exists():
                with open(self.violation_archive, encoding="utf-8") as f:
                    return json.load(f)
        except Exception:
            pass
        return []

    def _save_violation_history(self):
        """é•åå±¥æ­´ã®ä¿å­˜"""
        try:
            with open(self.violation_archive, "w", encoding="utf-8") as f:
                json.dump(self.violation_history, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self._log(f"Failed to save violation history: {e}")

    def generate_enforcement_report(self) -> Dict[str, Any]:
        """å¼·åˆ¶å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ"""
        total_violations = len(self.violation_history)

        if total_violations == 0:
            return {
                "status": "compliant",
                "total_violations": 0,
                "compliance_rate": 1.0,
                "recommendations": [],
                "enforcement_summary": self._generate_enforcement_summary(),
            }

        # é•åã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ
        violation_types = {}
        for violation in self.violation_history:
            rule_type = violation["rule"]["processing_type"]
            if rule_type not in violation_types:
                violation_types[rule_type] = 0
            violation_types[rule_type] += 1

        # æœ€è¿‘ã®é•åï¼ˆ24æ™‚é–“ä»¥å†…ï¼‰
        recent_violations = []
        now = datetime.now()
        for violation in self.violation_history:
            try:
                violation_time = datetime.fromisoformat(violation["timestamp"])
                if (now - violation_time).days == 0:
                    recent_violations.append(violation)
            except Exception:
                pass

        # æ¨å¥¨äº‹é …ç”Ÿæˆ
        recommendations = []
        if violation_types.get("technical", 0) > 0:
            recommendations.append("Use English for technical implementations")
        if violation_types.get("declaration", 0) > 0:
            recommendations.append(
                "Use Japanese for declarations (## ğŸ¯ ã“ã‚Œã‹ã‚‰è¡Œã†ã“ã¨)"
            )
        if violation_types.get("reporting", 0) > 0:
            recommendations.append("Use Japanese for reports (## âœ… å®Œé‚å ±å‘Š)")

        return {
            "status": "violations_detected",
            "total_violations": total_violations,
            "recent_violations": len(recent_violations),
            "violation_types": violation_types,
            "compliance_rate": max(0.0, 1.0 - (total_violations * 0.1)),
            "recommendations": recommendations,
            "enforcement_summary": self._generate_enforcement_summary(),
        }

    def _generate_enforcement_summary(self) -> str:
        """å¼·åˆ¶å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆ"""
        total_violations = len(self.violation_history)

        if total_violations == 0:
            return "ğŸ‰ å®Œå…¨ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ï¼šè¨€èªä½¿ç”¨ãƒ«ãƒ¼ãƒ«é•åãªã—"

        return f"âš ï¸ è¨€èªä½¿ç”¨ãƒ«ãƒ¼ãƒ«é•å: {total_violations}ä»¶æ¤œå‡º - æ”¹å–„ãŒå¿…è¦"

    def _log(self, message: str):
        """ãƒ­ã‚°å‡ºåŠ›"""
        log_entry = f"[{datetime.now().isoformat()}] {message}"
        print(log_entry)

        try:
            with open(self.enforcement_log, "a", encoding="utf-8") as f:
                f.write(log_entry + "\n")
        except Exception:
            pass


# ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°
def demo_english_processing_enforcement():
    """è‹±èªå‡¦ç†å¼·åˆ¶ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("=== è‹±èªå‡¦ç†å¼·åˆ¶ã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢ ===")

    enforcer = EnglishProcessingEnforcement()

    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {
            "title": "æ—¥æœ¬èªå®£è¨€ï¼ˆé©åˆ‡ï¼‰",
            "content": "## ğŸ¯ ã“ã‚Œã‹ã‚‰è¡Œã†ã“ã¨\n\nãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ ã‚’æ”¹å–„ã—ã¾ã™ã€‚",
        },
        {
            "title": "è‹±èªæŠ€è¡“å®Ÿè£…ï¼ˆé©åˆ‡ï¼‰",
            "content": "def create_database_connection():\n    return Database.connect()",
        },
        {
            "title": "æ—¥æœ¬èªæŠ€è¡“å®Ÿè£…ï¼ˆé•åï¼‰",
            "content": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ä½œæˆã™ã‚‹é–¢æ•°ã‚’å®Ÿè£…ã—ã¾ã™ã€‚",
        },
        {
            "title": "è‹±èªå®£è¨€ï¼ˆé•åï¼‰",
            "content": "## Goal: Implement database system\n\nWe will create a new database system.",
        },
        {
            "title": "æ—¥æœ¬èªå ±å‘Šï¼ˆé©åˆ‡ï¼‰",
            "content": "## âœ… å®Œé‚å ±å‘Š\n\nã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…ãŒå®Œäº†ã—ã¾ã—ãŸã€‚",
        },
    ]

    for test_case in test_cases:
        print(f"\n--- {test_case['title']} ---")
        context = enforcer.enforce_language_rules(test_case["content"])

        print(f"æ¤œå‡ºè¨€èª: {context.detected_language.value}")
        print(f"å‡¦ç†ã‚¿ã‚¤ãƒ—: {context.processing_type.value}")
        print(f"æœŸå¾…è¨€èª: {context.expected_language.value}")
        print(f"ä¿¡é ¼åº¦: {context.confidence_score:.2f}")

        if context.violations:
            print(f"é•å: {', '.join(context.violations)}")
        else:
            print("âœ… é•åãªã—")

        if context.corrections:
            print(f"ä¿®æ­£ææ¡ˆ: {context.corrections[0]}")

    # å¼·åˆ¶å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ
    print("\n--- å¼·åˆ¶å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ ---")
    report = enforcer.generate_enforcement_report()
    print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {report['status']}")
    print(f"ç·é•åæ•°: {report['total_violations']}")
    print(f"ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹ç‡: {report['compliance_rate']:.2f}")
    print(f"ã‚µãƒãƒªãƒ¼: {report['enforcement_summary']}")

    if report["recommendations"]:
        print("æ¨å¥¨äº‹é …:")
        for rec in report["recommendations"]:
            print(f"  - {rec}")


if __name__ == "__main__":
    demo_english_processing_enforcement()
