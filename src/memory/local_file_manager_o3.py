#!/usr/bin/env python3
"""
üìÅ o3Êé®Â•®„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•„É≠„Éº„Ç´„É´„Éï„Ç°„Ç§„É´ÁÆ°ÁêÜ„Ç∑„Çπ„ÉÜ„É† - ÂÆâÂÖ®ÊÄßÂÑ™ÂÖàÈöéÂ±§ÂåñÂâäÈô§
=================================================================

„Äêo3ÂõûÁ≠î„Å´„Çà„ÇãË®≠Ë®àÊîπÂñÑ„Äë
- 500MB ‚Üí 8GBÂÆπÈáèË®≠ÂÆöÔºàÈñãÁô∫Áí∞Â¢É„Å´ÁèæÂÆüÁöÑÔºâ
- ÈöéÂ±§Âåñ„Çπ„Éà„É¨„Éº„Ç∏ÔºàHot/Warm/ColdÔºâ
- Â≠¶Áøí„Éá„Éº„ÇøÊ∞∏Á∂ö‰øùË≠∑Ôºà30Êó•ÂâäÈô§ÂïèÈ°åËß£Ê±∫Ôºâ
- „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•„Éá„Éº„Çø„Éô„Éº„ÇπË®≠ÂÆö
- ÂØæË©±ÂûãUXÊîπÂñÑ

„ÄêÂÆüË£ÖÂÜÖÂÆπ„Äë
- „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ëá™ÂãïÊ§úÂá∫
- ÂÆπÈáè„Éô„Éº„ÇπÈöéÂ±§ÂåñÁõ£Ë¶ñ
- Ë§áÂêà„Çπ„Ç≥„Ç¢„É™„É≥„Ç∞ÂâäÈô§ÂÑ™ÂÖàÂ∫¶
- ÂÆâÂÖ®„Å™atomic renameÊìç‰Ωú
- DBÊìç‰Ωú„É≠„Ç∞Ë®òÈå≤
- ÂØæË©±Âûã„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó„Ç¶„Ç£„Ç∂„Éº„Éâ
"""

import json
from pathlib import Path
from typing import Any, Dict, Optional


class LocalFileManagerO3:
    """o3Êé®Â•®„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•„É≠„Éº„Ç´„É´„Éï„Ç°„Ç§„É´ÁÆ°ÁêÜ - UXÈáçË¶ñË®≠Ë®à"""

    def __init__(
        self, project_root: Optional[Path] = None, config_file: Optional[str] = None
    ):
        """ÂàùÊúüÂåñ - „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•Ë®≠ÂÆöÂØæÂøú"""

        # „Éó„É≠„Ç∏„Çß„ÇØ„Éà„É´„Éº„ÉàËá™ÂãïÊ§úÂá∫
        if project_root:
            self.project_root = project_root
        else:
            self.project_root = Path(__file__).parent.parent

        # Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë™≠„ÅøËæº„ÅøÔºàUXÂÑ™ÂÖàÔºâ
        self.config = self._load_project_config(config_file)

        # DBË®≠ÂÆöÔºà„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•Ôºâ
        self.db_config = self.config.get(
            "database",
            {
                "host": "localhost",
                "database": f"{self.project_root.name}_ai",  # „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂêç„Éô„Éº„Çπ
                "user": "dd",
                "password": "",
                "port": 5432,
            },
        )

        # o3Êé®Â•®ÁèæÂÆüÁöÑÂÆπÈáèË®≠ÂÆö
        capacity_config = self.config.get("capacity", {})
        self.max_total_size_mb = capacity_config.get(
            "max_size_mb", 8192
        )  # „Éá„Éï„Ç©„É´„Éà8GB
        self.warning_threshold_mb = capacity_config.get(
            "warning_mb", int(self.max_total_size_mb * 0.8)
        )
        self.target_cleanup_mb = capacity_config.get(
            "target_mb", int(self.max_total_size_mb * 0.64)
        )

        # o3Êé®Â•®‰øùË≠∑ÊúüÈñìË®≠ÂÆöÔºà„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•Ë™øÊï¥ÂèØËÉΩÔºâ
        # DISABLED: Memory inheritance system never expires data
        # retention_config = self.config.get("retention", {})
        self.hot_retention_days = -1  # DISABLED: Permanent retention
        self.warm_retention_days = -1  # DISABLED: Permanent retention
        self.critical_preserve_days = -1  # DISABLED: Permanent retention

        # „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•‰øùË≠∑Ë®≠ÂÆö
        protection_config = self.config.get("protection", {})
        self.learning_data_protection = protection_config.get("learning_data", True)
        self.documentation_protection = protection_config.get("documentation", True)
        self.auto_backup_enabled = protection_config.get("auto_backup", True)

        # „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•„Éá„Ç£„É¨„ÇØ„Éà„É™Ë®≠ÂÆö
        paths_config = self.config.get("paths", {})

        # „Éõ„ÉÉ„ÉàÂ±§Ôºà„Éá„Éï„Ç©„É´„Éà + „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂõ∫ÊúâÔºâ
        default_hot_paths = ["logs", "tmp", "runtime", "operations/runtime-logs"]
        hot_paths = paths_config.get("hot_tier", default_hot_paths)
        self.hot_tier_paths = [self.project_root / path for path in hot_paths]

        # „Ç¶„Ç©„Éº„É†Â±§
        warm_path = paths_config.get("warm_tier", "data/warm")
        self.warm_tier_path = self.project_root / warm_path

        # Â≠¶Áøí„Éá„Éº„ÇøÂ±§ÔºàÊ∞∏Á∂ö‰øùË≠∑Ôºâ
        default_learning_paths = ["docs", "ai-instructions", "memory"]
        learning_paths = paths_config.get("learning_data", default_learning_paths)
        self.learning_data_paths = [self.project_root / path for path in learning_paths]

        # ÂÆâÂÖ®ÊÄßË®≠ÂÆöÔºà„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•Ë™øÊï¥ÂèØËÉΩÔºâ
        safety_config = self.config.get("safety", {})
        trash_dir = safety_config.get("trash_directory", ".trash")
        self.trash_directory = self.project_root / trash_dir
        self.verification_delay_seconds = safety_config.get("verification_delay", 2)
        self.max_batch_delete = safety_config.get("max_batch_delete", 20)

        # UXÊîπÂñÑË®≠ÂÆö
        ux_config = self.config.get("ux", {})
        self.interactive_mode = ux_config.get("interactive_mode", True)
        self.verbose_logging = ux_config.get("verbose_logging", True)
        self.progress_bar_enabled = ux_config.get("progress_bar", True)

        # „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•‰øùË≠∑„Éë„Çø„Éº„É≥Ë®≠ÂÆö
        patterns_config = self.config.get("protection_patterns", {})

        default_learning = [
            "mistake*",
            "president*",
            "*learning*",
            "*report*",
            "*analysis*",
        ]
        self.learning_protected_patterns = patterns_config.get(
            "learning", default_learning
        )

        default_docs = [
            "README*",
            "*.md",
            "docs/*",
            "ai-instructions/*",
            "*manual*",
            "*guide*",
        ]
        self.documentation_protected_patterns = patterns_config.get(
            "documentation", default_docs
        )

        default_critical = [
            "*error*",
            "*critical*",
            ".git*",
            "config/*",
            "*.py",
            "*.json",
        ]
        self.critical_system_patterns = patterns_config.get(
            "critical_system", default_critical
        )

        # „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂõ∫Êúâ„ÅÆËøΩÂä†„Éë„Çø„Éº„É≥
        self.custom_protected_patterns = patterns_config.get("custom", [])

    def _load_project_config(self, config_file: Optional[str] = None) -> Dict[str, Any]:
        """„Éó„É≠„Ç∏„Çß„ÇØ„ÉàË®≠ÂÆö„Éï„Ç°„Ç§„É´Ë™≠„ÅøËæº„Åø"""

        # Ë®≠ÂÆö„Éï„Ç°„Ç§„É´ÂÄôË£ú
        config_candidates = []

        if config_file:
            config_candidates.append(Path(config_file))

        # „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂÜÖË®≠ÂÆö„Éï„Ç°„Ç§„É´ÂÄôË£ú
        config_candidates.extend(
            [
                self.project_root / "memory_config.json",
                self.project_root / "config" / "memory.json",
                self.project_root / ".memory_config.json",
                Path.home() / ".ai_memory" / f"{self.project_root.name}.json",
                Path.home() / ".ai_memory" / "default.json",
            ]
        )

        # ÊúÄÂàù„Å´Ë¶ã„Å§„Åã„Å£„ÅüË®≠ÂÆö„Éï„Ç°„Ç§„É´„Çí‰ΩøÁî®
        for config_path in config_candidates:
            if config_path.exists():
                try:
                    with open(config_path, encoding="utf-8") as f:
                        config = json.load(f)
                    if hasattr(self, "verbose_logging") and self.verbose_logging:
                        print(f"üìÑ Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë™≠„ÅøËæº„Åø: {config_path}")
                    return config
                except Exception as e:
                    if hasattr(self, "verbose_logging") and self.verbose_logging:
                        print(f"‚ö†Ô∏è Ë®≠ÂÆö„Éï„Ç°„Ç§„É´Ë™≠„ÅøËæº„Åø„Ç®„É©„Éº {config_path}: {e}")
                    continue

        # Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑÂ†¥Âêà„ÅØ„Éá„Éï„Ç©„É´„ÉàË®≠ÂÆö
        return self._create_default_config()

    def _create_default_config(self) -> Dict[str, Any]:
        """„Éá„Éï„Ç©„É´„ÉàË®≠ÂÆöÁîüÊàê"""
        return {
            "database": {
                "host": "localhost",
                "database": f"{self.project_root.name}_ai",
                "user": "dd",
                "password": "",
                "port": 5432,
            },
            "capacity": {"max_size_mb": 8192, "warning_mb": 6553, "target_mb": 5242},
            "retention": {"hot_days": 14, "warm_days": 365, "critical_days": 730},
            "protection": {
                "learning_data": True,
                "documentation": True,
                "auto_backup": True,
            },
            "ux": {
                "interactive_mode": True,
                "verbose_logging": True,
                "progress_bar": True,
            },
        }

    def generate_config_template(self, output_path: Optional[Path] = None) -> Path:
        """Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÉÜ„É≥„Éó„É¨„Éº„ÉàÁîüÊàê"""

        if output_path is None:
            output_path = self.project_root / "memory_config.json"

        template = {
            "_comment": "AI Memory Management Configuration",
            "project_name": self.project_root.name,
            "database": {
                "host": "localhost",
                "database": f"{self.project_root.name}_ai",
                "user": "dd",
                "password": "",
                "port": 5432,
            },
            "capacity": {
                "_comment": "Storage capacity settings (MB)",
                "max_size_mb": 8192,
                "warning_mb": 6553,
                "target_mb": 5242,
            },
            "paths": {
                "_comment": "Project-specific directory paths",
                "hot_tier": ["logs", "tmp", "runtime"],
                "warm_tier": "data/warm",
                "learning_data": ["docs", "ai-instructions", "memory"],
            },
            "retention": {
                "_comment": "Retention periods (days)",
                "hot_days": 14,
                "warm_days": 365,
                "critical_days": 730,
            },
            "protection": {
                "_comment": "Data protection settings",
                "learning_data": True,
                "documentation": True,
                "auto_backup": True,
            },
            "protection_patterns": {
                "_comment": "File patterns to protect from deletion",
                "learning": [
                    "mistake*",
                    "president*",
                    "*learning*",
                    "*report*",
                    "*analysis*",
                ],
                "documentation": ["README*", "*.md", "docs/*", "ai-instructions/*"],
                "critical_system": [
                    "*error*",
                    "*critical*",
                    ".git*",
                    "config/*",
                    "*.py",
                    "*.json",
                ],
                "custom": [],
            },
            "safety": {
                "_comment": "Safety and verification settings",
                "trash_directory": ".trash",
                "verification_delay": 2,
                "max_batch_delete": 20,
            },
            "ux": {
                "_comment": "User experience settings",
                "interactive_mode": True,
                "verbose_logging": True,
                "progress_bar": True,
            },
        }

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(template, f, indent=2, ensure_ascii=False)

        if self.verbose_logging:
            print(f"üìù Ë®≠ÂÆö„ÉÜ„É≥„Éó„É¨„Éº„ÉàÁîüÊàê: {output_path}")

        return output_path

    def calculate_tiered_storage_stats(self) -> Dict[str, Any]:
        """o3Êé®Â•®ÈöéÂ±§Âåñ„Çπ„Éà„É¨„Éº„Ç∏Áµ±Ë®àË®àÁÆó"""

        hot_size = 0
        warm_size = 0
        protected_size = 0
        total_file_count = 0
        tier_stats = {
            "hot_tier": {},
            "warm_tier": {},
            "learning_data": {},
            "total_summary": {},
        }

        # „Éõ„ÉÉ„ÉàÂ±§Áµ±Ë®à
        for monitor_path in self.hot_tier_paths:
            if not monitor_path.exists():
                continue

            dir_size = 0
            dir_files = 0

            for file_path in monitor_path.rglob("*"):
                if file_path.is_file():
                    try:
                        file_size = file_path.stat().st_size
                        hot_size += file_size
                        dir_size += file_size
                        total_file_count += 1
                        dir_files += 1
                    except (OSError, PermissionError):
                        continue

            tier_stats["hot_tier"][str(monitor_path.relative_to(self.project_root))] = {
                "size_mb": round(dir_size / (1024 * 1024), 2),
                "file_count": dir_files,
            }

        # Â≠¶Áøí„Éá„Éº„ÇøÂ±§Áµ±Ë®à
        for learning_path in self.learning_data_paths:
            if not learning_path.exists():
                continue

            dir_size = 0
            dir_files = 0

            for file_path in learning_path.rglob("*"):
                if file_path.is_file():
                    try:
                        file_size = file_path.stat().st_size
                        protected_size += file_size
                        dir_size += file_size
                        total_file_count += 1
                        dir_files += 1
                    except (OSError, PermissionError):
                        continue

            tier_stats["learning_data"][
                str(learning_path.relative_to(self.project_root))
            ] = {"size_mb": round(dir_size / (1024 * 1024), 2), "file_count": dir_files}

        # „Ç¶„Ç©„Éº„É†Â±§Áµ±Ë®à
        if self.warm_tier_path.exists():
            for file_path in self.warm_tier_path.rglob("*"):
                if file_path.is_file():
                    try:
                        warm_size += file_path.stat().st_size
                    except (OSError, PermissionError):
                        continue

        total_size = hot_size + warm_size + protected_size
        total_size_mb = total_size / (1024 * 1024)
        hot_size_mb = hot_size / (1024 * 1024)
        warm_size_mb = warm_size / (1024 * 1024)
        protected_size_mb = protected_size / (1024 * 1024)

        tier_stats["total_summary"] = {
            "total_size_mb": round(total_size_mb, 2),
            "hot_tier_mb": round(hot_size_mb, 2),
            "warm_tier_mb": round(warm_size_mb, 2),
            "protected_data_mb": round(protected_size_mb, 2),
            "total_files": total_file_count,
            "capacity_analysis": {
                "max_limit_mb": self.max_total_size_mb,
                "warning_threshold_mb": self.warning_threshold_mb,
                "current_usage_percent": round(
                    (hot_size_mb / self.max_total_size_mb) * 100, 1
                ),
                "needs_cleanup": hot_size_mb > self.warning_threshold_mb,
                "tier_distribution": {
                    "hot_percent": round((hot_size_mb / total_size_mb) * 100, 1)
                    if total_size_mb > 0
                    else 0,
                    "warm_percent": round((warm_size_mb / total_size_mb) * 100, 1)
                    if total_size_mb > 0
                    else 0,
                    "protected_percent": round(
                        (protected_size_mb / total_size_mb) * 100, 1
                    )
                    if total_size_mb > 0
                    else 0,
                },
            },
        }

        return tier_stats

    def get_project_summary(self) -> Dict[str, Any]:
        """„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•„Çµ„Éû„É™„ÉºÁîüÊàê"""
        stats = self.calculate_tiered_storage_stats()

        return {
            "project_name": self.project_root.name,
            "database_name": self.db_config["database"],
            "capacity_summary": stats["total_summary"]["capacity_analysis"],
            "tier_distribution": stats["total_summary"]["capacity_analysis"][
                "tier_distribution"
            ],
            "configuration": {
                "max_capacity_gb": round(self.max_total_size_mb / 1024, 1),
                "hot_retention_days": self.hot_retention_days,
                "warm_retention_days": self.warm_retention_days,
                "protection_enabled": {
                    "learning_data": self.learning_data_protection,
                    "documentation": self.documentation_protection,
                    "auto_backup": self.auto_backup_enabled,
                },
            },
            "paths": {
                "hot_tier": [
                    str(p.relative_to(self.project_root)) for p in self.hot_tier_paths
                ],
                "warm_tier": str(self.warm_tier_path.relative_to(self.project_root)),
                "learning_data": [
                    str(p.relative_to(self.project_root))
                    for p in self.learning_data_paths
                ],
            },
        }

    def interactive_cleanup_wizard(self) -> Dict[str, Any]:
        """DISABLED: Memory inheritance system never deletes memories"""
        return {
            "status": "disabled",
            "message": "Memory inheritance system preserves all memories",
            "cleaned_files": 0,
        }
        if not self.interactive_mode:
            return {"status": "non_interactive_mode", "message": "ÂØæË©±„É¢„Éº„Éâ„ÅåÁÑ°Âäπ„Åß„Åô"}

        print("\nüßô‚Äç‚ôÇÔ∏è ÂØæË©±Âûã„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó„Ç¶„Ç£„Ç∂„Éº„Éâ")
        stats = self.calculate_tiered_storage_stats()
        capacity = stats["total_summary"]["capacity_analysis"]

        print(f"üìä ÁèæÂú®„ÅÆ‰ΩøÁî®Èáè: {capacity['current_usage_percent']}%")
        print(f"üìà Ë≠¶ÂëäÈñæÂÄ§: {self.warning_threshold_mb}MB")
        print(f"üî• ÁèæÂú®„ÅÆ„Éõ„ÉÉ„ÉàÂ±§: {stats['total_summary']['hot_tier_mb']}MB")

        if not capacity["needs_cleanup"]:
            print("‚úÖ „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó„ÅØ‰∏çË¶Å„Åß„Åô„ÄÇ")
            return {"status": "no_cleanup_needed"}

        print("\nüóÇÔ∏è  „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó„ÅåÊé®Â•®„Åï„Çå„Åæ„Åô")
        print(f"üíæ „Éá„Éº„Çø„Éô„Éº„Çπ: {self.db_config['database']}")
        print(
            f"üõ°Ô∏è Â≠¶Áøí„Éá„Éº„Çø‰øùË≠∑: {'ÊúâÂäπ' if self.learning_data_protection else 'ÁÑ°Âäπ'}"
        )

        # „É¶„Éº„Ç∂„ÉºÁ¢∫Ë™ç
        while True:
            choice = input("\nÂÆüË°å„Åó„Åæ„Åô„ÅãÔºü [y]es/[n]o/[d]ry-run: ").lower().strip()
            if choice in ["y", "yes"]:
                print("üöÄ ÂÆüÈöõ„ÅÆ„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó„ÇíÂÆüË°å„Åó„Åæ„Åô...")
                return {"status": "user_confirmed", "action": "execute"}
            elif choice in ["d", "dry", "dry-run"]:
                print("üîç „Éâ„É©„Ç§„É©„É≥„ÇíÂÆüË°å„Åó„Åæ„Åô...")
                return {"status": "user_confirmed", "action": "dry_run"}
            elif choice in ["n", "no"]:
                print("‚ùå „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó„Çí„Ç≠„É£„É≥„Çª„É´„Åó„Åæ„Åó„Åü„ÄÇ")
                return {"status": "cancelled"}
            else:
                print("‚ö†Ô∏è  y/n/d „ÅÆ„ÅÑ„Åö„Çå„Åã„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")


def main():
    """„É°„Ç§„É≥ÂÆüË°å - „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•„É≠„Éº„Ç´„É´„Éï„Ç°„Ç§„É´ÁÆ°ÁêÜ"""

    # „Ç≥„Éû„É≥„Éâ„É©„Ç§„É≥ÂºïÊï∞ÂØæÂøú
    import sys

    project_root = None
    config_file = None

    if len(sys.argv) > 1:
        if sys.argv[1] == "--generate-config":
            if len(sys.argv) > 2:
                project_root = Path(sys.argv[2])
            else:
                project_root = Path.cwd()

            manager = LocalFileManagerO3(project_root=project_root)
            config_path = manager.generate_config_template()
            print(f"‚úÖ Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÉÜ„É≥„Éó„É¨„Éº„ÉàÁîüÊàêÂÆå‰∫Ü: {config_path}")
            print("   Ë®≠ÂÆö„Çí„Ç´„Çπ„Çø„Éû„Ç§„Ç∫„Åó„Å¶„Åã„Çâ„Ç∑„Çπ„ÉÜ„É†„ÇíÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
            return

        elif sys.argv[1] == "--config":
            config_file = sys.argv[2] if len(sys.argv) > 2 else None

        elif sys.argv[1] == "--project":
            project_root = Path(sys.argv[2]) if len(sys.argv) > 2 else None

    print("üìÅ „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•„É≠„Éº„Ç´„É´„Éï„Ç°„Ç§„É´ÁÆ°ÁêÜ„Ç∑„Çπ„ÉÜ„É†ÈñãÂßã")

    try:
        manager = LocalFileManagerO3(project_root=project_root, config_file=config_file)
    except Exception as e:
        print(f"‚ùå ÂàùÊúüÂåñ„Ç®„É©„Éº: {e}")
        print(
            "   Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„ÇíÁ¢∫Ë™ç„Åô„Çã„Åã„ÄÅ--generate-config „Åß„ÉÜ„É≥„Éó„É¨„Éº„Éà„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        )
        return

    print(f"üèóÔ∏è „Éó„É≠„Ç∏„Çß„ÇØ„Éà: {manager.project_root.name}")
    print(f"üíæ „Éá„Éº„Çø„Éô„Éº„Çπ: {manager.db_config['database']}")
    print(f"üìä ÂÆπÈáè‰∏äÈôê: {manager.max_total_size_mb}MB")

    # 1. „Éó„É≠„Ç∏„Çß„ÇØ„Éà„Çµ„Éû„É™„ÉºË°®Á§∫
    print("\n1Ô∏è‚É£ „Éó„É≠„Ç∏„Çß„ÇØ„Éà„Çµ„Éû„É™„Éº")
    summary = manager.get_project_summary()
    print(f"üíæ ÊúÄÂ§ßÂÆπÈáè: {summary['configuration']['max_capacity_gb']}GB")
    print(f"üî• „Éõ„ÉÉ„ÉàÂ±§‰øùÊåÅ: {summary['configuration']['hot_retention_days']}Êó•")
    print(f"üå°Ô∏è „Ç¶„Ç©„Éº„É†Â±§‰øùÊåÅ: {summary['configuration']['warm_retention_days']}Êó•")

    # 2. ÈöéÂ±§Âåñ„Çπ„Éà„É¨„Éº„Ç∏Áä∂Ê≥ÅÁ¢∫Ë™ç
    print("\n2Ô∏è‚É£ ÈöéÂ±§Âåñ„Çπ„Éà„É¨„Éº„Ç∏Áä∂Ê≥Å")
    stats = manager.calculate_tiered_storage_stats()
    total_summary = stats["total_summary"]
    print(f"üìä Á∑èÂÆπÈáè: {total_summary['total_size_mb']}MB")
    print(
        f"üî• „Éõ„ÉÉ„ÉàÂ±§: {total_summary['hot_tier_mb']}MB ({total_summary['capacity_analysis']['tier_distribution']['hot_percent']}%)"
    )
    print(
        f"üå°Ô∏è „Ç¶„Ç©„Éº„É†Â±§: {total_summary['warm_tier_mb']}MB ({total_summary['capacity_analysis']['tier_distribution']['warm_percent']}%)"
    )
    print(
        f"üõ°Ô∏è ‰øùË≠∑„Éá„Éº„Çø: {total_summary['protected_data_mb']}MB ({total_summary['capacity_analysis']['tier_distribution']['protected_percent']}%)"
    )
    print(f"üìà ‰ΩøÁî®Áéá: {total_summary['capacity_analysis']['current_usage_percent']}%")
    print(
        f"‚ö†Ô∏è „ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„ÉóÂøÖË¶Å: {'‚úÖ Yes' if total_summary['capacity_analysis']['needs_cleanup'] else '‚ùå No'}"
    )

    # „Éá„Ç£„É¨„ÇØ„Éà„É™Âà•ÂÆπÈáè
    print("\n   „Éõ„ÉÉ„ÉàÂ±§„Éá„Ç£„É¨„ÇØ„Éà„É™Âà•:")
    for dir_name, dir_stats in stats["hot_tier"].items():
        print(
            f"     üî• {dir_name}: {dir_stats['size_mb']}MB ({dir_stats['file_count']}„Éï„Ç°„Ç§„É´)"
        )

    if stats["learning_data"]:
        print("\n   Â≠¶Áøí„Éá„Éº„Çø„Éá„Ç£„É¨„ÇØ„Éà„É™Âà•:")
        for dir_name, dir_stats in stats["learning_data"].items():
            print(
                f"     üß† {dir_name}: {dir_stats['size_mb']}MB ({dir_stats['file_count']}„Éï„Ç°„Ç§„É´)"
            )

    # 3. ÂØæË©±Âûã„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó
    if total_summary["capacity_analysis"]["needs_cleanup"]:
        print("\n3Ô∏è‚É£ ÂØæË©±Âûã„ÇØ„É™„Éº„É≥„Ç¢„ÉÉ„Éó")

        if manager.interactive_mode:
            wizard_result = manager.interactive_cleanup_wizard()
            print(f"„Ç¶„Ç£„Ç∂„Éº„ÉâÁµêÊûú: {wizard_result['status']}")
        else:
            print("   ÈùûÂØæË©±„É¢„Éº„Éâ„ÅåË®≠ÂÆö„Åï„Çå„Å¶„ÅÑ„Åæ„Åô")

    # 4. Ë®≠ÂÆöË°®Á§∫„Å®Ê¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó
    print("\n4Ô∏è‚É£ „Éó„É≠„Ç∏„Çß„ÇØ„ÉàË®≠ÂÆöÊÉÖÂ†±")
    print(f"üìã Ë®≠ÂÆö„Éï„Ç°„Ç§„É´: {manager.project_root / 'memory_config.json'}")
    print(f"üíæ „Éá„Éº„Çø„Éô„Éº„Çπ: {manager.db_config['database']}")
    print(f"üîß ÂØæË©±„É¢„Éº„Éâ: {'ÊúâÂäπ' if manager.interactive_mode else 'ÁÑ°Âäπ'}")
    print(f"üìù Ë©≥Á¥∞„É≠„Ç∞: {'ÊúâÂäπ' if manager.verbose_logging else 'ÁÑ°Âäπ'}")

    print("\nüìñ ‰ΩøÁî®ÊñπÊ≥ï:")
    print(
        "   Ë®≠ÂÆöÁîüÊàê: python local_file_manager_o3.py --generate-config [„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Éë„Çπ]"
    )
    print("   Ë®≠ÂÆöÊåáÂÆö: python local_file_manager_o3.py --config [Ë®≠ÂÆö„Éï„Ç°„Ç§„É´„Éë„Çπ]")
    print(
        "   „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÊåáÂÆö: python local_file_manager_o3.py --project [„Éó„É≠„Ç∏„Çß„ÇØ„Éà„Éë„Çπ]"
    )

    print("\n‚úÖ o3Êé®Â•®„Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•„É≠„Éº„Ç´„É´„Éï„Ç°„Ç§„É´ÁÆ°ÁêÜ„Ç∑„Çπ„ÉÜ„É†ÂÆüË£ÖÂÆå‰∫Ü")
    print(
        "üìç 8GBÂÆπÈáè + ÈöéÂ±§Âåñ„Çπ„Éà„É¨„Éº„Ç∏ + Â≠¶Áøí„Éá„Éº„ÇøÊ∞∏Á∂ö‰øùË≠∑ + „Éó„É≠„Ç∏„Çß„ÇØ„ÉàÂà•DB + UXÈáçË¶ñË®≠Ë®à"
    )


if __name__ == "__main__":
    main()
