#!/usr/bin/env python3
"""
Intelligent Project Analyzer - AIçµ„ç¹”è‡ªå‹•é…ç½®ã‚·ã‚¹ãƒ†ãƒ 
=====================================================
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¦ä»¶åˆ†æã¨AIãƒ¯ãƒ¼ã‚«ãƒ¼æœ€é©é…ç½®ã‚’è‡ªå‹•å®Ÿè¡Œ

Features:
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚¹ã‚­ãƒ£ãƒ³ãƒ»è§£æ
- è¦ä»¶å®šç¾©æ›¸ãƒ»ä»•æ§˜æ›¸ã®è‡ªå‹•è§£æ
- é©åˆ‡ãªAIå½¹è·ã®è‡ªå‹•æ±ºå®šï¼ˆæœ€ä½4ãƒ¯ãƒ¼ã‚«ãƒ¼+PRESIDENTï¼‰
- tmux-based Claude Codeä¸¦åˆ—èµ·å‹•
- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰çµ±åˆç›£è¦–
"""

import json
import logging
import os
import re
import subprocess
import sys
import time
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

# Add project root to path
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))


@dataclass
class ProjectAnalysis:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æçµæœ"""

    project_type: str  # web_dev, ai_system, data_analysis, etc.
    complexity_level: str  # simple, moderate, complex, enterprise
    key_technologies: List[str]
    primary_objectives: List[str]
    required_expertise: List[str]
    estimated_team_size: int
    recommended_roles: List[str]
    critical_files: List[str]
    analysis_confidence: float


@dataclass
class AIWorkerRole:
    """AIãƒ¯ãƒ¼ã‚«ãƒ¼å½¹è·å®šç¾©"""

    role_id: str
    role_name: str
    display_name: str
    expertise_areas: List[str]
    responsibilities: List[str]
    priority: int  # 1=highest, 5=lowest


class IntelligentProjectAnalyzer:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè‡ªå‹•åˆ†æãƒ»AIé…ç½®ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, project_root: Optional[str] = None):
        self.project_root = (
            Path(project_root) if project_root else Path(__file__).resolve().parents[2]
        )
        self.runtime_dir = self.project_root / "runtime"
        self.analysis_cache = self.runtime_dir / "project_analysis_cache.json"

        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            handlers=[
                logging.FileHandler(self.runtime_dir / "logs" / "project_analyzer.log"),
                logging.StreamHandler(),
            ],
        )
        self.logger = logging.getLogger("project-analyzer")

        # AIå½¹è·ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.role_templates = self._load_role_templates()

        # åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«
        self.critical_analysis_files = [
            "Index.md",
            "CLAUDE.md",
            "README.md",
            "startup_checklist.md",
            "docs/01_concepts/",
            "docs/02_guides/",
            "docs/03_processes/",
            "docs/04_reference/",
            "src/",
            "tests/",
            "requirements.txt",
            "package.json",
            "pyproject.toml",
            "Makefile",
        ]

    def _load_role_templates(self) -> Dict[str, AIWorkerRole]:
        """AIå½¹è·ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿"""
        return {
            "PRESIDENT": AIWorkerRole(
                role_id="PRESIDENT",
                role_name="Executive President",
                display_name="ğŸ‘‘ PRESIDENT",
                expertise_areas=[
                    "strategic_planning",
                    "coordination",
                    "quality_assurance",
                ],
                responsibilities=[
                    "Overall project leadership",
                    "Quality control",
                    "Team coordination",
                ],
                priority=1,
            ),
            "TECH_LEAD": AIWorkerRole(
                role_id="TECH_LEAD",
                role_name="Technical Lead",
                display_name="ğŸ—ï¸ TECH_LEAD",
                expertise_areas=["architecture", "code_review", "technical_decisions"],
                responsibilities=[
                    "Technical architecture",
                    "Code quality",
                    "Technical decisions",
                ],
                priority=2,
            ),
            "FULL_STACK_DEV": AIWorkerRole(
                role_id="FULL_STACK_DEV",
                role_name="Full Stack Developer",
                display_name="ğŸ’» FULL_STACK",
                expertise_areas=["frontend", "backend", "integration"],
                responsibilities=[
                    "Feature implementation",
                    "Integration work",
                    "End-to-end development",
                ],
                priority=2,
            ),
            "QA_SPECIALIST": AIWorkerRole(
                role_id="QA_SPECIALIST",
                role_name="QA Specialist",
                display_name="ğŸ§ª QA_SPEC",
                expertise_areas=["testing", "quality_assurance", "automation"],
                responsibilities=[
                    "Test planning",
                    "Quality validation",
                    "Bug detection",
                ],
                priority=3,
            ),
            "AI_SPECIALIST": AIWorkerRole(
                role_id="AI_SPECIALIST",
                role_name="AI/ML Specialist",
                display_name="ğŸ¤– AI_SPEC",
                expertise_areas=["machine_learning", "ai_systems", "data_processing"],
                responsibilities=[
                    "AI/ML implementation",
                    "Model optimization",
                    "Intelligence systems",
                ],
                priority=2,
            ),
            "SECURITY_SPEC": AIWorkerRole(
                role_id="SECURITY_SPEC",
                role_name="Security Specialist",
                display_name="ğŸ›¡ï¸ SEC_SPEC",
                expertise_areas=["security", "compliance", "risk_assessment"],
                responsibilities=[
                    "Security implementation",
                    "Compliance checking",
                    "Risk mitigation",
                ],
                priority=3,
            ),
            "DEVOPS_SPEC": AIWorkerRole(
                role_id="DEVOPS_SPEC",
                role_name="DevOps Specialist",
                display_name="âš™ï¸ DEVOPS",
                expertise_areas=["deployment", "infrastructure", "automation"],
                responsibilities=["CI/CD", "Infrastructure", "Deployment automation"],
                priority=3,
            ),
            "DOC_SPECIALIST": AIWorkerRole(
                role_id="DOC_SPECIALIST",
                role_name="Documentation Specialist",
                display_name="ğŸ“š DOC_SPEC",
                expertise_areas=["documentation", "technical_writing", "user_guides"],
                responsibilities=["Documentation", "User guides", "Technical writing"],
                priority=4,
            ),
        }

    def analyze_project_comprehensively(self) -> ProjectAnalysis:
        """åŒ…æ‹¬çš„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æ"""
        self.logger.info("Starting comprehensive project analysis...")

        # å„åˆ†æã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå®Ÿè¡Œ
        structure_analysis = self._analyze_project_structure()
        documentation_analysis = self._analyze_documentation()
        technology_analysis = self._analyze_technologies()
        complexity_analysis = self._analyze_complexity()

        # åˆ†æçµæœçµ±åˆ
        project_type = self._determine_project_type(
            structure_analysis, technology_analysis
        )
        complexity_level = complexity_analysis["level"]
        key_technologies = technology_analysis["technologies"]
        primary_objectives = documentation_analysis["objectives"]
        required_expertise = self._determine_required_expertise(
            project_type, key_technologies
        )

        # ãƒãƒ¼ãƒ ã‚µã‚¤ã‚ºã¨ãƒ¯ãƒ¼ã‚«ãƒ¼å½¹è·æ±ºå®š
        team_size, recommended_roles = self._determine_optimal_team_composition(
            project_type, complexity_level, required_expertise
        )

        analysis = ProjectAnalysis(
            project_type=project_type,
            complexity_level=complexity_level,
            key_technologies=key_technologies,
            primary_objectives=primary_objectives,
            required_expertise=required_expertise,
            estimated_team_size=team_size,
            recommended_roles=recommended_roles,
            critical_files=self._identify_critical_files(),
            analysis_confidence=self._calculate_confidence(
                structure_analysis, documentation_analysis
            ),
        )

        # åˆ†æçµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._cache_analysis(analysis)

        self.logger.info(
            f"Project analysis completed: {project_type} ({complexity_level})"
        )
        return analysis

    def _analyze_project_structure(self) -> Dict[str, Any]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ åˆ†æ"""
        structure = {
            "src_dirs": [],
            "test_dirs": [],
            "config_files": [],
            "documentation_dirs": [],
            "total_files": 0,
            "total_python_files": 0,
            "total_js_files": 0,
            "has_ai_components": False,
            "has_web_components": False,
            "has_database": False,
        }

        for root, _dirs, files in os.walk(self.project_root):
            rel_path = Path(root).relative_to(self.project_root)

            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆ†é¡
            if "src" in str(rel_path) or "source" in str(rel_path):
                structure["src_dirs"].append(str(rel_path))
            if "test" in str(rel_path) or "spec" in str(rel_path):
                structure["test_dirs"].append(str(rel_path))
            if "docs" in str(rel_path) or "documentation" in str(rel_path):
                structure["documentation_dirs"].append(str(rel_path))

            # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
            for file in files:
                structure["total_files"] += 1

                if file.endswith((".py", ".pyi")):
                    structure["total_python_files"] += 1

                    # AIé–¢é€£ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ¤œå‡º
                    if any(
                        keyword in file.lower()
                        for keyword in ["ai", "ml", "neural", "model", "learning"]
                    ):
                        structure["has_ai_components"] = True

                elif file.endswith((".js", ".ts", ".jsx", ".tsx")):
                    structure["total_js_files"] += 1
                    structure["has_web_components"] = True

                elif file.endswith((".sql", ".db", ".sqlite")):
                    structure["has_database"] = True

                elif file in [
                    "requirements.txt",
                    "package.json",
                    "Makefile",
                    "docker-compose.yml",
                ]:
                    structure["config_files"].append(file)

        return structure

    def _analyze_documentation(self) -> Dict[str, Any]:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåˆ†æ"""
        docs_analysis = {
            "objectives": [],
            "features": [],
            "requirements": [],
            "complexity_indicators": [],
        }

        # é‡è¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿ãƒ»è§£æ
        key_docs = ["README.md", "CLAUDE.md", "Index.md", "startup_checklist.md"]

        for doc_file in key_docs:
            doc_path = self.project_root / doc_file
            if doc_path.exists():
                content = doc_path.read_text(encoding="utf-8", errors="ignore")

                # ç›®çš„ãƒ»æ©Ÿèƒ½æŠ½å‡º
                objectives = re.findall(
                    r"(?:ç›®çš„|ç›®æ¨™|objectives?|goals?)[:\s]*([^\n]+)",
                    content,
                    re.IGNORECASE,
                )
                docs_analysis["objectives"].extend(objectives)

                features = re.findall(
                    r"(?:æ©Ÿèƒ½|features?|capabilities)[:\s]*([^\n]+)",
                    content,
                    re.IGNORECASE,
                )
                docs_analysis["features"].extend(features)

                # è¤‡é›‘æ€§æŒ‡æ¨™
                if "AI" in content or "machine learning" in content.lower():
                    docs_analysis["complexity_indicators"].append("ai_complexity")
                if (
                    "microservice" in content.lower()
                    or "distributed" in content.lower()
                ):
                    docs_analysis["complexity_indicators"].append(
                        "architecture_complexity"
                    )
                if (
                    "enterprise" in content.lower()
                    or "enterprise-grade" in content.lower()
                ):
                    docs_analysis["complexity_indicators"].append(
                        "enterprise_complexity"
                    )

        return docs_analysis

    def _analyze_technologies(self) -> Dict[str, Any]:
        """æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯åˆ†æ"""
        technologies = set()

        # requirements.txtåˆ†æ
        req_file = self.project_root / "requirements.txt"
        if req_file.exists():
            content = req_file.read_text()
            for line in content.split("\n"):
                if line.strip() and not line.startswith("#"):
                    pkg = line.split("==")[0].split(">=")[0].split("~=")[0].strip()
                    technologies.add(pkg)

        # package.jsonåˆ†æ
        pkg_file = self.project_root / "package.json"
        if pkg_file.exists():
            try:
                pkg_data = json.loads(pkg_file.read_text())
                for deps in [
                    pkg_data.get("dependencies", {}),
                    pkg_data.get("devDependencies", {}),
                ]:
                    technologies.update(deps.keys())
            except json.JSONDecodeError:
                pass

        # pyproject.tomlåˆ†æ
        pyproject_file = self.project_root / "pyproject.toml"
        if pyproject_file.exists():
            content = pyproject_file.read_text()
            # ç°¡æ˜“TOMLè§£æ
            deps_section = re.search(
                r"\[tool\.poetry\.dependencies\](.*?)\[", content, re.DOTALL
            )
            if deps_section:
                for line in deps_section.group(1).split("\n"):
                    if "=" in line:
                        dep = line.split("=")[0].strip().strip('"')
                        if dep:
                            technologies.add(dep)

        return {"technologies": list(technologies)}

    def _analyze_complexity(self) -> Dict[str, Any]:
        """è¤‡é›‘æ€§åˆ†æ"""
        complexity_score = 0
        indicators = []

        # ãƒ•ã‚¡ã‚¤ãƒ«æ•°ã«ã‚ˆã‚‹è¤‡é›‘æ€§
        total_files = sum(1 for _ in self.project_root.rglob("*") if _.is_file())
        if total_files > 1000:
            complexity_score += 3
            indicators.append("large_codebase")
        elif total_files > 500:
            complexity_score += 2
            indicators.append("medium_codebase")
        elif total_files > 100:
            complexity_score += 1
            indicators.append("small_codebase")

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã«ã‚ˆã‚‹è¤‡é›‘æ€§
        if (self.project_root / "src").exists():
            complexity_score += 1
        if (self.project_root / "tests").exists():
            complexity_score += 1
        if (self.project_root / "docs").exists():
            complexity_score += 1

        # æŠ€è¡“çš„è¤‡é›‘æ€§
        if (self.project_root / "docker-compose.yml").exists():
            complexity_score += 2
            indicators.append("containerized")
        if (self.project_root / ".github").exists():
            complexity_score += 1
            indicators.append("ci_cd")

        # è¤‡é›‘æ€§ãƒ¬ãƒ™ãƒ«æ±ºå®š
        if complexity_score >= 8:
            level = "enterprise"
        elif complexity_score >= 5:
            level = "complex"
        elif complexity_score >= 3:
            level = "moderate"
        else:
            level = "simple"

        return {"level": level, "score": complexity_score, "indicators": indicators}

    def _determine_project_type(self, structure: Dict, technology: Dict) -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—æ±ºå®š"""
        technologies = {tech.lower() for tech in technology["technologies"]}

        # AI/MLãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
        ai_keywords = {
            "tensorflow",
            "pytorch",
            "scikit-learn",
            "pandas",
            "numpy",
            "transformers",
        }
        if structure["has_ai_components"] or ai_keywords.intersection(technologies):
            return "ai_system"

        # Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
        web_keywords = {
            "react",
            "vue",
            "angular",
            "express",
            "flask",
            "django",
            "fastapi",
        }
        if structure["has_web_components"] or web_keywords.intersection(technologies):
            return "web_application"

        # ãƒ‡ãƒ¼ã‚¿åˆ†æ
        data_keywords = {"jupyter", "matplotlib", "seaborn", "plotly", "streamlit"}
        if data_keywords.intersection(technologies):
            return "data_analysis"

        # ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»DevOps
        infra_keywords = {"docker", "kubernetes", "terraform", "ansible"}
        if infra_keywords.intersection(technologies):
            return "infrastructure"

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
        return "general_software"

    def _determine_required_expertise(
        self, project_type: str, technologies: List[str]
    ) -> List[str]:
        """å¿…è¦å°‚é–€çŸ¥è­˜æ±ºå®š"""
        expertise = set()

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—åˆ¥
        type_expertise = {
            "ai_system": ["machine_learning", "data_processing", "ai_systems"],
            "web_application": ["frontend", "backend", "database"],
            "data_analysis": ["data_processing", "visualization", "statistics"],
            "infrastructure": ["deployment", "automation", "monitoring"],
            "general_software": ["programming", "testing", "documentation"],
        }

        expertise.update(type_expertise.get(project_type, []))

        # æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯åˆ¥
        tech_lower = [tech.lower() for tech in technologies]
        if any(t in tech_lower for t in ["security", "auth", "oauth"]):
            expertise.add("security")
        if any(t in tech_lower for t in ["test", "pytest", "jest"]):
            expertise.add("testing")
        if any(t in tech_lower for t in ["docker", "k8s", "kubernetes"]):
            expertise.add("deployment")

        return list(expertise)

    def _determine_optimal_team_composition(
        self, project_type: str, complexity: str, expertise: List[str]
    ) -> Tuple[int, List[str]]:
        """æœ€é©ãƒãƒ¼ãƒ æ§‹æˆæ±ºå®š"""
        base_roles = ["PRESIDENT"]  # PRESIDENTã¯å¸¸ã«å«ã‚€

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—åˆ¥æ¨å¥¨å½¹è·
        type_roles = {
            "ai_system": [
                "AI_SPECIALIST",
                "TECH_LEAD",
                "QA_SPECIALIST",
                "DOC_SPECIALIST",
            ],
            "web_application": [
                "FULL_STACK_DEV",
                "TECH_LEAD",
                "QA_SPECIALIST",
                "SECURITY_SPEC",
            ],
            "data_analysis": [
                "AI_SPECIALIST",
                "FULL_STACK_DEV",
                "QA_SPECIALIST",
                "DOC_SPECIALIST",
            ],
            "infrastructure": [
                "DEVOPS_SPEC",
                "SECURITY_SPEC",
                "TECH_LEAD",
                "QA_SPECIALIST",
            ],
            "general_software": [
                "FULL_STACK_DEV",
                "TECH_LEAD",
                "QA_SPECIALIST",
                "DOC_SPECIALIST",
            ],
        }

        recommended = type_roles.get(project_type, type_roles["general_software"])

        # è¤‡é›‘æ€§ã«å¿œã˜ãŸèª¿æ•´
        if complexity in ["complex", "enterprise"]:
            if "SECURITY_SPEC" not in recommended:
                recommended.append("SECURITY_SPEC")
            if "DEVOPS_SPEC" not in recommended and len(recommended) < 6:
                recommended.append("DEVOPS_SPEC")

        # æœ€ä½4ãƒ¯ãƒ¼ã‚«ãƒ¼ä¿è¨¼
        if len(recommended) < 4:
            missing = 4 - len(recommended)
            extras = ["FULL_STACK_DEV", "QA_SPECIALIST", "DOC_SPECIALIST", "TECH_LEAD"]
            for extra in extras[:missing]:
                if extra not in recommended:
                    recommended.append(extra)

        all_roles = base_roles + recommended
        return len(all_roles), all_roles

    def _identify_critical_files(self) -> List[str]:
        """é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«ç‰¹å®š"""
        critical = []

        standard_files = [
            "README.md",
            "CLAUDE.md",
            "Index.md",
            "Makefile",
            "requirements.txt",
        ]
        for file in standard_files:
            if (self.project_root / file).exists():
                critical.append(file)

        # src/é…ä¸‹ã®ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«
        src_dir = self.project_root / "src"
        if src_dir.exists():
            for py_file in src_dir.rglob("*.py"):
                if py_file.stat().st_size > 1000:  # 1KBä»¥ä¸Š
                    critical.append(str(py_file.relative_to(self.project_root)))

        return critical[:20]  # ä¸Šä½20ãƒ•ã‚¡ã‚¤ãƒ«

    def _calculate_confidence(self, structure: Dict, documentation: Dict) -> float:
        """åˆ†æä¿¡é ¼åº¦è¨ˆç®—"""
        confidence = 0.5  # ãƒ™ãƒ¼ã‚¹ä¿¡é ¼åº¦

        # æ§‹é€ çš„è¦ç´ ã«ã‚ˆã‚‹ä¿¡é ¼åº¦å‘ä¸Š
        if structure["src_dirs"]:
            confidence += 0.1
        if structure["test_dirs"]:
            confidence += 0.1
        if structure["documentation_dirs"]:
            confidence += 0.1

        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå“è³ªã«ã‚ˆã‚‹ä¿¡é ¼åº¦å‘ä¸Š
        if documentation["objectives"]:
            confidence += 0.1
        if documentation["features"]:
            confidence += 0.1

        return min(confidence, 1.0)

    def _cache_analysis(self, analysis: ProjectAnalysis):
        """åˆ†æçµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        cache_data = {
            "timestamp": datetime.now().isoformat(),
            "analysis": asdict(analysis),
        }

        self.analysis_cache.parent.mkdir(parents=True, exist_ok=True)
        with open(self.analysis_cache, "w", encoding="utf-8") as f:
            json.dump(cache_data, f, indent=2, ensure_ascii=False)

    def launch_ai_organization(self, analysis: ProjectAnalysis) -> bool:
        """AIçµ„ç¹”è‡ªå‹•èµ·å‹•"""
        self.logger.info(
            f"Launching AI organization for {analysis.project_type} project"
        )

        try:
            # æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self._cleanup_existing_sessions()

            # AIçµ„ç¹”è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆai-team.shã®è¦ä»¶ï¼‰
            self._ensure_ai_org_configuration()

            # æ—¢å­˜ai-team.shã‚’ä½¿ç”¨ã—ã¦tmuxèµ·å‹•
            ai_team_script = self.project_root / "scripts/tools/system/ai-team.sh"

            if not ai_team_script.exists():
                self.logger.error(f"AI team script not found: {ai_team_script}")
                return False

            # Direct tmux AI organization launch (bypassing interactive confirmation)
            success = self._launch_tmux_ai_organization_direct()

            if success:
                result = type("Result", (), {"returncode": 0})()
            else:
                result = type(
                    "Result",
                    (),
                    {
                        "returncode": 1,
                        "stdout": "",
                        "stderr": "Direct tmux launch failed",
                    },
                )()

            # Fallback to ai-team.sh with automatic confirmation
            if not success:
                result = self._launch_with_auto_confirmation(ai_team_script)

            if result.returncode == 0:
                self.logger.info("AI organization launched successfully")

                # å½¹è·ç‰¹åŒ–ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
                self._send_specialized_instructions(analysis)
                return True
            else:
                self.logger.error("Failed to launch AI organization:")
                self.logger.error(f"Return code: {result.returncode}")
                self.logger.error(f"STDOUT: {result.stdout}")
                self.logger.error(f"STDERR: {result.stderr}")
                return False

        except Exception as e:
            self.logger.error(f"Error launching AI organization: {e}")
            return False

    def _cleanup_existing_sessions(self):
        """æ—¢å­˜tmuxã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        sessions_to_cleanup = ["president", "multiagent"]

        for session in sessions_to_cleanup:
            try:
                # Check if session exists
                result = subprocess.run(
                    ["tmux", "has-session", "-t", session],
                    capture_output=True,
                    text=True,
                )

                if result.returncode == 0:
                    self.logger.info(f"Cleaning up existing session: {session}")
                    subprocess.run(["tmux", "kill-session", "-t", session], check=True)
                    self.logger.info(f"Session {session} cleaned up successfully")

            except subprocess.CalledProcessError as e:
                self.logger.warning(f"Failed to cleanup session {session}: {e}")

    def _ensure_ai_org_configuration(self):
        """AIçµ„ç¹”è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºä¿"""
        config_file = self.project_root / ".ai-org-configured"

        if not config_file.exists():
            self.logger.info("Creating AI organization configuration file")
            config_file.touch()
            self.logger.info("AI organization configuration file created")
        else:
            self.logger.info("AI organization configuration file already exists")

    def _launch_tmux_ai_organization_direct(self) -> bool:
        """ç›´æ¥tmuxã‚³ãƒãƒ³ãƒ‰ã§AIçµ„ç¹”èµ·å‹•"""
        try:
            self.logger.info("Launching AI organization via direct tmux commands")

            # Step 1: Start PRESIDENT session
            subprocess.run(
                [
                    "tmux",
                    "new-session",
                    "-d",
                    "-s",
                    "president",
                    "-c",
                    str(self.project_root),
                ],
                check=True,
            )

            subprocess.run(
                [
                    "tmux",
                    "send-keys",
                    "-t",
                    "president",
                    "claude --dangerously-skip-permissions",
                    "C-m",
                ],
                check=True,
            )

            # Step 2: Start multiagent session with 4 panes
            subprocess.run(
                [
                    "tmux",
                    "new-session",
                    "-d",
                    "-s",
                    "multiagent",
                    "-c",
                    str(self.project_root),
                ],
                check=True,
            )

            # Split into 4 panes
            subprocess.run(
                ["tmux", "split-window", "-h", "-t", "multiagent"], check=True
            )
            subprocess.run(
                ["tmux", "split-window", "-v", "-t", "multiagent:0.0"], check=True
            )
            subprocess.run(
                ["tmux", "split-window", "-v", "-t", "multiagent:0.1"], check=True
            )
            subprocess.run(
                ["tmux", "select-layout", "-t", "multiagent", "tiled"], check=True
            )

            # Set pane titles and start Claude instances
            titles = [
                "ğŸ‘”ï¼šBOSS1ï¼šçµ±æ‹¬ç®¡ç†",
                "ğŸ’»ï¼šWORKER1ï¼šé–‹ç™ºå®Ÿè£…",
                "ğŸ”§ï¼šWORKER2ï¼šå“è³ªç®¡ç†",
                "ğŸ¨ï¼šWORKER3ï¼šè¨­è¨ˆæ–‡æ›¸",
            ]
            for i in range(4):
                subprocess.run(
                    ["tmux", "select-pane", "-t", f"multiagent:0.{i}", "-T", titles[i]],
                    check=True,
                )

                subprocess.run(
                    [
                        "tmux",
                        "send-keys",
                        "-t",
                        f"multiagent:0.{i}",
                        "claude --dangerously-skip-permissions",
                        "C-m",
                    ],
                    check=True,
                )
                time.sleep(3)  # Longer delay for proper initialization

            # Wait for Claude initialization and send Enter to complete setup
            self.logger.info("Waiting for Claude instances to initialize...")
            time.sleep(10)  # Wait for all instances to start

            # Send Enter to complete Claude initialization
            for i in range(4):
                subprocess.run(
                    ["tmux", "send-keys", "-t", f"multiagent:0.{i}", "C-m"], check=True
                )
                time.sleep(1)

            # Also send Enter to PRESIDENT
            subprocess.run(["tmux", "send-keys", "-t", "president", "C-m"], check=True)

            # Wait for final initialization
            time.sleep(5)

            # Verify initialization
            self._verify_claude_initialization()

            # Configure status bar with perfect enforcer
            self._apply_perfect_statusbar_system()

            # Start worker status monitoring
            self._start_worker_status_monitoring()

            self.logger.info("AI organization launched successfully via direct tmux")
            return True

        except subprocess.CalledProcessError as e:
            self.logger.error(f"Failed to launch AI organization via direct tmux: {e}")
            return False

    def _verify_claude_initialization(self):
        """Verify Claude instances are properly initialized"""
        panes_to_check = ["president"] + [f"multiagent:0.{i}" for i in range(4)]

        for pane in panes_to_check:
            try:
                result = subprocess.run(
                    ["tmux", "capture-pane", "-t", pane, "-p"],
                    capture_output=True,
                    text=True,
                    check=True,
                )

                content = result.stdout.strip()
                if "How can I help" in content:
                    self.logger.info(f"âœ… {pane}: Claude initialized successfully")
                else:
                    self.logger.warning(
                        f"âš ï¸  {pane}: Claude may not be fully initialized"
                    )
                    # Try sending another Enter
                    subprocess.run(["tmux", "send-keys", "-t", pane, "C-m"], check=True)

            except Exception as e:
                self.logger.error(f"Failed to verify {pane}: {e}")

    def _apply_perfect_statusbar_system(self):
        """å®Œç’§ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ã‚·ã‚¹ãƒ†ãƒ é©ç”¨"""
        try:
            from src.orchestrator.tmux_statusbar_enforcer import TmuxStatusBarEnforcer

            self.logger.info("Applying perfect statusbar system...")
            enforcer = TmuxStatusBarEnforcer(str(self.project_root))

            # å…¨ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šé©ç”¨
            results = enforcer.apply_all_sessions()

            success_count = sum(1 for result in results.values() if result)
            total_count = len(results)

            self.logger.info(
                f"StatusBar configuration: {success_count}/{total_count} sessions successful"
            )

            # ç¶™ç¶šç›£è¦–é–‹å§‹
            enforcer.start_continuous_monitoring()
            self.logger.info(
                "âœ… Perfect statusbar system activated with continuous monitoring"
            )

        except Exception as e:
            self.logger.error(f"Error applying perfect statusbar system: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬è¨­å®š
            self._apply_basic_statusbar_fallback()

    def _apply_basic_statusbar_fallback(self):
        """åŸºæœ¬ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼è¨­å®šï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        try:
            self.logger.info("Applying basic statusbar fallback...")

            sessions = ["president", "multiagent"]
            for session in sessions:
                if self._session_exists(session):
                    subprocess.run(
                        ["tmux", "set-option", "-t", session, "status", "on"],
                        check=True,
                    )
                    subprocess.run(
                        [
                            "tmux",
                            "set-option",
                            "-t",
                            session,
                            "pane-border-status",
                            "top",
                        ],
                        check=True,
                    )
                    subprocess.run(
                        [
                            "tmux",
                            "set-option",
                            "-t",
                            session,
                            "pane-border-format",
                            "#{pane_title}",
                        ],
                        check=True,
                    )

            self.logger.info("Basic statusbar fallback applied")

        except Exception as e:
            self.logger.error(f"Error in statusbar fallback: {e}")

    def _session_exists(self, session_name: str) -> bool:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å­˜åœ¨ç¢ºèª"""
        try:
            result = subprocess.run(
                ["tmux", "has-session", "-t", session_name],
                capture_output=True,
                text=True,
            )
            return result.returncode == 0
        except Exception:
            return False

    def _start_worker_status_monitoring(self):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç›£è¦–é–‹å§‹"""
        try:
            # å½¹è·ã¨ã‚¿ã‚¹ã‚¯ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã‚’å„ªå…ˆ
            from src.orchestrator.realtime_task_display_system import (
                RealtimeTaskDisplaySystem,
            )

            self.logger.info("Starting realtime task display system...")
            task_display = RealtimeTaskDisplaySystem(str(self.project_root))

            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ç›£è¦–é–‹å§‹
            import threading

            display_thread = threading.Thread(
                target=task_display.start_monitoring, daemon=True
            )
            display_thread.start()

            self.logger.info("âœ… Realtime task display system activated")

            # æ—¢å­˜ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç›£è¦–ã‚‚èµ·å‹•ï¼ˆè£œåŠ©çš„ã«ï¼‰
            try:
                from src.orchestrator.ai_worker_status_monitor import (
                    AIWorkerStatusMonitor,
                )

                monitor = AIWorkerStatusMonitor(str(self.project_root))
                monitor_thread = threading.Thread(
                    target=monitor.start_monitoring, daemon=True
                )
                monitor_thread.start()
                self.logger.info("âœ… Worker status monitoring also activated")
            except Exception:
                pass  # è£œåŠ©ã‚·ã‚¹ãƒ†ãƒ ãªã®ã§å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œ

        except Exception as e:
            self.logger.error(f"Error starting task display system: {e}")

    def _launch_with_auto_confirmation(self, ai_team_script: Path) -> object:
        """ai-team.shã«è‡ªå‹•ç¢ºèªã‚’é€ä¿¡ã—ã¦èµ·å‹•"""
        try:
            self.logger.info("Attempting AI organization launch with auto-confirmation")

            # Use 'yes' command to automatically confirm
            result = subprocess.run(
                ["sh", "-c", f"echo 'Y' | {ai_team_script} start"],
                capture_output=True,
                text=True,
                cwd=self.project_root,
            )

            return result

        except Exception as e:
            self.logger.error(f"Auto-confirmation launch failed: {e}")
            return type(
                "Result", (), {"returncode": 1, "stdout": "", "stderr": str(e)}
            )()

    def _send_specialized_instructions(self, analysis: ProjectAnalysis):
        """å°‚é–€åŒ–æŒ‡ç¤ºé€ä¿¡ï¼ˆå…¨ãƒ¯ãƒ¼ã‚«ãƒ¼ã«é€ä¿¡+ã‚¨ãƒ³ã‚¿ãƒ¼å‡¦ç†ï¼‰"""
        time.sleep(8)  # AIçµ„ç¹”èµ·å‹•å¾…æ©Ÿï¼ˆã‚ˆã‚Šé•·ã‚ã«ï¼‰

        # PRESIDENTå‘ã‘ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
        president_msg = f"""
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æå®Œäº†ã€‚ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç‰¹æ€§ã«åŸºã¥ã„ã¦ãƒãƒ¼ãƒ ã‚’æŒ‡æ®ã—ã¦ãã ã•ã„ï¼š

ğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æçµæœ:
- ã‚¿ã‚¤ãƒ—: {analysis.project_type}
- è¤‡é›‘åº¦: {analysis.complexity_level}
- ä¸»è¦æŠ€è¡“: {", ".join(analysis.key_technologies[:5])}
- æ¨å¥¨ãƒãƒ¼ãƒ : {", ".join(analysis.recommended_roles)}

ğŸ¯ ä¸»è¦ç›®æ¨™:
{chr(10).join(f"- {obj}" for obj in analysis.primary_objectives[:3])}

å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã«å°‚é–€åˆ†é‡ã‚’å‰²ã‚Šå½“ã¦ã€åŠ¹ç‡çš„ãªã‚¿ã‚¹ã‚¯åˆ†æ•£ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
        """

        # ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‘ã‘åŸºæœ¬æŒ‡ç¤º
        worker_base_msg = f"""
ğŸš€ AIçµ„ç¹”ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒé–‹å§‹

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {analysis.project_type} ({analysis.complexity_level})
æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯: {", ".join(analysis.key_technologies[:3])}

å„è‡ªã®å°‚é–€åˆ†é‡ã‚’æ´»ã‹ã—ã¦åŠ¹ç‡çš„ã«ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
ä¸æ˜ãªç‚¹ãŒã‚ã‚Œã°PRESIDENTã«ç¢ºèªã—ã¦ãã ã•ã„ã€‚
        """

        try:
            # PRESIDENTå‘ã‘è©³ç´°æŒ‡ç¤ºé€ä¿¡
            self._send_message_with_enter("president", president_msg)
            self.logger.info("âœ… Specialized instructions sent to PRESIDENT")

            time.sleep(3)  # ãƒ¯ãƒ¼ã‚«ãƒ¼æŒ‡ç¤ºå‰ã®å¾…æ©Ÿ

            # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã«åŸºæœ¬æŒ‡ç¤ºé€ä¿¡
            worker_panes = [f"multiagent:0.{i}" for i in range(4)]
            worker_roles = ["BOSS1", "WORKER1", "WORKER2", "WORKER3"]

            for _i, (pane, role) in enumerate(zip(worker_panes, worker_roles)):
                role_specific_msg = f"{worker_base_msg}\n\nğŸ‘” ã‚ãªãŸã®å½¹è·: {role}"
                self._send_message_with_enter(pane, role_specific_msg)
                self.logger.info(f"âœ… Instructions sent to {role} ({pane})")
                time.sleep(2)  # å„ãƒ¯ãƒ¼ã‚«ãƒ¼é–“ã®é–“éš”

            self.logger.info("ğŸ‰ All specialized instructions sent successfully")

        except subprocess.CalledProcessError as e:
            self.logger.error(f"Failed to send instructions: {e}")
        except Exception as e:
            self.logger.error(f"Error in instruction sending: {e}")

    def _send_message_with_enter(self, pane_target: str, message: str):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡å¾Œã«ç¢ºå®Ÿã«ã‚¨ãƒ³ã‚¿ãƒ¼ã‚’æŠ¼ã™"""
        try:
            # 1. ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚»ãƒƒãƒˆï¼ˆsend-keysã§æ–‡å­—åˆ—é€ä¿¡ï¼‰
            subprocess.run(
                ["tmux", "send-keys", "-t", pane_target, message], check=True
            )

            time.sleep(1)  # ã‚»ãƒƒãƒˆå¾Œã®çŸ­ã„å¾…æ©Ÿ

            # 2. ã‚¨ãƒ³ã‚¿ãƒ¼ã‚­ãƒ¼ã§é€ä¿¡å®Ÿè¡Œ
            subprocess.run(["tmux", "send-keys", "-t", pane_target, "C-m"], check=True)

            self.logger.debug(f"Message sent to {pane_target} with Enter")

        except subprocess.CalledProcessError as e:
            self.logger.error(f"Failed to send message to {pane_target}: {e}")
            raise


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    import argparse

    parser = argparse.ArgumentParser(description="Intelligent Project Analyzer")
    parser.add_argument(
        "action", choices=["analyze", "launch", "full"], help="Action to perform"
    )
    parser.add_argument("--project-root", help="Project root directory")

    args = parser.parse_args()

    analyzer = IntelligentProjectAnalyzer(args.project_root)

    if args.action == "analyze":
        analysis = analyzer.analyze_project_comprehensively()
        print(json.dumps(asdict(analysis), indent=2, ensure_ascii=False))

    elif args.action == "launch":
        # æ—¢å­˜åˆ†æã‚’ä½¿ç”¨ã—ã¦AIçµ„ç¹”èµ·å‹•
        if analyzer.analysis_cache.exists():
            cache_data = json.load(open(analyzer.analysis_cache))
            analysis = ProjectAnalysis(**cache_data["analysis"])
            success = analyzer.launch_ai_organization(analysis)
            print(f"AI Organization Launch: {'SUCCESS' if success else 'FAILED'}")
        else:
            print("No cached analysis found. Run 'analyze' first.")

    elif args.action == "full":
        # å®Œå…¨è‡ªå‹•å®Ÿè¡Œ
        analysis = analyzer.analyze_project_comprehensively()
        print("Project Analysis Completed")
        print(f"Project Type: {analysis.project_type}")
        print(f"Complexity: {analysis.complexity_level}")
        print(f"Recommended Team: {', '.join(analysis.recommended_roles)}")

        success = analyzer.launch_ai_organization(analysis)
        print(f"AI Organization Launch: {'SUCCESS' if success else 'FAILED'}")


if __name__ == "__main__":
    main()
